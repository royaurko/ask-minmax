Password: An important question in providing on-demand access to large widely shared data files, such as popular video files, is how to effectively use regional (proxy) servers that can store some of the data close to the clients. The proxy caching problem is more complex in the context of continuous media files because of the need to consider bandwidth as well as storage constraints at the proxy servers, and because of the bandwidth sharing possibilities provided by recently proposed multicast delivery techniques. This paper develops new highly efficient analytic models for determining optimal proxy cache content in such environments. Specifically, the new models apply to heterogeneous systems in which the proxy servers have different client workloads and server capabilities. Results from the models provide general insights into caching strategies for such systems, and suggest that it may be useful to employ efficient cost models in actual systems to determine what content should be cached in response to the measured client workload. Keywords Proxy caching ; Heterogenous systems ; Streaming media ; Optimization models 1. Introduction In systems that support on-demand access to widely shared data, delivery cost can be greatly reduced through the use of regional (or proxy) servers that store some of the data close to the requesting clients. This paper addresses the question of which large popular widely shared data should be stored at the regional/proxy servers. The context is of a system containing multiple heterogeneous proxy servers, one or more shared remote servers (i.e., the information sources, which are distinct from the proxy servers), and multicast delivery to conserve server and network bandwidth. We assume the system uses the recently proposed partitioned dynamic skyscraper delivery technique [11] reviewed in Section 2 . As explained in Section 2.1 , our results are also applicable to other on-demand multicast delivery techniques. Our goal is to achieve broad insights into proxy caching strategies for such systems, rather than to compute the precise cache contents for any particular system. However, the models are highly efficient, and typical solution time is within a few seconds. Thus, the models serve as “prototypes” for cost models that could be employed in actual systems to compute the optimal cache content for a given measured client workload. Most prior work on World Wide Web caching as well as distributed video-on-demand (VOD) architectures has focused on determining on which server(s) each entire file should be allocated, so as to optimize system cost/performance [2] , [4] , [6] , [8]  and  [21] . Other related work has concerned strategies for dynamically caching intervals of data from continuous media files, so as to satisfy one or more requests that arrive close in time to a previous request [24] . This prior work on whole file placement and interval caching has not considered the impact of shared delivery of popular files that is enabled by multicast delivery techniques. In particular, there is a new trade-off between caching the files that are requested most frequently and caching less popular files that have less cost sharing when delivered from the remote server. Furthermore, for segmented multicast delivery techniques such as partitioned dynamic skyscraper, the earlier segments of a file are smaller and have more frequent multicasts (i.e., higher bandwidth requirement per byte) with fewer clients per multicast (i.e., less cost sharing of remote delivery) than the later segments of the file. This leads to another key cost trade-off between caching the entire data for a particular popular file or caching the initial segments of many more files. 1 Heterogeneity in proxy workloads and server capabilities is an important factor because it occurs in practical systems and because it introduces a new tension between (a) tailoring the data stored at each proxy according to the local client workload, and (b) maximizing uniformity in proxy cache contents so as to achieve the greatest possible sharing of remove server multicasts of uncached items. In other words, heterogeneity may cause a divergence between the globally optimal cache configurations, and what is individually optimal for each regional site. A key goal of this work is to create and apply models that provide insight into how this tension is resolved for various kinds of heterogeneity. We consider the above trade-offs in the context of determining which data should be cached on the disks of a regional proxy server. We consider that the popular files on a given multimedia server, such as the popular lectures on a distance education server or the popular shows on an entertainment server, might be expected to remain in high demand for perhaps as long as a good fraction of a day, or longer. Requests for low popularity content on the server will be interspersed with requests for the popular content. Due to disk bandwidth considerations at the proxy server, we believe that it makes sense to semi-statically cache the popular files (i.e., over periods of relatively stable measured access rates), rather than dynamically caching the files in response to individual client requests. The question addressed in this paper is, for a given set of files with specified request rates, which files or portions of the files should be semi-statically cached in order to minimize the delivery cost for the files? Models that include client cost-sharing, as well as server bandwidth requirements for the new multicast delivery techniques, are needed to evaluate the semi-static cache design trade-offs. A previous optimization model [11] reviewed in Section 2.2 determines what data should be stored at homogeneous proxy servers. The model computes the cache content that minimizes a specified delivery cost objective, under specified bandwidth and storage constraints at the proxy, assuming partitioned dynamic skyscraper multicast delivery and the capability to cache all, none, or a specified number of initial segments of each file. We modify this previous model to study systems in which the proxy servers differ with respect to their bandwidth and storage capacities, and with respect to their client workloads. A key challenge is to create models that are efficient to solve and that allow us to gain the desired insights for heterogeneous systems. We have developed two such models, which are described in Section 3 . The models are applied in Section 4 to study proxy server data caching strategies and the impact of heterogeneity. The insights and design principles derived from the results include: • Even in systems with quite strong heterogeneous features, it is often more cost-effective to store the same data at all of the proxy servers , rather than to closely tailor cache content at each proxy according to the local client preferences and server characteristics. • It is often more cost-effective to store just initial segments rather than entire files at the proxy servers. Heterogeneity increases this tendency as compared with the homogeneous system. • When minimum total delivery cost is the objective, a regional proxy server with a distinct client workload can sometimes influence the data cached by the other regional proxy servers in unexpected ways. • When minimum delivery cost for the clients of a given proxy server is the objective, the optimal set of data to store at that server may be quite different than the “socially optimal” set that minimizes total delivery cost to all clients. Cases where the latter two observations apply motivate the use of efficient cost models to guide cache content in actual systems. Section 5 provides the conclusions of this paper and suggests fruitful topics for future research. 2. Background Section 2.1 reviews segmented multicast delivery techniques and the partitioned dynamic skyscraper delivery technique that is assumed in the delivery cost models developed in this paper. Section 2.2 reviews the previous cost model for determining optimal cache content in partitioned dynamic skyscraper systems with homogeneous proxy servers. The new models that will be developed in Section 3 can be applied to homogeneous systems as a special case of the input parameters; thus the detailed equations of the previous homogeneous system model are not repeated in this paper. Throughout the remainder of the paper, a (proxy or remote) server is assumed to have enough disk bandwidth, memory bandwidth, and network i/o bandwidth to support a given number of simultaneous data streams at a specified file delivery rate. For simplicity, all files are assumed to have the same delivery rate, although the caching models can easily be extended to handle multiple file streaming rates. The fixed-rate streams will be referred to as “channels” throughout the paper, and server bandwidth will be measured in units of the (fixed-rate) channels that the server can support.