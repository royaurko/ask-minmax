  Join the Shortest Queue (JSQ) is a popular routing policy for server farms. However, until now all analysis of JSQ has been limited to First-Come-First-Serve (FCFS) server farms, whereas it is known that web server farms are better modeled as Processor Sharing (PS) server farms. We provide the first approximate analysis of JSQ in the PS server farm model for general job-size distributions, obtaining the distribution of queue length at each queue. To do this, we approximate the queue length of each queue in the server farm by a one-dimensional Markov chain, in a novel fashion. We also discover some interesting insensitivity properties of PS server farms with JSQ routing, and discuss the near-optimality of JSQ. Keywords Shortest queue routing ; JSQ ; Processor sharing ; Insensitivity ; Single-queue approximation The server farm is a popular architecture of computing centers. A server farm consists of a front-end router/dispatcher which receives all the incoming requests (jobs), and dispatches each job to one of a collection of servers which do the actual processing. The dispatcher employs a routing policy (also called a “task assignment policy”, or TAP), which decides when and to which server an incoming request should be routed. Server farms afford low cost (many slow servers are cheaper than one fast server), high scalability (it is easy to add and remove servers) and high reliability (failure of individual servers does not bring the whole system down). One of the most important design goals of a server farm is choosing a routing policy which will yield low response times; the response time is the time from the arrival of a request to its completion. We are motivated by web server farm architectures serving static requests. Requests for files (or HTTP pages) arrive at a front-end dispatcher. The dispatcher then immediately routes the request to one of the servers in the farm for processing using a routing policy. It is important that the dispatcher does not hold back the arriving connection request, or the client will time out and possibly submit more requests. The bottleneck resource at a web server is often the uplink bandwidth. This bandwidth is shared by all files requested in a round-robin manner with a small granularity, which is well-modeled by the idealized processor sharing (PS) scheduling policy  [18] . Under PS scheduling, the server splits its capacity equally over the requests it is processing, giving an equal share of its capacity to each of the current requests at every instant of time. We are thus interested in a PS server farm with immediate dispatch. Time sharing servers are beneficial in that they allow “short jobs” to get processed quickly, without being stuck waiting behind long jobs. This is particularly important, since measurements have shown that requested files’ sizes, and the associated service requirements, are highly variable, (e.g., heavy-tailed  [4]  and  [10] ). The Join-the-Shortest-Queue (JSQ) routing policy is the most popular routing policy used in PS server farms today; e.g., it is used in Cisco Local Director, IBM Network Dispatcher, Microsoft Sharepoint and F5 Labs BIG/IP. Under JSQ, an incoming request is routed to the server with the least number of unfinished requests. Thus, JSQ strives to balance load across the servers, reducing the probability of one server having several jobs while another server sits idle. From the point of view of a new arrival, it is a greedy policy for the case of PS servers, because the arrival would prefer sharing a server with as few jobs as possible. We refer to a PS server farm with JSQ routing as a JSQ/PS server farm . 1.2. Model and notation We model the arrival process of jobs as a stationary Poisson process. 1 We assume that there is a single dispatcher (router) and K K identical PS servers with unlimited waiting space, as depicted in Fig. 1 . We assume that routing is immediate using the JSQ policy. Ties are broken by randomly choosing (with equal probabilities) among the servers with the fewest jobs. No jockeying is allowed between the servers (once a job is dispatched to a server, it stays there until completion). A job’s size (service requirement) is defined as the time taken by a job to run on a server in isolation. Fig. 1. 