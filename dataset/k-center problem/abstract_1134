This paper describes a decision theoretic formulation of learning the
graphical structure of a Bayesian Belief Network from data. This framework
subsumes the standard Bayesian approach of choosing the model with the largest
posterior probability as the solution of a decision problem with a 0-1 loss
function and allows the use of more general loss functions able to trade-off
the complexity of the selected model and the error of choosing an
oversimplified model. A new class of loss functions, called disintegrable, is
introduced, to allow the decision problem to match the decomposability of the
graphical model. With this class of loss functions, the optimal solution to the
decision problem can be found using an efficient bottom-up search strategy.