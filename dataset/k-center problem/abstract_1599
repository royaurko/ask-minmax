In this paper, we are concerned with regularized regression problems where
the prior penalty is a piecewise regular/partly smooth gauge whose active
manifold is linear. This encompasses as special cases the Lasso ($\ell^1$
regularizer), the group Lasso ($\ell^1-\ell^2$ regularizer) and the
$\ell^\infty$-norm regularizer penalties. This also includes so-called
analysis-type priors, i.e. composition of the previously mentioned functionals
with linear operators, a typical example being the total variation prior. We
study the sensitivity of {\textit{any}} regularized minimizer to perturbations
of the observations and provide its precise local parameterization. Our main
result shows that, when the observations are outside a set of zero Lebesgue
measure, the predictor moves locally stably along the same linear space as the
observations undergo small perturbations. This local stability is a consequence
of the piecewise regularity of the gauge, which in turn plays a pivotal role to
get a closed form expression for the variations of the predictor w.r.t.
observations which holds almost everywhere. When the perturbation is random
(with an appropriate continuous distribution), this allows us to derive an
unbiased estimator of the degrees of freedom and of the risk of the estimator
prediction. Our results hold true without placing any assumption on the design
matrix, should it be full column rank or not. They generalize those already
known in the literature such as the Lasso problem, the general Lasso problem
(analysis $\ell^1$-penalty), or the group Lasso where existing results for the
latter assume that the design is full column rank.