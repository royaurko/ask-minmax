Let $\cal{N}=\{1,\cdots,n\}$. The entropy function $\bf h$ of a set of $n$
discrete random variables $\{X_i:i\in\cal N\}$ is a $2^n$-dimensional vector
whose entries are ${\bf{h}}({\cal{A}})\triangleq
H(X_{\cal{A}}),\cal{A}\subset{\cal N} $, the (joint) entropies of the subsets
of the set of $n$ random variables with $H(X_\emptyset)=0$ by convention. The
set of all entropy functions for $n$ discrete random variables, denoted by
$\Gamma^*_n$, is called the entropy function region for $n$. Characterization
of $\Gamma^*_n$ and its closure $\overline{\Gamma^*_n}$ are well-known open
problems in information theory. They are important not only because they play
key roles in information theory problems but also they are related to other
subjects in mathematics and physics.
  In this paper, we consider \emph{partition-symmetrical entropy
  functions}. Let $p=\{\cal{N}_1,\cdots, \cal{N}_t\}$ be a $t$-partition of
$\cal N$. An entropy function $\bf h$ is called $p$-symmetrical if for all
${\cal A},{\cal B} \subset {\cal N}$, $\bf{h}({\cal A}) = \bf{h}({\cal B})$
whenever $|{\cal A} \cap {\cal N}_i| = |{\cal B} \cap {\cal N}_i|$, $i = 1,
\cdots,t$. The set of all the $p$-symmetrical entropy functions, denoted by
$\Psi^*_p$, is called $p$-symmetrical entropy function region. We prove that
$\overline{\Psi^*_p}$, the closure of $\Psi^*_p$, is completely characterized
by Shannon-type information inequalities if and only if $p$ is the
$1$-partition or a $2$-partition with one of its blocks being a singleton.
  The characterization of the partition-symmetrical entropy functions can be
useful for solving some information theory and related problems where symmetry
exists in the structure of the problems.
  Keywords: entropy, entropy function, information inequality, polymatroid.