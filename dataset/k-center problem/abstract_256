While machine learning has proven to be a powerful data-driven solution to
many real-life problems, its use in sensitive domains that involve human
subjects has been limited due to privacy concerns. The cryptographic approach
known as "differential privacy" offers provable privacy guarantees. In this
paper we study the learnability under Vapnik's general learning setting with
differential privacy constraint, and reveal some intricate relationships
between privacy, stability and learnability.
  In particular, we show that a problem is privately learnable \emph{if an only
if} there is a private algorithm that asymptotically minimizes the empirical
risk (AERM). This is rather surprising because for non-private learning, AERM
alone is not sufficient for learnability. This result suggests that when
searching for private learning algorithms, we can restrict the search to
algorithms that are AERM. In light of this, we propose a conceptual procedure
that always finds a universally consistent algorithm whenever the problem is
learnable under privacy constraint. We also propose a generic and practical
algorithm and show that under very general conditions it privately learns a
wide class of learning problems.