We consider the deterministic evolution of a time-discretized spiking network
of neurons with connection weights having delays, modeled as a discretized
neural network of the generalized integrate and fire (gIF) type. The purpose is
to study a class of algorithmic methods allowing to calculate the proper
parameters to reproduce exactly a given spike train generated by an hidden
(unknown) neural network. This standard problem is known as NP-hard when delays
are to be calculated. We propose here a reformulation, now expressed as a
Linear-Programming (LP) problem, thus allowing to provide an efficient
resolution. This allows us to "back-engineer" a neural network, i.e. to find
out, given a set of initial conditions, which parameters (i.e., connection
weights in this case), allow to simulate the network spike dynamics. More
precisely we make explicit the fact that the back-engineering of a spike train,
is a Linear (L) problem if the membrane potentials are observed and a LP
problem if only spike times are observed, with a gIF model. Numerical
robustness is discussed. We also explain how it is the use of a generalized IF
neuron model instead of a leaky IF model that allows us to derive this
algorithm. Furthermore, we point out how the L or LP adjustment mechanism is
local to each unit and has the same structure as an "Hebbian" rule. A step
further, this paradigm is easily generalizable to the design of input-output
spike train transformations. This means that we have a practical method to
"program" a spiking network, i.e. find a set of parameters allowing us to
exactly reproduce the network output, given an input. Numerical verifications
and illustrations are provided.