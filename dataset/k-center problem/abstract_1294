Context-Based Information Retrieval is recently modelled as an exploration/
exploitation trade-off (exr/exp) problem, where the system has to choose
between maximizing its expected rewards dealing with its current knowledge
(exploitation) and learning more about the unknown user's preferences to
improve its knowledge (exploration). This problem has been addressed by the
reinforcement learning community but they do not consider the risk level of the
current user's situation, where it may be dangerous to explore the
non-top-ranked documents the user may not desire in his/her current situation
if the risk level is high. We introduce in this paper an algorithm named
CBIR-R-greedy that considers the risk level of the user's situation to
adaptively balance between exr and exp.