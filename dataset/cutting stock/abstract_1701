This presentation's Part 3 studies the evolutionary information processes and
regularities of evolution dynamics, evaluated by an entropy functional (EF) of
a random field (modeled by a diffusion information process) and an
informational path functional (IPF) on trajectories of the related dynamic
process (Lerner 2012). The integral information measure on the process'
trajectories accumulates and encodes inner connections and dependencies between
the information states, and contains more information than a sum of Shannon's
entropies, which measures and encodes each process's states separately. Cutting
off the process' measured information under action of impulse controls (Lerner
2012a), extracts and reveals hidden information, covering the states'
correlations in a multi-dimensional random process, and implements the EF-IPF
minimax variation principle (VP). The approach models an information observer
(Lerner 2012b)-as an extractor of such information, which is able to convert
the collected information of the random process in the information dynamic
process and organize it in the hierarchical information network (IN), Part2
(Lerner, 2012c). The IN's highest level of the structural hierarchy, measured
by a maximal quantity and quality of the accumulated cooperative information,
evaluates the observer's intelligence level, associated with its ability to
recognize and build such structure of a meaningful hidden information. The
considered evolution of optimal extraction, assembling, cooperation, and
organization of this information in the IN, satisfying the VP, creates the
phenomena of an evolving observer's intelligence. The requirements of
preserving the evolutionary hierarchy impose the restrictions that limit the
observer's intelligence level in the IN. The cooperative information geometry,
evolving under observations, limits the size and volumes of a particular
observer.