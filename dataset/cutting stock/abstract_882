This paper considers the problem of learning, from samples, the dependency
structure of a system of linear stochastic differential equations, when some of
the variables are latent. In particular, we observe the time evolution of some
variables, and never observe other variables; from this, we would like to find
the dependency structure between the observed variables - separating out the
spurious interactions caused by the (marginalizing out of the) latent
variables' time series. We develop a new method, based on convex optimization,
to do so in the case when the number of latent variables is smaller than the
number of observed ones. For the case when the dependency structure between the
observed variables is sparse, we theoretically establish a high-dimensional
scaling result for structure recovery. We verify our theoretical result with
both synthetic and real data (from the stock market).