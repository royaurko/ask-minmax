The vast amount of geo-tagged social images has attracted great attention in
research of predicting location using the plentiful content of images, such as
visual content and textual description. Most of the existing researches use the
text-based or vision-based method to predict location. There still exists a
problem: how to effectively exploit the correlation between different types of
content as well as their geographical distributions for location prediction. In
this paper, we propose to predict image location by learning the latent
relation between geographical location and multiple types of image content. In
particularly, we propose a geographical topic model GTMI (geographical topic
model of social image) to integrate multiple types of image content as well as
the geographical distributions, In GTMI, image topic is modeled on both text
vocabulary and visual feature. Each region has its own distribution over topics
and hence has its own language model and vision pattern. The location of a new
image is estimated based on the joint probability of image content and
similarity measure on topic distribution between images. Experiment results
demonstrate the performance of location prediction based on GTMI.