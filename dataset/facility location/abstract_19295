Classical novae are explosive phenomena that take place in stellar binary
systems. They are powered by mass transfer from a low-mass, main sequence star
onto a white dwarf. The material piles up under degenerate conditions and a
thermonuclear runaway ensues. The energy released by the suite of nuclear
processes operating at the envelope heats the material up to peak temperatures
of ~ (1 - 4) \times 108 K. During these events, about 10-4 - 10-5 M\odot,
enriched in CNO and other intermediate-mass elements, are ejected into the
interstellar medium. To account for the gross observational properties of
classical novae (in particular, a metallicity enhancement in the ejecta above
solar values), numerical models assume mixing between the (solar-like) material
transferred from the companion and the outermost layers (CO- or ONe-rich) of
the underlying white dwarf. The nature of the mixing mechanism that operates at
the core-envelope interface has puzzled stellar modelers for about 40 years.
Here we investigate the role of Kelvin-Helmholtz instabilities as a natural
mechanism for self-enrichment of the accreted envelope with core material. The
feasibility of this mechanism is studied by means of the multidimensional code
FLASH. Here, we present a series of 9 numerical simulations perfomed in two
dimensions aimed at testing the possible influence of the initial perturbation
(duration, strength, location, and size), the resolution adopted, or the size
of the computational domain on the results. We show that results do not depend
substantially on the specific choice of these parameters, demonstrating that
Kelvin- Helmholtz instabilities can naturally lead to self-enrichment of the
accreted envelope with core material, at levels that agree with observations.