Line ratios in "fir" triplets of helium-like ions have proven to be a
powerful diagnostic of conditions in X-ray emitting gas surrounding massive
stars. Recent observations indicate that these ratios can be variable with
time.
  The possible causes of variation in line ratios are limited: changes in the
radiation field or changes in density, and changes in mass-loss or geometry. In
this paper, we investigate the ability of changes in the radiation field to
induce variability in the ratio R=f/i.
  To isolate the radiative effect, we use a heuristic model of temperature and
radius changes in variable stars in the B and O range with low-density,
steady-state winds. We model the changes in emissivity of X-ray emitting gas
close to the star due to differences in level-pumping from available UV photons
at the location of the gas.
  We find that under these conditions, variability in R is dominated by the
stellar temperature. Although the relative amplitude of variability is roughly
comparable for most lines at most temperatures, detectable variations are
limited to a few lines for each spectral type. We predict that variable values
in R due to stellar variability must follow predictable trends found in our
simulations.
  Our model uses radial pulsations as a mode of stellar variability that
maximizes the amplitude of variation in R. This model is robust enough to show
which ions will provide the best opportunity for observing variability in the
f/i ratio at different stellar temperatures, and the correlation of that
variability with other observable parameters. In real systems, the effects
would be more complex than in our model, with differences in phase and
suppressed amplitude in the presence of non-radial pulsations. This suggests
that changes in R across many lines concurrently are not likely to be produced
by a variable radiation field.