Dust grains grow their sizes in the interstellar clouds (especially in
molecular clouds) by accretion and coagulation. Here we model and test these
processes by examining the consistency with the observed variation of the
extinction curves in the Milky Way. We find that, if we simply use the
parameters used in previous studies, the model fails to explain the flattening
of far-UV extinction curve for large $R_V$ (flatness of optical extinction
curve) and the existence of carbon bump even in flat extinction curves. This
discrepancy is resolved by adopting a `tuned' model, in which coagulation of
carbonaceous dust is less efficient (by a factor of 2) and that of silicate is
more efficient with the coagulation threshold removed. The tuned model is also
consistent with the relation between silicon depletion (indicator of accretion)
and $R_V$ if the duration of accretion and coagulation is >100(n_H/10^3
cm^{-3})^{-1} Myr, where n_H is the number density of hydrogen nuclei in the
cloud. We also examine the relations between each of the extinction curve
features (UV slope, far-UV curvature, and carbon bump strength) and $R_V$. The
correlation between UV slope and $R_V$, which is the strongest among the three
correlations, is well reproduced by the tuned model. For far-UV curvature and
carbon bump strength, the observational data are located between the tuned
model and the original model without tuning, implying that the large scatters
in the observational data can be explained by the sensitive response to the
coagulation efficiency. The overall success of the tuned model indicates that
accretion and coagulation are promising mechanisms of producing the variation
of extinction curves in the Milky Way, although we do not exclude possibilities
of other dust-processing mechanisms changing extinction curves.