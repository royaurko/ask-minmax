We analyze H$\alpha$ images and long-slit spectra of samples of normal and
starburst galaxies to better understand the nature of the diffuse,
low-surface-brightness gas in these galaxies. We find that in both samples
there is a strong inverse correlation between the H$\alpha$ surface-brightness
($\Sigma_{H\alpha}$) and the [SII]/H$\alpha$ line ratio at a given location in
the galaxy. However, the correlation for the starbursts is offset brightward by
an order-of-magnitude in H$\alpha$ surface-brightness at a given line ratio. In
contrast, we find that all the galaxies (starburst and normal alike) define a
universal relation between line ratio and the relative H$\alpha$ surface
brightness ($\Sigma_{H\alpha}/\Sigma_e$, where $\Sigma_e$ is the mean
H$\alpha$ surface brightness within the galaxy half-light radius). We show that
such a universal correlation is a natural outcome of a model in which the DIM
is photoionized gas that has a characteristic thermal pressure ($P$) that is
proportional to the mean rate of star-formation per unit area in the galaxy
($\Sigma_{SFR}$). Good quantitative agreement with the data follows if we
require the constant of proportionality to be consistent with the values of $P$
and $\Sigma_{SFR}$ in the local disk of the Milky Way. Such a scaling between
$P$ and $\Sigma_{SFR}$ may arise either because feedback from massive stars
heats the ISM or because $\Sigma_{SFR}$ is determined (or limited) by the mean
gas pressure.