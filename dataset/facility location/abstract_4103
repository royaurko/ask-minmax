Nowadays, locating software components responsible for observed failures is
one of the most expensive and error-prone tasks in the software development
process. To improve the debugging process efficiency, some effort was already
made to automatically assist the detection and location of software faults.
This led to the creation of statistical debugging tools such as Tarantula,
Zoltar and GZoltar. These tools use information gathered from code coverage
data and the result of test executions to return a list of potential faulty
locations. Although helpful, fault localization tools have some scaling
problems because of the fine-grained coverage data they need to perform the
fault localization analysis. Instrumentation overhead, which in some cases can
be as high as 50% is the main cause for their inefficiency. This thesis
proposes a new approach to this problem, avoiding as much as possible the high
level of coverage detail, while still using the proven techniques these fault
localization tools employ. This approach, named DCC, consists of using a
coarser initial instrumentation, obtaining only coverage traces for large
components. Then, the instrumentation detail of certain components is
progressively increased, based on the intermediate results provided by the same
techniques employed in current fault localization tools. To assess the validity
of our proposed approach, an empirical evaluation was performed, injecting
faults in four real-world software projects. The empirical evaluation
demonstrates that the DCC approach reduces the execution overhead that exists
in spectrum-based fault localization, and even presents a more concise
potential fault ranking to the user. We have observed execution time reductions
of 27% on average and diagnostic report size reductions of 63% on average.