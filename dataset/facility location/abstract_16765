Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for
the acquisition of sparse or compressible signals that can be well approximated
by just K << N elements from an N-dimensional basis. Instead of taking periodic
samples, CS measures inner products with M < N random vectors and then recovers
the signal via a sparsity-seeking optimization or greedy algorithm. Standard CS
dictates that robust signal recovery is possible from M = O(K log(N/K))
measurements. It is possible to substantially decrease M without sacrificing
robustness by leveraging more realistic signal models that go beyond simple
sparsity and compressibility by including structural dependencies between the
values and locations of the signal coefficients. This paper introduces a
model-based CS theory that parallels the conventional theory and provides
concrete guidelines on how to create model-based recovery algorithms with
provable performance guarantees. A highlight is the introduction of a new class
of structured compressible signals along with a new sufficient condition for
robust structured compressible signal recovery that we dub the restricted
amplification property, which is the natural counterpart to the restricted
isometry property of conventional CS. Two examples integrate two relevant
signal models - wavelet trees and block sparsity - into two state-of-the-art CS
recovery algorithms and prove that they offer robust recovery from just M=O(K)
measurements. Extensive numerical simulations demonstrate the validity and
applicability of our new theory and algorithms.