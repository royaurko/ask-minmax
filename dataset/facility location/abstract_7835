We conduct an empirical study to test the ability of convolutional neural
networks (CNNs) to reduce the effects of nuisance transformations of the input
data, such as location, scale and aspect ratio. We isolate factors by adopting
a common convolutional architecture either deployed globally on the image to
compute class posterior distributions, or restricted locally to compute class
conditional distributions given location, scale and aspect ratios of bounding
boxes determined by proposal heuristics. As explained in the paper, averaging
the latter should in principle yield performance inferior to proper
marginalization. Empirical tests yield the converse, however, leading us to
conclude that - at the current level of complexity of convolutional
architectures and scale of the data sets used to train them - CNNs are not very
effective at marginalizing nuisance variability. We also quantify the effects
of context on the overall classification task and its impact on the performance
of CNNs, and propose improved sampling techniques for heuristic proposal
schemes that improve end-to-end performance to state-of-the-art levels. We test
our hypothesis on classification task using the ImageNet Challenge benchmark,
on detection and on wide-baseline matching using the Oxford and Fischer
matching datasets.