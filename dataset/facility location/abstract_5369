We use a sample of 19 Gamma Ray Bursts (GRBs) that exhibit single-peaked
optical light curves to test the standard fireball model by investigating the
relationship between the time of the onset of the afterglow and the temporal
rising index. Our sample includes GRBs and X-ray flashes for which we derive a
wide range of initial Lorentz factors ($40 < \Gamma < 450$). Using plausible
model parameters the typical frequency of the forward shock is expected to lie
close to the optical band; within this low typical frequency framework, we use
the optical data to constrain $\epsilon_e$ and show that values derived from
the early time light curve properties are consistent with published typical
values derived from other afterglow studies. We produce expected radio light
curves by predicting the temporal evolution of the expected radio emission from
forward and reverse shock components, including synchrotron self-absorption
effects at early time. Although a number of the GRBs in this sample do not have
published radio measurements, we demonstrate the effectiveness of this method
in the case of {\it Swift} GRB 090313, for which millimetric and centrimetric
observations were available, and conclude that future detections of
reverse-shock radio flares with new radio facilities such as the EVLA and ALMA
will test the low frequency model and provide constraints on magnetic models.