We study Bragg scattering at 1D optical lattices. Cold atoms are confined by
the optical dipole force at the antinodes of a standing wave generated inside a
laser-driven high-finesse cavity. The atoms arrange themselves into a chain of
pancake-shaped layers located at the antinodes of the standing wave. Laser
light incident on this chain is partially Bragg-reflected. We observe an
angular dependence of this Bragg reflection which is different to what is known
from crystalline solids. In solids the scattering layers can be taken to be
infinitely spread (3D limit). This is not generally true for an optical lattice
consistent of a 1D linear chain of point-like scattering sites. By an explicit
structure factor calculation we derive a generalized Bragg condition, which is
valid in the intermediate regime. This enables us to determine the aspect ratio
of the atomic lattice from the angular dependance of the Bragg scattered light.