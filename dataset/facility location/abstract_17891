In an effort to better understand meaning from natural language texts, we
explore methods aimed at organizing lexical objects into contexts. A number of
these methods for organization fall into a family defined by word ordering.
Unlike demographic or spatial partitions of data, these collocation models are
of special importance for their universal applicability. While we are
interested here in text and have framed our treatment appropriately, our work
is potentially applicable to other areas of research (e.g., speech, genomics,
and mobility patterns) where one has ordered categorical data, (e.g., sounds,
genes, and locations). Our approach focuses on the phrase (whether word or
larger) as the primary meaning-bearing lexical unit and object of study. To do
so, we employ our previously developed framework for generating word-conserving
phrase-frequency data. Upon training our model with the Wiktionary---an
extensive, online, collaborative, and open-source dictionary that contains over
100,000 phrasal-definitions---we develop highly effective filters for the
identification of meaningful, missing phrase-entries. With our predictions we
then engage the editorial community of the Wiktionary and propose short lists
of potential missing entries for definition, developing a breakthrough, lexical
extraction technique, and expanding our knowledge of the defined English
lexicon of phrases.