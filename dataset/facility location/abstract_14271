Recent technology of visual lifelogging consists in acquiring images that
capture our everyday experience by wearing a camera over long periods of time.
The collected data offer a large potential of mining and inferring knowledge
about how people live their lives and for analyzing the story behind these
data. This opens new opportunities for a large amount of potential applications
ranging from health-care, security or leisure, to quantified self.
  However, extracting and locating relevant content from a huge collection of
personal data triggers major challenges that strongly limit their utility and
usability in practice. Furthermore, due to the first-person view nature of
lifelogging data and to the technical specifications of the imaging sensor,
many available Computer Vision techniques become inadequate, demanding full or
partial re-formulation. This review aims to provide a comprehensive summary of
what is currently available and what would be needed from a Computer Vision
perspective to complete the building blocks for automatic personal
storytelling, being a suitable reference for all Computer Vision scientists
interested in Egocentric vision in general, and in Storytelling through visual
lifelogging.