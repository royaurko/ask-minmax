Recently discovered scattered light at 3-5 $\mu$m from low-mass cores
(so-called "coreshine") reveals the presence of grains around 1 $\mu$m, which
is larger than the grains found in the low-density interstellar medium. But
only about half of the 100+ cores investigated so far show the effect. This
prompts further studies on the origin of this detection rate. From the 3D
continuum radiative transfer equation, we derive the expected scattered light
intensity from a core placed in an arbitrary direction seen from Earth. We use
the approximation of single scattering, consider extinction up to 2nd-order
Taylor approximation, and neglect spatial gradients in the dust size
distribution. The impact of the directional characteristics of the scattering
on the detection of scattered light from cores is calculated for a given grain
size distribution, and local effects like additional radiation field components
are discussed. The surface brightness profiles of a core with a 1D density
profile are calculated for various Galactic locations, and the results are
compared to the approximate detection limits. We find that for optically thin
radiation and a constant size distribution, a simple limit for detecting
scattered light from a low-mass core can be derived that holds for grains with
sizes smaller than 0.5 $\mu$m. The extinction by the core prohibits detection
in bright parts of the Galactic plane, especially near the Galactic center. For
scattered light received from low-mass cores with grain sizes beyond 0.5
$\mu$m, the directional characteristics of the scattering favors the detection
of scattered light above and below the Galactic center, and to some extent near
the Galactic anti-center. We identify the local incident radiation field as the
major unknown causing deviations from this simple scheme.