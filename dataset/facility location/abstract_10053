Static software checking tools are useful as an additional automated software
inspection step that can easily be integrated in the development cycle and
assist in creating secure, reliable and high quality code. However, an often
quoted disadvantage of these tools is that they generate an overly large number
of warnings, including many false positives due to the approximate analysis
techniques. This information overload effectively limits their usefulness.
  In this paper we present ELAN, a technique that helps the user prioritize the
information generated by a software inspection tool, based on a demand-driven
computation of the likelihood that execution reaches the locations for which
warnings are reported. This analysis is orthogonal to other prioritization
techniques known from literature, such as severity levels and statistical
analysis to reduce false positives. We evaluate feasibility of our technique
using a number of case studies and assess the quality of our predictions by
comparing them to actual values obtained by dynamic profiling.