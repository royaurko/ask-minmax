We discuss an attentional model for simultaneous object tracking and
recognition that is driven by gaze data. Motivated by theories of perception,
the model consists of two interacting pathways: identity and control, intended
to mirror the what and where pathways in neuroscience models. The identity
pathway models object appearance and performs classification using deep
(factored)-Restricted Boltzmann Machines. At each point in time the
observations consist of foveated images, with decaying resolution toward the
periphery of the gaze. The control pathway models the location, orientation,
scale and speed of the attended object. The posterior distribution of these
states is estimated with particle filtering. Deeper in the control pathway, we
encounter an attentional mechanism that learns to select gazes so as to
minimize tracking uncertainty. Unlike in our previous work, we introduce gaze
selection strategies which operate in the presence of partial information and
on a continuous action space. We show that a straightforward extension of the
existing approach to the partial information setting results in poor
performance, and we propose an alternative method based on modeling the reward
surface as a Gaussian Process. This approach gives good performance in the
presence of partial information and allows us to expand the action space from a
small, discrete set of fixation points to a continuous domain.