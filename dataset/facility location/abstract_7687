Video object segmentation is a challenging problem due to the presence of
deformable, connected, and articulated objects, intra- and inter-object
occlusions, object motion, and poor lighting. Some of these challenges call for
object models that can locate a desired object and separate it from its
surrounding background, even when both share similar colors and textures. In
this work, we extend a fuzzy object model, named cloud system model (CSM), to
handle video segmentation, and evaluate it for body pose estimation of toddlers
at risk of autism. CSM has been successfully used to model the parts of the
brain (cerebrum, left and right brain hemispheres, and cerebellum) in order to
automatically locate and separate them from each other, the connected brain
stem, and the background in 3D MR-images. In our case, the objects are
articulated parts (2D projections) of the human body, which can deform, cause
self-occlusions, and move along the video. The proposed CSM extension handles
articulation by connecting the individual clouds, body parts, of the system
using a 2D stickman model. The stickman representation naturally allows us to
extract 2D body pose measures of arm asymmetry patterns during unsupported gait
of toddlers, a possible behavioral marker of autism. The results show that our
method can provide insightful knowledge to assist the specialist's observations
during real in-clinic assessments.