Programs to observe evolution in the Mbh-sigma or Mbh-L relations typically
compare black-hole masses, Mbh, in high-redshift galaxies selected by nuclear
activity to Mbh in local galaxies selected by luminosity L, or stellar velocity
dispersion sigma. Because AGN luminosity is likely to depend on Mbh, selection
effects are different for high-redshift and local samples, potentially
producing a false signal of evolution. This bias arises because cosmic scatter
in the Mbh-sigma and Mbh-L relations means that the mean log(L) or log(sigma)
among galaxies that host a black hole of given Mbh, may be substantially
different than the log(L) or log(sigma) obtained from inverting the Mbh-L or
Mbh-sigma relations for the same nominal Mbh. The bias is particularly strong
at high Mbh, where the luminosity and dispersion functions of galaxies are
falling rapidly. The most massive black holes occur more often as rare outliers
in galaxies of modest mass than in the even rarer high-mass galaxies, which
would otherwise be the sole location of such black holes in the absence of
cosmic scatter. Because of this bias, Mbh will typically appear to be too large
in the distant sample for a given L or sigma. For the largest black holes and
the largest plausible cosmic scatter, the bias can reach a factor of 3 in Mbh
for the Mbh-sigma relation and a factor of 9 for the Mbh-L relation.
Unfortunately, the actual cosmic scatter is not known well enough to correct
for the bias. Measuring evolution of the Mbh and galaxy property relations
requires object selection to be precisely defined and exactly the same at all
redshifts.