Gesture recognition is mainly apprehensive on analyzing the functionality of
human wits. The main goal of gesture recognition is to create a system which
can recognize specific human gestures and use them to convey information or for
device control. Hand gestures provide a separate complementary modality to
speech for expressing ones ideas. Information associated with hand gestures in
a conversation is degree,discourse structure, spatial and temporal structure.
The approaches present can be mainly divided into Data-Glove Based and Vision
Based approaches. An important face feature point is the nose tip. Since nose
is the highest protruding point from the face. Besides that, it is not affected
by facial expressions.Another important function of the nose is that it is able
to indicate the head pose. Knowledge of the nose location will enable us to
align an unknown 3D face with those in a face database. Eye detection is
divided into eye position detection and eye contour detection. Existing works
in eye detection can be classified into two major categories: traditional
image-based passive approaches and the active IR based approaches. The former
uses intensity and shape of eyes for detection and the latter works on the
assumption that eyes have a reflection under near IR illumination and produce
bright/dark pupil effect. The traditional methods can be broadly classified
into three categories: template based methods,appearance based methods and
feature based methods. The purpose of this paper is to compare various human
Gesture recognition systems for interfacing machines directly to human wits
without any corporeal media in an ambient environment.