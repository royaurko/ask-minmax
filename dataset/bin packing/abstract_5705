In this paper we examine the contribution of galaxies with different infrared
(IR) spectral energy distributions (SEDs) to the comoving infrared luminosity
density, a proxy for the comoving star formation rate (SFR) density. We
characterise galaxies as having either a cold or hot IR SED depending upon
whether the rest-frame wavelength of their peak IR energy output is above or
below 90um. Our work is based on a far-IR selected sample both in the local
Universe and at high redshift, the former consisting of IRAS 60um-selected
galaxies at z<0.07 and the latter of Spitzer 70um selected galaxies across
0.1<z<1. We find that the total IR luminosity densities for each
redshift/luminosity bin agree well with results derived from other deep
mid/far-IR surveys. At z<0.07 we observe the previously known results: that
moderate luminosity galaxies (L_IR<10^11 Lsun) dominate the total luminosity
density and that the fraction of cold galaxies decreases with increasing
luminosity, becoming negligible at the highest luminosities. Conversely, above
z=0.1 we find that luminous IR galaxies (L_IR>10^11 Lsun), the majority of
which are cold, dominate the IR luminosity density. We therefore infer that
cold galaxies dominate the IR luminosity density across the whole 0<z<1 range,
hence appear to be the main driver behind the increase in SFR density up to z~1
whereas local luminous galaxies are not, on the whole, representative of the
high redshift population.