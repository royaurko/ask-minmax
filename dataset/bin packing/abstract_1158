This paper investigates a class of algorithms for numerical integration of a
function in d dimensions over a compact domain by Monte Carlo methods. We
construct a histogram approximation to the function using a partition of the
integration domain into a set of bins specified by some parameters. We then
consider two adaptations; the first is to subtract the histogram approximation,
whose integral we may easily evaluate explicitly, from the function and
integrate the difference using Monte Carlo; the second is to modify the bin
parameters in order to make the variance of the Monte Carlo estimate of the
integral the same for all bins. This allows us to use Student's t-test as a
trigger for rebinning, which we claim is more stable than the \chi-squared test
that is commonly used for this purpose. We provide a program that we have used
to study the algorithm for the case where the histogram is represented as a
product of one-dimensional histograms. We discuss the assumptions and
approximations made, as well as giving a pedagogical discussion of the myriad
ways in which the results of any such Monte Carlo integration program can be
misleading.