First-order methods play a central role in large-scale convex optimization.
Even though many variations exist, each suited to a particular problem form,
almost all such methods fundamentally rely on two types of algorithmic steps
and two corresponding types of analysis: gradient-descent steps, which yield
primal progress, and mirror-descent steps, which yield dual progress. In this
paper, we observe that the performances of these two types of step are
complementary, so that faster algorithms can be designed by linearly coupling
the two steps.
  In particular, we obtain a simple accelerated gradient method for the class
of smooth convex optimization problems. The first such method was proposed by
Nesterov back to 1983, but to the best of our knowledge, the proof of the fast
convergence of accelerated gradient methods has not found a clear
interpretation and is still regarded by many as crucially relying on "algebraic
tricks". We apply our novel insights to construct a new accelerated gradient
method as a natural linear coupling of gradient descent and mirror descent and
to write its proof of convergence as a simple combination of the convergence
analyses of the two underlying descent steps.
  We believe that the complementary view and the linear coupling technique in
this paper will prove very useful in the design of first-order methods as it
allows us to design fast algorithms in a conceptually easier way. For instance,
our technique greatly facilitates the recent breakthroughs in solving packing
and covering linear programs [AO14, AO15].