The lag-luminosity relation for gamma-ray bursts (GRBs) is an
anti-correlation between the time lag, tau_lag, which represents the delay
between the arrival of hard and soft photons, and the isotropic peak
luminosity, L. In this paper, we use a sample of 43 Swift bursts to investigate
whether this relation depends on redshift. Both the z-correction and the
k-correction are taken into account. Our analysis consists of binning the data
in redshift, z, then applying a fit of the form: log(L) = A +
Blog(tau_lag0/<tau_lag0>) for each bin, where tau_lag0 is the time-lag in the
burst's source frame, and <tau_lag0> is the corresponding mean value for the
entire sample. The goal is to see whether the two fitting parameters, A and B,
evolve in a systematic way with z. Our results indicate that both the
normalization, A, and the slope, B, seem to vary in a systematic way with
redshift. We note that although good best-fits were obtained, with reasonable
values for both the linear regression coefficient, r, and the reduced
chi-squared, the data showed large scatter. Also, the number of GRBs in the
sample studied is not large, and thus our conclusions are only tentative at
this point. A flat universe with omega_M = 0.27, omega_lambda = 0.73, and a
Hubble constant, H_0 = 70 km s-1 Mpc-1 is assumed.