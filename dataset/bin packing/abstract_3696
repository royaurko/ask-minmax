The standard method of measuring the galaxy pairwise velocity dispersion on
small scales is heavily weighted by the densest regions in a way that is
difficult to calibrate. We propose a new statistic which measures the
small-scale velocity dispersion as an explicit function of density. Computing
this statistic for a volume-limited subsample of the Optical Redshift Survey,
we find that the small-scale velocity dispersion rises from 220 to 760 km/s as
density increases. We calculate this statistic for a series of mock catalogs
drawn from a hydrodynamic simulation of an \Omega h = 0.5 Cold Dark Matter
universe (standard CDM), and find that the observed velocity distribution lies
~1 \sigma below the simulations in each of eight density bins, formally ruling
out this model at the 7.4 \sigma level, quantifying the well-known problem that
this model produces too high a velocity dispersion. This comparison is
insensitive to the normalization of the power spectrum, although it is quite
sensitive to the density and velocity bias of galaxies relative to dark matter
on small scales. (abridged)