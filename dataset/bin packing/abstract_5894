We present a detailed comparison between the 2-10 keV hard X-ray and infrared
(IR) luminosity function (LF) of active galactic nuclei (AGN). The composite
X-ray to IR spectral energy distributions (SEDs) of AGN used for connecting the
hard X-ray LF (HXLF) and IR LF (IRLF) are modeled with a simple but well tested
torus model based on the radiative transfer and photoionization code CLOUDY.
Four observational determinations of the evolution of 2-10 keV HXLF and six
evolution models of the obscured type-2 AGN fraction ($f_2$) have been
considered. The 8.0 and 15 \micron LFs for the total, unobscured type-1 and
obscured type-2 AGN are predicted from the HXLFs, and then compared with the
measurements currently available. We find that the IRLFs predicted from HXLFs
tend to underestimate the number of the most IR-luminous AGN. This is
independent of the choices of HXLF and $f_2$, and even more obvious for the
HXLFs recently measured. We show that the discrepancy between the HXLFs and
IRLFs can be largely resolved when the anticorrelation between the UV to X-ray
slope $\alpha_{\mathrm{ox}}$ and UV luminosity $L_{\rm UV}$ is appropriately
considered. We also discuss other possible explanations for the discrepancy,
such as the missing population of Compton-thick AGN and possible contribution
of star-formation in the host to the mid-IR. Meanwhile, we find that the HXLFs
and IRLFs of AGN can be more consistent with each other if the obscuration
mechanisms of quasars and Seyferts are assumed to be different, corresponding
to their different triggering and fueling mechanisms. More accurate
measurements of the IRLFs of AGN, especially that determined at smaller
redshift bins and more accurately separated to that for type-1 and type-2, are
very helpful for clarifying these interesting issues.