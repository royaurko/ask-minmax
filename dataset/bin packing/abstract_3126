The area of a spherical region can be easily measured by considering which
sampling points of a lattice are located inside or outside the region. This
point-counting technique is frequently used for measuring the Earth coverage of
satellite constellations, employing a latitude-longitude lattice. This paper
analyzes the numerical errors of such measurements, and shows that they could
be greatly reduced if the Fibonacci lattice were used instead. The latter is a
mathematical idealization of natural patterns with optimal packing, where the
area represented by each point is almost identical. Using the Fibonacci lattice
would reduce the root mean squared error by at least 40%. If, as is commonly
the case, around a million lattice points are used, the maximum error would be
an order of magnitude smaller.