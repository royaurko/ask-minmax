Hyperspectral unmixing (HU) plays a fundamental role in a wide range of
hyperspectral applications. It is still challenging due to the common presence
of outlier channels and the large solution space. To address the above two
issues, we propose a novel model by emphasizing both robust representation and
learning-based sparsity. Specifically, we apply the $\ell_{2,1}$-norm to
measure the representation error, preventing outlier channels from dominating
our objective. In this way, the side effects of outlier channels are greatly
relieved. Besides, we observe that the mixed level of each pixel varies over
image grids. Based on this observation, we exploit a learning-based sparsity
method to simultaneously learn the HU results and a sparse guidance map. Via
this guidance map, the sparsity constraint in the $\ell_{p}\!\left(\!0\!<\!
p\!\leq\!1\right)$-norm is adaptively imposed according to the learnt mixed
level of each pixel. Compared with state-of-the-art methods, our model is
better suited to the real situation, thus expected to achieve better HU
results. The resulted objective is highly non-convex and non-smooth, and so it
is hard to optimize. As a profound theoretical contribution, we propose an
efficient algorithm to solve it. Meanwhile, the convergence proof and the
computational complexity analysis are systematically provided. Extensive
evaluations verify that our method is highly promising for the HU task---it
achieves very accurate guidance maps and much better HU results compared with
state-of-the-art methods.