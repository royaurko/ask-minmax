We propose a practical method to calculate Zernike aberrations from analysis
of a single long-exposure defocused stellar image. It consists in fitting the
aberration coefficients and seeing blur directly to a realistic image binned
into detector pixels. This "donut" method is different from curvature sensing
in that it does not make the usual approximation of linearity. We calculate the
sensitivity of this technique to detector and photon noise and determine
optimal parameters for some representative cases. Aliasing of high-order
un-modeled aberrations is evaluated and shown to be similar to a low-order
Shack-Hartmann sensor. The method has been tested with real data from the SOAR
and Blanco 4m telescopes.