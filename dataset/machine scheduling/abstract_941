The goal of machine learning is to provide solutions which are trained by
data or by experience coming from the environment. Many training algorithms
exist and some brilliant successes were achieved. But even in structured
environments for machine learning (e.g. data mining or board games), most
applications beyond the level of toy problems need careful hand-tuning or human
ingenuity (i.e. detection of interesting patterns) or both. We discuss several
aspects how self-configuration can help to alleviate these problems. One aspect
is the self-configuration by tuning of algorithms, where recent advances have
been made in the area of SPO (Sequen- tial Parameter Optimization). Another
aspect is the self-configuration by pattern detection or feature construction.
Forming multiple features (e.g. random boolean functions) and using algorithms
(e.g. random forests) which easily digest many fea- tures can largely increase
learning speed. However, a full-fledged theory of feature construction is not
yet available and forms a current barrier in machine learning. We discuss
several ideas for systematic inclusion of feature construction. This may lead
to partly self-configuring machine learning solutions which show robustness,
flexibility, and fast learning in potentially changing environments.