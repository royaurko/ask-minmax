The aim of this paper is to undertake an experimental investigation of the
trade-offs between program-size and time computational complexity. The
investigation includes an exhaustive exploration and systematic study of the
functions computed by the set of all 2-color Turing machines with 2, 3 and 4
states--denoted by (n,2) with n the number of states--with particular attention
to the runtimes and space usages when the machines have access to larger
resources (more states). We report that the average runtime of Turing machines
computing a function almost surely increases as a function of the number of
states, indicating that machines not terminating (almost) immediately tend to
occupy all the resources at hand. We calculated all time complexity classes to
which the algorithms computing the functions found in both (2,2) and (3,2)
belong to, and made a comparison among these classes. For a selection of
functions the comparison was extended to (4,2). Our study revealed various
structures in the micro-cosmos of small Turing machines. Most notably we
observed "phase-transitions" in the halting-probability distribution that we
explain. Moreover, it is observed that short initial segments fully define a
function computed by a Turing machine.