Currently, many machine learning algorithms contain lots of iterations. When
it comes to existing large-scale distributed systems, some slave nodes may
break down or have lower efficiency. Therefore traditional machine learning
algorithm may fail because of the instability of distributed system.We presents
a hybrid approach which not only own a high fault-tolerant but also achieve a
balance of performance and efficiency.For each iteration, the result of slow
machines will be abandoned. Then, we discuss the relationship between accuracy
and abandon rate. Next we debate the convergence speed of this process.
Finally, our experiments demonstrate our idea can dramatically reduce
calculation time and be used in many platforms.