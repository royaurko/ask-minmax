We design a dynamic rate scheduling policy of Markov type via the solution (a
social optimal Nash equilibrium point) to a utility-maximization problem over a
randomly evolving capacity set for a class of generalized processor-sharing
queues living in a random environment, whose job arrivals to each queue follow
a doubly stochastic renewal process (DSRP). Both the random environment and the
random arrival rate of each DSRP are driven by a finite state continuous time
Markov chain (FS-CTMC). Whereas the scheduling policy optimizes in a greedy
fashion with respect to each queue and environmental state and since the
closed-form solution for the performance of such a queueing system under the
policy is difficult to obtain, we establish a reflecting diffusion with
regime-switching (RDRS) model for its measures of performance and justify its
asymptotic optimality through deriving the stochastic fluid and diffusion
limits for the corresponding system under heavy traffic and identifying a cost
function related to the utility function, which is minimized through minimizing
the workload process in the diffusion limit. More importantly, our queueing
model includes both J-user multi-input multi-output (MIMO) multiple access
channel (MAC) and broadcast channel (BC) with cooperation and admission control
as special cases. In these wireless systems, data from the J users in the MAC
or data to the J users in the BC is transmitted over a common channel that is
fading according to the FS-CTMC. The J-user capacity region for the MAC or the
BC is a set-valued stochastic process that switches with the FS-CTMC fading. In
any particular channel state, we show that each of the J-user capacity regions
is a convex set bounded by a number of linear or smooth curved facets.
Therefore our queueing model can perfectly match the dynamics of these wireless
systems.