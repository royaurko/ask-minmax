In wireless sensor networks, various applications involve learning one or
multiple functions of the measurements observed by sensors, rather than the
measurements themselves. This paper focuses on type-threshold functions, e.g.,
the maximum and indicator functions. Previous work studied this problem under
the collocated collision network model and showed that under many probabilistic
models for the measurements, the achievable computation rates converge to zero
as the number of sensors increases. This paper considers two network models
reflecting both the broadcast and superposition properties of wireless
channels: the collocated linear finite field network and the collocated
Gaussian network. A general multi-round coding scheme exploiting not only the
broadcast property but particularly also the superposition property of the
networks is developed. Through careful scheduling of concurrent transmissions
to reduce redundancy, it is shown that given any independent measurement
distribution, all type-threshold functions can be computed reliably with a
non-vanishing rate in the collocated Gaussian network, even if the number of
sensors tends to infinity.