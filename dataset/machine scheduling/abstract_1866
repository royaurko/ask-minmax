This paper shows how a machine, which observes stimuli through an
uncharacterized, uncalibrated channel and sensor, can glean machine-independent
information (i.e., channel- and sensor-independent information) about the
stimuli. First, we demonstrate that a machine defines a specific coordinate
system on the stimulus state space, with the nature of that coordinate system
depending on the device's channel and sensor. Thus, machines with different
channels and sensors "see" the same stimulus trajectory through state space,
but in different machine-specific coordinate systems. For a large variety of
physical stimuli, statistical properties of that trajectory endow the stimulus
configuration space with differential geometric structure (a metric and
parallel transfer procedure), which can then be used to represent relative
stimulus configurations in a coordinate-system-independent manner (and,
therefore, in a channel- and sensor-independent manner). The resulting
description is an "inner" property of the stimulus time series in the sense
that it does not depend on extrinsic factors like the observer's choice of a
coordinate system in which the stimulus is viewed (i.e., the observer's choice
of channel and sensor). This methodology is illustrated with analytic examples
and with a numerically simulated experiment. In an intelligent sensory device,
this kind of representation "engine" could function as a "front-end" that
passes channel/sensor-independent stimulus representations to a pattern
recognition module. After a pattern recognizer has been trained in one of these
devices, it could be used without change in other devices having different
channels and sensors.