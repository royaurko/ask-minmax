This paper studies a scheduling control problem for a single-server
multiclass queueing network in heavy traffic, operating in a changing
environment. The changing environment is modeled as a finite state Markov
process that modulates the arrival and service rates in the system. Various
cases are considered: fast changing environment, fixed environment and slow
changing environment. In each of the cases, using weak convergence analysis, in
particular functional limit theorems for renewal processes and ergodic Markov
processes, it is shown that an appropriate "averaged" version of the classical
c\mu -policy (the priority policy that favors classes with higher values of the
product of holding cost c and service rate \mu) is asymptotically optimal for
an infinite horizon discounted cost criterion.