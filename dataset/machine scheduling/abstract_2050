This article is concerned with stability analysis and stabilization of
randomly switched nonlinear systems. These systems may be regarded as piecewise
deterministic stochastic systems: the discrete switches are triggered by a
stochastic process which is independent of the state of the system, and between
two consecutive switching instants the dynamics are deterministic. Our results
provide sufficient conditions for almost sure global asymptotic stability using
Lyapunov-based methods when individual subsystems are stable and a certain
``slow switching'' condition holds. This slow switching condition takes the
form of an asymptotic upper bound on the probability mass function of the
number of switches that occur between the initial and current time instants.
This condition is shown to hold for switching signals coming from the states of
finite-dimensional continuous-time Markov chains; our results therefore hold
for Markov jump systems in particular. For systems with control inputs we
provide explicit control schemes for feedback stabilization using the universal
formula for stabilization of nonlinear systems.