Markov chains for probability distributions related to matrix product states
and 1D Hamiltonians are introduced. With appropriate 'inverse temperature'
schedules, these chains can be combined into a random approximation scheme for
ground states of such Hamiltonians. Numerical experiments suggest that a
linear, i.e. fast, schedule is possible in non-trivial cases. A natural
extension of these chains to 2D settings is next presented and tested. The
obtained results compare well with Euclidean evolution. The proposed Markov
chains are easy to implement and are inherently sign problem free (even for
fermionic degrees of freedom).