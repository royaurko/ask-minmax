We propose a novel method of introducing structure into existing machine
learning techniques by developing structure-based similarity and distance
measures. To learn structural information, low-dimensional structure of the
data is captured by solving a non-linear, low-rank representation problem. We
show that this low-rank representation can be kernelized, has a closed-form
solution, allows for separation of independent manifolds, and is robust to
noise. From this representation, similarity between observations based on
non-linear structure is computed and can be incorporated into existing feature
transformations, dimensionality reduction techniques, and machine learning
methods. Experimental results on both synthetic and real data sets show
performance improvements for clustering, and anomaly detection through the use
of structural similarity.