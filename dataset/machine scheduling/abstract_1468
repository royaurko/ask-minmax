Many machine learning algorithms are based on the assumption that training
examples are drawn independently. However, this assumption does not hold
anymore when learning from a networked sample where two or more training
examples may share common features. We propose an efficient weighting method
for learning from networked examples and show the sample error bound which is
better than previous work.