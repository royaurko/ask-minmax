This is a follow-up sensitivity study on r-mode gravitational wave signals
from newborn neutron stars illustrating the applicability of machine learning
algorithms for the detection of long-lived gravitational-wave transients. In
this sensitivity study we examine three machine learning algorithms (MLAs):
artificial neural networks (ANNs), support vector machines (SVMs) and
constrained subspace classifiers (CSCs). The objective of this study is to
compare the detection efficiency that MLAs can achieve with the efficiency of
conventional detection algorithms discussed in an earlier paper. Comparisons
are made using 2 distinct r-mode waveforms. For the training of the MLAs we
assumed that some information about the distance to the source is given so that
the training was performed over distance ranges not wider than half an order of
magnitude. The results of this study suggest that machine learning algorithms
are suitable for the detection of long-lived gravitational-wave transients and
that when assuming knowledge of the distance to the source, MLAs are at least
as efficient as conventional methods.