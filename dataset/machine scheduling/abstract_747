We used peer grading in a course on algorithms and data structures at the
University of Hamburg. During the whole semester, students repeatedly handed in
solutions to exercises, which were then evaluated both by teaching assistants
and by peer grading. We tried different methods from the machine learning
literature to aggregate the peer grades in order to come up with accurate final
grades for the submitted solutions (supervised and unsupervised, methods based
on numeric scores and ordinal rankings). We found that none of them improves
over the baseline of using the mean peer grade as the final grade.