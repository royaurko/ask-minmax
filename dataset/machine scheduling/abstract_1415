We present a data dependent generalization bound for a large class of
regularized algorithms which implement structured sparsity constraints. The
bound can be applied to standard squared-norm regularization, the Lasso, the
group Lasso, some versions of the group Lasso with overlapping groups, multiple
kernel learning and other regularization schemes. In all these cases
competitive results are obtained. A novel feature of our bound is that it can
be applied in an infinite dimensional setting such as the Lasso in a separable
Hilbert space or multiple kernel learning with a countable number of kernels.