Password: In this paper we study job scheduling performance in a partitionable parallel system. Jobs consist of parallel tasks scheduled to execute concurrently on processor partitions, where each task starts at the same time and computes at the same pace. The performance of different scheduling schemes is compared over various workloads. The impact of the variability of tasks service time is also studied. Various performance metrics are examined. The objective is to achieve good overall performance and also small scheduling overhead. Simulated results reveal that periodic job scheduling and also scheduling which depends on the number of job insertions in the queue can succeed these goals. Keywords Performance ; Gang scheduling ; Parallel systems 1. Introduction In multiprogrammed parallel systems, the scheduling of parallel jobs on processors has been shown to be a critical factor in achieving efficient parallel execution. Users expect their individual jobs to achieve excellent performance. The main issue is how to share system resources among competing jobs, in a way that satisfies the demands of jobs and produces good overall performance. These objectives raise a number of scheduling policy issues with respect to large parallel computing environments. This paper considers a partitionable parallel system where the partitions are subsystems allocated to independent jobs [13] . Jobs consist of parallel tasks that are scheduled to execute concurrently on a set of processors. The parallel tasks need to start at essentially the same time, co-ordinate their execution, and compute at the same pace. This type of resource management is called “coscheduling” or “gang scheduling” and has been extensively studied in the literature of distributed and shared memory systems [1] , [3] , [4] , [6] , [8] , [10] , [11] , [14] , [15] , [18] , [19] , [20]  and  [21] . Common reasons to use gang scheduling are its responsiveness and efficient use of resources. Some examples of gang scheduling use are its implementation on the CM-5 Connection Machine, IBM SP2 and clusters of workstations. Jobs start to execute only if enough idle processors are available to handle them. However, a scheduling policy is needed to determine which parallel program is to be mapped to the available processors. In multiprogrammed parallel systems, processor partitions are usually allocated on a first come first served (FCFS) basis. This approach can result in severe fragmentation, because processors that cannot fulfil demands of the next job in the queue remain idle until the needed resources are freed. To avoid fragmentation, a non-FCFS policy for queuing waiting jobs on a partitionable system should be used. In [8] we studied the performance of two well-known gang scheduling methods, the largest job first served (LJFS) and the adapted first come first served (AFCFS). That paper considers closed queuing network models with a fixed number of jobs. It has been shown that in many cases LJFS performs better than AFCFS. However, LJFS has the disadvantage that it involves a considerable amount of overhead because the processor queue is re-arranged each time a new parallel job is added. Most research into parallel job scheduling policies has focused on improving overall performance where scheduling overhead is assumed to be negligible. However, scheduling overhead can seriously degrade performance. In this work, along with the AFCFS and LJFS scheduling methods, we also consider two other policies: the periodic largest job first served (PLJFS) and the queue insertions dependent LJFS (QLJFS) scheduling methods. With the PLJFS policy the processors queue is re-arranged only at the end of predefined time periods p . At the end of a period the scheduler recalculates the priorities of all jobs in the queue using the LJFS criterion. When the QLJFS policy is employed, the queue is re-arranged according to the LJFS criterion every i job insertions in the queue. We aim to find if the periodic and the queue insertions dependent scheduling methods perform well as compared to the LJFS policy and minimize the disadvantage of LJFS as much as possible. Scheduling optimality is defined as minimizing the number of queue re-arrangements. We study and compare the scheduling policies for various workloads and for different periods p and numbers i of jobs insertions in the queue. Comparative results are obtained using simulation techniques. In a previous paper [9] we studied an epoch scheduling method. However, in that paper the system and workload models are different than those that are examined here. That paper studies a distributed system, where each processor is equipped with its own queue. It considers a closed queuing network model with a fixed number of jobs. Further to this, it does not examine gang scheduling. It considers jobs with independent tasks that can execute on any processor and in any order. Periodic gang scheduling in an open queueing network model of a partitionable parallel system has been studied in [10] . In that paper the overall performance is expressed by the average response time of jobs. In this paper we study additional metrics, which better reflect performance of scheduling strategies. One of them is the average slowdown. Furthermore, we examine two other metrics the average weighted response time and the average weighted slowdown where the weight is the number of processors required by a job, which is a job’s degree of parallelism. Thereby, it is avoided that jobs with the same execution time, but with different resource requirements, have the same impact on the overall performance. Furthermore, this paper studies an additional scheduling method, the queue insertions dependent method that is not studied in [10] . Many scheduling policies have been proposed for multiprocessor systems, the evaluation of which usually was conducted on workloads with a relatively small variability in task processing requirements. However, multiprocessing computer centers have reported that their service time coefficient of variation can in fact be greater than one. This paper extends our previous research [11] where the exponential distribution is used for the service demands of parallel tasks. This paper examines also the performance of the gang scheduling strategies in the case where the service demands of parallel jobs present high variability. In this way we are able to examine the impact of the variability of task service demands on scheduling strategies performance. The paper presents and analyses additional results produced by employing the Branching Erlang distribution for tasks service demands, and it provides a more detailed study of the impact on performance of various workload parameters. To our knowledge, gang scheduling in partitionable parallel systems operating under these workload models has not appeared in the research literature. In this paper the results are obtained from simulation studies instead of from measurements of real systems. However, we believe that the results we present are of practical value for real systems. The scheduling strategies we study are practical in that they can be implemented. Although we do not derive absolute performance predictions for specific parallel systems and workloads, we study the relative performance of the different gang scheduling strategies for various workloads and we examine how changes in the workload affect performance. For simple systems, performance models can be mathematically analysed using queuing theory to obtain performance measures. Our system, in addition to exponential distribution for task processing requirements, involves Branching Erlang distribution as well. Also, it involves scheduling policies with different complexities. For complex systems analytical modelling is difficult and often requires additional simplifying assumptions. Such assumptions might have unpredictable impact on the results. For this reason, there have been many research efforts to finding approximate analysis, to developing tractable models in some cases, and to performing simulations. In this research we employed simulation because it is possible to simulate the system under study in detail. Detailed simulation models help determine performance bottlenecks in architecture and also help in refining the system configuration. The structure of the paper is as follows: Section 2 specifies system and workload models, it describes the scheduling strategies, and it presents the metrics employed while assessing performance of the scheduling strategies. Section 3 describes the experimental methodology and the input parameters, and also presents and analyses the experimental results. Section 4 contains conclusions and suggestions for further research, and the last section is the references. 2. Model and methodology 2.1. System and workload models An open queuing network model is considered that consists of P  = 128 parallel homogeneous processors ( Fig. 1 ). An example of a machine of this size is Sweetgum which is an SGI Origin 2800 Supercomputer equipped with 128 CPUs. All processors share a single queue (memory). The effects of the memory requirements and the communication latencies are not represented explicitly in the system model. Instead, they appear implicitly at job execution time. By covering different types of job execution behaviours, we expect that various architectural characteristics be captured, as well. Fig. 1. 