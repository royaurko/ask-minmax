Password: The computing GRID infrastructure could benefit of techniques that can improve the overall throughput of the system. It is possible that job submission will include different ontology in resource requests due to the generality of the GRID infrastructure. Such flexible resource request could offer the opportunity to optimize several parameters, from network load to job costs in relation to due time, more generally the quality of services. We present the result of the simulation of GRID jobs allocation. The search strategy for this input case does not converge to the optimal case inside the limited number of trial performed, in contrast with previous work on up to 24 jobs [Scheduling in a Grid Computing Environment using Genetic Algorithms, in: Proceedings of the International Parallel and Distributed Processing Symposium: IPDPS 2002 Workshops]. The benefits of the usage of the genetic algorithms to improve the quality of the scheduling is discussed. The simulation has been obtained using an environment GGAS suitable to study the scheduling of jobs in a distributed group of parallel machines. The modular structure of GGAS allows to expand its functionalities to include other first level schedule policy with respect to the FCFS that is considered. The result of this paper suggests the usage of local search strategy to improve the convergence when the number of jobs to be considered is as big as in real world operation. Keywords GRID computing ; Scheduling ; Genetic algorithms optimization Grid Computing aims to allow unified access to data, computing power, sensors and others resources through a single virtual laboratory [2] . Technologies should provide services, protocols and software needed for a flexible and controlled sharing of resources. Taking advantage of the portability of parallel codes it is possible to build an infrastructure to offer computing power to a large high performance computing audience. To be appealing such an infrastructure has to be competitive in terms of costs to the final users. Usually this corresponds to an optimal usage of the resources, to avoid constraint conflicts that can compromise the usage of this complex and fully automated system. There are basically two approaches to solve this problem, the first is based on a distributed resource discover and allocation system, the second is based on a central repository of distributed resources and resources requests. The first is suitable for small jobs that can easily be accepted by the computing GRID, the second is suitable for large periodical jobs that are scheduled in advance and that can benefit from a costs reduction. This kind of centralized scheduler is usually referred to as “superscheduler” [3] (or metascheduler), because of its logical position on top of the local schedulers. It should optimize the allocation of a job allowing the execution on the fittest set of resources, permitting to consider a variable cost of the job execution at scheduling time. Scheduling in a Grid environment has to satisfy a number of constraints on different problems. We have defined a set of them to study the feasibility and the usefulness of applying evolutionary techniques to this field. It is important to point out that this is by no means a complete characterization of the real world problem; the subset of constraints that we have considered provide a first insight into the usefulness of GA for scheduling in a Grid environment. 2. Problem definition Let us consider a set of jobs, a set of interconnected computing nodes each one with a set of heterogeneous computing resources. Jobs are subject to constraints on the hardware and on the execution time. That means, jobs may run on different hardware architectures following the submission schema decided by the specific user. The grid nodes manage local computing resources with respect to local policies, giving access to them through a local scheduler. In our simulations we have simulated a FCFS scheduler available at each node of the Grid. Parallel computing resources, single parallel machines, local to a node are subdivided by architecture type. Shared memory, distributed memory and off the shelf PC cluster architecture types are considered. Each machine is identified also from the total computing power that can be released, i.e. by the number of computing nodes times the single processor power. The machine usage is not partitioned a priori, a single FCFS queue is feeding jobs for execution to a parallel computer as a whole. The problem here discussed highlights the interaction with different local entities (geographically distributed) using mixed hardware architectures. Precedence relations between tasks, checkpointing and failures of jobs are not covered at present. In a previous work we also addressed the problem of data locality [1] . The goal of the superscheduler is to find the allocation sequence on each node of a computational grid that minimizes the release time of jobs with respect to a set of constraints. As reported in Hamscher et al. [5] there are different job allocation strategies in a Grid environment (e.g. centralized or decentralized with job pool). We have designed a two level system of scheduling, with a first level formed by the set of computing nodes (the sites participating in the Grid)––each one with a local scheduling policy––and the second level formed by the superscheduler. The local scheduler accepts a single job at a time and allocates it on the local hardware with respect to the current (local) informations. Fig. 1 shows the architecture described with a three node Grid environment example. Fig. 1.  We have developed a simulation environment to study the usefulness of genetic algorithms for this superscheduler problem with respect to different job sequence input cases. A schematic view of the different modules of the simulator is sketched in Fig. 2 Fig. 2.  The simulator has been written in C language using the PGAPack (Parallel Genetic Algorithm PACKage) library [4] and tested under Linux (Intel platform), Aix (Risc 6000 platform) and True64 (Alpha platform) with native C compilers (namely GNU, IBM and Compaq compilers) [6] , [8]  and  [9] . The optimal solution is selected using the following parameters: • job characteristics, • Grid environment characteristics, • data distribution characteristics. We have chosen a set of properties and descriptions relevant to real world situations. The first constraint is the job-architecture pair selection. The user defines his preferred HW architecture and alternative ones if applicable. For each architecture he provides the resource consumption parameter in terms of computing power and parallel efficiency and the relative execution time. Requested computing power normalized with parallel efficiency defines the number of processors necessary to run the job on a given parallel computer architecture. The second constraint is the total theoretical computing power that a machine can supply; this corresponds to a given contemporaneous number of parallel jobs with a dynamic partition of the machine, for example half of the available processing node is assigned to a job and the other half to another job. The parallel computer is seen as a whole and not as a rigid repartition in a defined set of queues. A more practical division of the overall parallel machine could include multiples of networked clusters, i.e. in case of a 16 way shared memory machine, allocation in multiple of 16 processors should be preferred. All this data is static and corresponds to the snapshot of the last values averages taken at the beginning of the optimization process. New submitted jobs, QOS of network, machine failures and other dynamic parameters may be recognized only at the next snapshot. In Table 1 we provide a synthesis of this different kind of information.