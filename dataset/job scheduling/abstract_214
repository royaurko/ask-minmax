Cloud computing' service-oriented characteristics advance a new way of service provisioning called utility based computing. However, toward the practical application of commercialized Cloud, we encounter two challenges: i) there is no well-defined job scheduling algorithm for the Cloud that considers the system state in the future, particularly under overloading circumstances; ii) the existing job scheduling algorithms under utility computing paradigm do not take hardware/software failure and recovery in the Cloud into account. In an attempt to address these challenges, we introduce the failure and recovery scenario in the Cloud computing entities and propose a Reinforcement Learning (RL) based algorithm to make job scheduling fault-tolerable while maximizing utilities attained in the long term. We carry out experimental comparison with Resource-constrained Utility Accrual algorithm (RUA), Utility Accrual Packet scheduling algorithm (UPA) and LBESA to demonstrate the feasibility of our proposed approach.