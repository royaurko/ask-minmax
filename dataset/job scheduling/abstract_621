  We propose a new multi-objective bi-level programming model based on MapReduce to improve energy efficiency of servers. • The relationship between performance and energy consumption of severs is taken into account in the proposed model. • Data locality can be adjusted dynamically according to current network state. • A new effective multi-objective genetic algorithm based on MOEA/D is proposed to solve the above large-scale scheduling model. How to reduce power consumption of data centers has received worldwide attention. By combining the energy-aware data placement policy and locality-aware multi-job scheduling scheme, we propose a new multi-objective bi-level programming model based on MapReduce to improve the energy efficiency of servers. First, the variation of energy consumption with the performance of servers is taken into account; second, data locality can be adjusted dynamically according to current network state; last but not least, considering that task-scheduling strategies depend directly on data placement policies, we formulate the problem as an integer bi-level programming model. In order to solve the model efficiently, specific-design encoding and decoding methods are introduced. Based on these, a new effective multi-objective genetic algorithm based on MOEA/D is proposed. As there are usually tens of thousands of tasks to be scheduled in the cloud, this is a large-scale optimization problem and a local search operator is designed to accelerate convergent speed of the proposed algorithm. Finally, numerical experiments indicate the effectiveness of the proposed model and algorithm. Keywords Energy aware ; Data locality ; Multi-job scheduling ; Cloud computing ; MapReduce 1. Introduction As cloud computing  [1] platforms are growing in popularity, soaring power usage of data centers has drawn increasing attention. Reducing energy consumption will not only cut down the operational costs of data centers, but also reduce the amount of greenhouse gases emissions. It is estimated that data centers consumed approximately 1.5% of all electricity worldwide in 2011, which was about 56% higher than that of the preceding five years [2] . What is more, according to Amazon’s CEMS project  [3] , energy-related cost amounts to 42% of the total budget as shown in Fig. 1 , inclusive of both direct power consumption (19%) and the investment of the supporting infrastructure for cooling and power distribution (23%). Yet average data center energy efficiency is merely 50%  [4] . Fig. 1.  Monthly cost of Amazon’s data center. Among all the approaches trying to reduce energy consumption of data centers, the most direct and intuitive one is to decrease energy consumed by supporting systems, including power distribution equipment and cooling systems. First, an overall power distribution loss only accounts for 8% of the total energy consumption for a data center with a PUE (Power Usage Effectiveness) of 1.7. That is to say, even with better technology, the reduction will not exceed 8%  [3] . Second, Google’s “free cooling” mode sets a successful example of reducing the energy consumption of cooling systems. It removes heat from servers by evaporating water or low temperature ambient air  [5] . Although “free cooling” mode has proved to be useful, it has a key prerequisite that providers must have sufficient financial and technical strength to run several data centers around the world and the data should be backed up across them with seamless migration of computing loads. Powering off idle devices when possible is regarded as another way of reducing energy consumption, especially during off-peak traffic hours. There exist a great number of solutions in the literature, which basically can be divided into two categories: designing energy-proportional servers or networks  [6] and establishing energy aware virtualization over servers  [7] . (1) Engineers from Google try to design energy-proportional servers that consume energy in proportion to the amount of work performed as they noticed that even an energy efficient server still consumes about half its full power when doing virtually no work  [8] . Meanwhile,  [9] proposes energy proportional networks whose power consumption is more proportional to the amount of traffic it is moving. (2) Virtualization abstracts away the details of physical hardware and provides virtualized resources for high-level applications  [10] , [11]  and  [12] . Services that only need a small fraction of computational resources can be virtualized and run within a virtual machine (VM). Several VMs with low resource utilization can run on a single hardware unit. Therefore, unused servers can be hibernated or turned off to save energy. However, the virtualization process will result in huge energy consumption because VMs are repeatedly created, terminated, cloned or moved from one host to another host  [13]  and  [14] . The last approach of equal importance is to improve servers’ energy efficiency. Fig. 2 shows how energy is used within a data center according to Emerson Network Power’s analysis  [15] . It was found that energy consumed by servers accounts for 52% of the total consumption, while support systems consume the remaining 48%. Furthermore, every Watt of savings that could be achieved on servers created approximately 2.84 W of savings in all. Therefore, it becomes critical to put forward an effective way to improve servers’ energy efficiency. Certain literature  [16]  and  [17] tries to achieve this goal by adjusting servers’ CPU through task-scheduling strategies based on a given data deployment. Fig. 2. 