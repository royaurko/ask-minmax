It is possible to represent each of a number of Markov chains as an evolving
sequence of connected subsets of a directed acyclic graph that grow in the
following way: initially, all vertices of the graph are unoccupied, particles
are fed in one-by-one at a distinguished source vertex, successive particles
proceed along directed edges according to an appropriate stochastic mechanism,
and each particle comes to rest once it encounters an unoccupied vertex.
Examples include the binary and digital search tree processes, the random
recursive tree process and generalizations of it arising from nested instances
of Pitman's two-parameter Chinese restaurant process, tree-growth models
associated with Mallows' phi model of random permutations and with
Schuetzenberger's non-commutative q-binomial theorem, and a construction due to
Luczak and Winkler that grows uniform random binary trees in a Markovian
manner. We introduce a framework that encompasses such Markov chains, and we
characterize their asymptotic behavior by analyzing in detail their Doob-Martin
compactifications, Poisson boundaries and tail sigma-fields.