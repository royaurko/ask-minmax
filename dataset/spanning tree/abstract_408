We present a new method to detect and quantify mass segregation in star
clusters. It compares the minimum spanning tree (MST) of massive stars with
that of random stars. If mass segregation is present, the MST length of the
most massive stars will be shorter than that of random stars. This difference
can be quantified (with an associated significance) to measure the degree of
mass segregation. We test the method on simulated clusters in both 2D and 3D
and show that the method works as expected.
  We apply the method to the Orion Nebula Cluster (ONC) and show that the
method is able to detect the mass segregation in the Trapezium with a `mass
segregation ratio' \Lambda_{MSR}=8.0 \pm 3.5 (where \Lambda_{MSR}=1 is no mass
segregation) down to 16 \Msun, and also that the ONC is mass segregated at a
lower level (~2.0 \pm 0.5) down to 5 \Msun. Below 5 \Msun we find no evidence
for any further mass segregation in the ONC.