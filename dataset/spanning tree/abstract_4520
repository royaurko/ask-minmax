In this paper we explore how machine learning techniques can be applied to
the discovery of efficient mathematical identities. We introduce an attribute
grammar framework for representing symbolic expressions. Given a set of grammar
rules we build trees that combine different rules, looking for branches which
yield compositions that are analytically equivalent to a target expression, but
of lower computational complexity. However, as the size of the trees grows
exponentially with the complexity of the target expression, brute force search
is impractical for all but the simplest of expressions. Consequently, we
introduce two novel learning approaches that are able to learn from simpler
expressions to guide the tree search. The first of these is a simple n-gram
model, the other being a recursive neural-network. We show how these approaches
enable us to derive complex identities, beyond reach of brute-force search, or
human derivation.