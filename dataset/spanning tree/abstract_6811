In perfect-information games in extensive form, common knowledge of
rationality triggers backward induction, which yields a Nash equilibrium. That
result assumes much about the players' knowledge, while it holds only for a
subclass of the games in extensive form. Alternatively, this article defines a
non-deterministic evolutionary process, by myopic and lazy improvements, that
settles exactly at Nash equilibrium (in extensive form). Importantly, the
strategical changes that the process allows depend only on the structure of the
game tree, they are independent from the actual preferences. Nonetheless, the
process terminates if the players have acyclic preferences; and even if some
preferences are cyclic, the players with acyclic preferences stop improving
eventually. This result is then generalised in games played on DAGs or infinite
trees, and it is also refined by assigning probabilities to the process and
perturbing it.