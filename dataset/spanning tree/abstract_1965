Deep neural networks have made significant breakthroughs in many fields of
artificial intelligence. However, it has not been applied in the field of
programming language processing. In this paper, we propose the tree-based
convolutional neural network (TBCNN) to model programming languages, which
contain rich and explicit tree structural information. In our model, program
vector representations are learned by the "coding" pretraining criterion based
on abstract syntax trees (ASTs); the convolutional layer explicitly captures
neighboring features on the tree; with the "binary continuous tree" and "3-way
pooling," our model can deal with ASTs of different shapes and sizes.We
evaluate the program vector representations empirically, showing that the
coding criterion successfully captures underlying features of AST nodes, and
that program vector representations significantly speed up supervised learning.
We also compare TBCNN to baseline methods; our model achieves better accuracy
in the task of program classification. To our best knowledge, this paper is the
first to analyze programs with deep neural networks; we extend the scope of
deep learning to the field of programming language processing. The experimental
results validate its feasibility; they also show a promising future of this new
research area.