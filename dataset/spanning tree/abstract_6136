Many fundamental statistical methods have become critical tools for
scientific data analysis yet do not scale tractably to modern large datasets.
This paper will describe very recent algorithms based on computational geometry
which have dramatically reduced the computational complexity of 1) kernel
density estimation (which also extends to nonparametric regression,
classification, and clustering), and 2) the n-point correlation function for
arbitrary n. These new multi-tree methods typically yield orders of magnitude
in speedup over the previous state of the art for similar accuracy, making
millions of data points tractable on desktop workstations for the first time.