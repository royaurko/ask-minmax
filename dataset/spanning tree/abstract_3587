Random forests, introduced by Leo Breiman in 2001, are a very effective
statistical method. The complex mechanism of the method makes theoretical
analysis difficult. Therefore, a simplified version of random forests, called
purely random forests, which can be theoretically handled more easily, has been
considered. In this paper we introduce a variant of this kind of random
forests, that we call purely uniformly random forests. In the context of
regression problems with a one-dimensional predictor space, we show that both
random trees and random forests reach minimax rate of convergence. In addition,
we prove that compared to random trees, random forests improve accuracy by
reducing the estimator variance by a factor of three fourths.