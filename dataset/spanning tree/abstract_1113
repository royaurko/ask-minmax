This paper describes the Context Tree Switching technique, a modification of
Context Tree Weighting for the prediction of binary, stationary, n-Markov
sources. By modifying Context Tree Weighting's recursive weighting scheme, it
is possible to mix over a strictly larger class of models without increasing
the asymptotic time or space complexity of the original algorithm. We prove
that this generalization preserves the desirable theoretical properties of
Context Tree Weighting on stationary n-Markov sources, and show empirically
that this new technique leads to consistent improvements over Context Tree
Weighting as measured on the Calgary Corpus.