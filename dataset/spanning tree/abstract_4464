We propose a human-supervised control synthesis method for a stochastic
Dubins vehicle such that the probability of satisfying a specification given as
a formula in a fragment of Probabilistic Computational Tree Logic (PCTL) over a
set of environmental properties is maximized. Under some mild assumptions, we
construct a finite approximation for the motion of the vehicle in the form of a
tree-structured Markov Decision Process (MDP). We introduce an efficient
algorithm, which exploits the tree structure of the MDP, for synthesizing a
control policy that maximizes the probability of satisfaction. For the proposed
PCTL fragment, we define the specification update rules that guarantee the
increase (or decrease) of the satisfaction probability. We introduce an
incremental algorithm for synthesizing an updated MDP control policy that
reuses the initial solution. The initial specification can be updated, using
the rules, until the supervisor is satisfied with both the updated
specification and the corresponding satisfaction probability. We propose an
offline and an online application of this method.