We study a two-player, zero-sum, dynamic game with incomplete information
where one of the players is more informed than his opponent. We analyze the
limit value as the players play more and more frequently. The more informed
player observes the realization of a Markov process (X,Y) on which the payoffs
depend, while the less informed player only observes Y and his opponent's
actions. We show the existence of a limit value as the time span between two
consecutive stages goes to zero. This value is characterized through an
auxiliary optimization problem and as the unique viscosity solution of a second
order Hamilton-Jacobi equation with convexity constraints.