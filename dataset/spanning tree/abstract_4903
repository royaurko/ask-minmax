We investigate an application in the automatic tuning of computer codes, an
area of research that has come to prominence alongside the recent rise of
distributed scientific processing and heterogeneity in high-performance
computing environments. Here, the response function is nonlinear and noisy and
may not be smooth or stationary. Clearly needed are variable selection,
decomposition of influence, and analysis of main and secondary effects for both
real-valued and binary inputs and outputs. Our contribution is a novel set of
tools for variable selection and sensitivity analysis based on the recently
proposed dynamic tree model. We argue that this approach is uniquely well
suited to the demands of our motivating example. In illustrations on benchmark
data sets, we show that the new techniques are faster and offer richer feature
sets than do similar approaches in the static tree and computer experiment
literature. We apply the methods in code-tuning optimization, examination of a
cold-cache effect, and detection of transformation errors.