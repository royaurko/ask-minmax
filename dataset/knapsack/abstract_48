We consider the linear contextual bandit problem with global convex
constraints and a concave objective function. In each round, the outcome of
pulling an arm is a vector, that depends linearly on the context of that arm.
The global constraints require the average of these vectors to lie in a certain
convex set. The objective is a concave function of this average vector. This
problem turns out to be a common generalization of classic linear contextual
bandits (linContextual) [Auer 2003], bandits with concave rewards and convex
knapsacks (BwCR) [Agrawal, Devanur 2014], and the online stochastic convex
programming (OSCP) problem [Agrawal, Devanur 2015]. We present algorithms with
near-optimal regret bounds for this problem. Our bounds compare favorably to
results on the unstructured version of the problem [Agrawal et al. 2015,
Badanidiyuru et al. 2014] where the relation between the contexts and the
outcomes could be arbitrary, but the algorithm only competes against a fixed
set of policies.