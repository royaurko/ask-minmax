  In this paper we study the problem where an optimal solution of a knapsack problem on n n items is known and a very small number k k of new items arrive. The objective is to find an optimal solution of the knapsack problem with n+k n + k items, given an optimal solution on the n n items (reoptimization of the knapsack problem). We show that this problem, even in the case k=1 k = 1 , is NP-hard and that, in order to have effective heuristics, it is necessary to consider not only the items included in the previously optimal solution and the new items, but also the discarded items. Then, we design a general algorithm that makes use, for the solution of a subproblem, of an α α -approximation algorithm known for the knapsack problem. We prove that this algorithm has a worst-case performance bound of 1 2 − α , which is always greater than α α , and therefore that this algorithm always outperforms the corresponding α α -approximation algorithm applied from scratch on the n+k n + k items. We show that this bound is tight when the classical Ext-Greedy   algorithm and the G 3 4 algorithm are used to solve the subproblem. We also show that there exist classes of instances on which the running time of the reoptimization algorithm is smaller than the running time of an equivalent PTAS and FPTAS. Keywords 0–1 knapsack problem ; Reoptimization ; Worst-case analysis 0. Introduction Combinatorial problems have been widely studied under the assumption that the instance is completely known at the time the optimization is carried out, that no information is available on the solution of the instance or of related instances and that an optimal solution will not need to be modified later. However, it happens more and more frequently that new information is made available in real time, after an optimal solution has been obtained. Therefore, the instance is perturbed and the optimal solution needs to be modified accordingly, in a short amount of time. A typical approach to solve this problem is to apply a known heuristic algorithm from scratch, completely ignoring the work done to obtain the previously optimal solution. A different approach is to solve the so-called reoptimization problem , that is the problem of finding an optimal solution to the perturbed instance knowing an optimal solution to the original one. Two issues become of interest in this setting. The first is the complexity of the reoptimization problem. The second is to study whether it is possible to take advantage of the available optimal solution to design more effective and/or efficient heuristic algorithms. This approach has received little attention in the past. It was applied to a scheduling problem by Schäffter  [13] and to the traveling salesman problem by Archetti et al.  [1] and Ausiello et al.  [2] . Bockenhauer et al.  [3] investigated the hardness of solving a modified instance of a problem when an optimal solution of the original instance is known for some variants of the traveling salesman problem and the Steiner tree problem. The 0–1 knapsack problem is one of the most studied combinatorial optimization problems. Very effective exact algorithms are known as well as several heuristics, approximation algorithms and schemes (we refer to the excellent books by Martello and Toth  [11] and by Kellerer et al.  [9] ). In particular, several Polynomial Time Approximation Schemes (PTASs) and Fully Polynomial Time Approximation Schemes (FPTASs) are known. Any PTAS for the knapsack problem is based on the idea of guessing a set of items included in an optimal solution by going through all possible candidate sets and then filling the remaining capacity by applying a greedy algorithm. We recall the classical PTAS by Sahni  [12] and the PTAS by Caprara et al.  [4] , which improves the PTAS by Sahni  [12] in terms of running time. Any FPTAS is based on the idea of scaling the profit values and then applying dynamic programming on the resulting instance. We recall the earliest FPTAS by Ibarra and Kim  [6] , the classical FPTAS by Lawler  [10] and the best known FPTAS by Kellerer and Pferschy  [7]  and  [9] .