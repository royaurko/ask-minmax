Password: The knapsack problem is believed to be one of the “easier” -hard problems. Not only can it be solved in pseudo-polynomial time, but also decades of algorithmic improvements have made it possible to solve nearly all standard instances from the literature. The purpose of this paper is to give an overview of all recent exact solution approaches, and to show that the knapsack problem still is hard to solve for these algorithms for a variety of new test problems. These problems are constructed either by using standard benchmark instances with larger coefficients, or by introducing new classes of instances for which most upper bounds perform badly. The first group of problems challenge the dynamic programming algorithms while the other group of problems are focused towards branch-and-bound algorithms. Numerous computational experiments with all recent state-of-the-art codes are used to show that (KP) is still difficult to solve for a wide number of problems. One could say that the previous benchmark tests were limited to a few highly structured instances, which do not show the full characteristics of knapsack problems. Keywords Knapsack problem ; Dynamic programming ; Branch-and-bound ; Test instances 1. Introduction The classical knapsack problem is defined as follows: We are given a set of n items, each item j having an integer profit p j and an integer weight w j . The problem is to choose a subset of the items such that their overall profit is maximized, while the overall weight does not exceed a given capacity c . We may formulate the model as the following integer programming model: equation ( 1 ) equation ( 2 ) equation ( 3 ) where the binary decision variables x j are used to indicate whether item j is included in the knapsack or not. Without loss of generality it may be assumed that all profits and weights are positive, that all weights are smaller than the capacity c , and that the overall weight of the items exceeds c . From practical experience it is known that many (KP) instances of considerable size can be solved within reasonable time by exact solution methods. This fact is due to several algorithmic refinements which emerged during the last two decades. These include advanced dynamic programming recursions , the concept of solving a core , and the separation of cover inequalities to tighten the formulation. For a recent survey of the latest techniques see Martello et al. [1] or the monograph by Kellerer et al. [2] . The knapsack problem is -hard in the weak sense, meaning that it can be solved in pseudo-polynomial time through dynamic programming. Meyer auf der Heide [3] showed that for the linear decision tree model (LDT) of computation no super-polynomial lower bound can exist. This negative result was extended by Fournier and Koiran [4] who showed that for even less powerful models of computation no super-polynomial lower bound is likely to exist. The lack of theoretical upper and lower bounds on the computational complexity of (KP) leaves plenty of space for practical algorithmic development. Although none of these algorithms can ensure efficient solution times for all instances, progress is made on reaching acceptable running times for all “practically occurring” instances. In the following section, we will give a short overview of the latest exact algorithms for (KP), and state their worst-case complexity where possible. In Section 3 , we experimentally measure the performance of these algorithms for a large variety of instance types, including two groups of new, difficult instances. The first group of difficult instances is based on large coefficients, while the second group contains six categories of structurally difficult instances with small coefficients. Although the classical problem instances are quite easy to solve for the most recent algorithms, it is interesting to see that the instances do not need to be changed much before the algorithms get a significantly different performance. In our search for algorithms, which are able to solve all “practically occurring” instances, it is important to be aware of these problems, and to extend our algorithms and in particular upper bounds to more robust variants. These thoughts are summarized in Section 4 . 2. Exact algorithms for the knapsack problem For the following discussion we need a few definitions. Assume that the items are sorted according to non-increasing efficiencies p j / w j , so that we have equation ( 4 ) The LP-relaxation of (KP) can be solved through the greedy algorithm by simply filling the knapsack until item , which is also known as the split item . The LP-bound is then defined as The split item s and hence also the LP-solution can be found in O ( n ) time using a median-search algorithm presented by Balas and Zemel [5] . In the following, we will denote z ∗ the integer optimal solution value and x ∗ the corresponding solution vector. The greedy solution , choosing items 1,…, s −1, will be denoted x ′. Various branch-and-bound algorithms for (KP) have been presented. The more recent of these solve a core problem, i.e. a (KP) defined on a subset of the items where there is a large probability of finding an optimal solution. The MT2 algorithm [6] is the most advanced of these algorithms. It starts by solving the core problem obtaining a lower bound z on the (KP) as well as an upper bound U . If z = U it stops, otherwise it reduces the size of the instance by fixing variables at their optimal value. In the last phase, the reduced (KP) is solved to optimality. Realizing that the core size is difficult to estimate in advance, Pisinger [7] proposed to use an expanding core algorithm, which simply starts with a core consisting of the split item only, and then adds more items to the core when needed. The proposed Expknap makes use of branch-and-bound where computationally cheap upper bounds from LP-relaxation are used. Martello and Toth [8] proposed a special variant of the MT2 algorithm which was developed to deal with hard knapsack problems. The resulting algorithm MThard makes use of a new family of upper bounds based on the generation of additional cardinality constraints which again are Lagrangian relaxed to reach an ordinary (KP). Straightforward use of dynamic programming leads to the well-known Bellman recursion [9] which solves the (KP) in pseudo-polynomial time O ( nc ). Reversing the roles of profits and weights in the dynamic programming recursion leads to an algorithm with running time O(nz ∗ ) .