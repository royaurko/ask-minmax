We typically observe large-scale outcomes that arise from the interactions of
many hidden, small-scale processes. Examples include age of disease onset,
rates of amino acid substitutions, and composition of ecological communities.
The macroscopic patterns in each problem often vary around a characteristic
shape that can be generated by neutral processes. A neutral generative model
assumes that each microscopic process follows unbiased stochastic fluctuations:
random connections of network nodes; amino acid substitutions with no effect on
fitness; species that arise or disappear from communities randomly. These
neutral generative models often match common patterns of nature. In this paper,
I present the theoretical background by which we can understand why these
neutral generative models are so successful. I show how the classic patterns
such as Poisson and Gaussian arise. Each classic pattern was often discovered
by a simple neutral generative model. The neutral patterns share a special
characteristic: they describe the patterns of nature that follow from simple
constraints on information. For example, any aggregation of processes that
preserves information only about the mean and variance attracts to the Gaussian
pattern; any aggregation that preserves information only about the mean
attracts to the exponential pattern; any aggregation that preserves information
only about the geometric mean attracts to the power law pattern. I present an
informational framework of the common patterns of nature based on the method of
maximum entropy. This framework shows that each neutral generative model is a
special case that helps to discover a particular set of informational
constraints; those informational constraints define a much wider domain of
non-neutral generative processes that attract to the same neutral pattern.