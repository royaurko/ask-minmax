The next generation of CMB experiments can measure cosmological parameters
with unprecedented accuracy - in principle. To achieve this in practice when
faced with such gigantic data sets, elaborate data analysis methods are needed
to make it computationally feasible. An important step in the data pipeline is
to make a map, which typically reduces the size of the data set my orders of
magnitude. We compare ten map-making methods, and find that for the Gaussian
case, both the method used by the COBE DMR team and various variants of Wiener
filtering are optimal in the sense that the map retains all cosmological
information that was present in the time-ordered data (TOD). Specifically, one
obtains just as small error bars on cosmological parameters when estimating
them from the map as one could have obtained by estimating them directly from
the TOD. The method of simply averaging the observations of each pixel (for
total-power detectors), on the contrary, is found to generally destroy
information, as does the maximum entropy method and most other non-linear
map-making techniques.
  Since it is also numerically feasible, the COBE method is the natural choice
for large data sets. Other lossless (e.g. Wiener-filtered) maps can then be
computed directly from the COBE method map.