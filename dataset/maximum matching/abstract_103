We present a new algorithm to generate a random (unclustered) version of an
magnitude limited observational galaxy redshift catalogue. It takes into
account both galaxy evolution and the perturbing effects of large scale
structure. The key to the algorithm is a maximum likelihood (ML) method for
jointly estimating both the luminosity function (LF) and the overdensity as a
function of redshift. The random catalogue algorithm then works by cloning each
galaxy in the original catalogue, with the number of clones determined by the
ML solution. Each of these cloned galaxies is then assigned a random redshift
uniformly distributed over the accessible survey volume, taking account of the
survey magnitude limit(s) and, optionally, both luminosity and number density
evolution. The resulting random catalogues, which can be employed in
traditional estimates of galaxy clustering, make fuller use of the information
available in the original catalogue and hence are superior to simply fitting a
functional form to the observed redshift distribution. They are particularly
well suited to studies of the dependence of galaxy clustering on galaxy
properties as each galaxy in the random catalogue has the same list of
attributes as measured for the galaxies in the genuine catalogue. The
derivation of the joint overdensity and LF estimator reveals the limit in which
the ML estimate reduces to the standard 1/Vmax LF estimate, namely when one
makes the prior assumption that the are no fluctuations in the radial
overdensity. The new ML estimator can be viewed as a generalization of the
1/Vmax estimate in which Vmax is replaced by a density corrected Vdc,max.