The search for gravitational-wave signals in detector data is often hampered
by the fact that many data analysis methods are based on the theory of
stationary Gaussian noise, while actual measurement data frequently exhibit
clear departures from these assumptions. Deriving methods from models more
closely reflecting the data's properties promises to yield more sensitive
procedures. The commonly used matched filter is such a detection method that
may be derived via a Gaussian model. In this paper we propose a generalized
matched-filtering technique based on a Student-t distribution that is able to
account for heavier-tailed noise and is robust against outliers in the data. On
the technical side, it generalizes the matched filter's least-squares method to
an iterative, or adaptive, variation. In a simplified Monte Carlo study we show
that when applied to simulated signals buried in actual interferometer noise it
leads to a higher detection rate than the usual ("Gaussian") matched filter.