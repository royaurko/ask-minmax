We analyze the standardizability of Type Ia supernovae (SNe Ia) in the
near-infrared (NIR) by investigating the correlation between observed peak NIR
absolute magnitude and post-maximum B-band decline rate. A sample of 27
low-redshift SNe Ia observed by the Carnegie Supernova Project between 2004 to
2007 is used. All 27 objects have pre-maximum coverage in optical bands, with a
subset of 13 having pre-maximum NIR observations as well. We describe the
methods used to derive absolute peak magnitudes and decline rates from both
spline- and template-fitting procedures, and confirm prior findings that
fitting templates to SNe Ia light curves in the NIR is problematic due to the
diversity of post-maximum behaviour of objects that are characterized by
similar decline rate values, especially at high decline rates. Nevertheless, we
show that NIR light curves can be reasonably fit with a template, especially if
the observations begin within 5 days after NIR maximum. For the subset of 13
objects in our dataset that excludes the highly reddened and fast declining SNe
Ia, and includes only those objects for which NIR observations began prior to
five days after maximum light, we find modest evidence for a peak
luminosity-decline rate relation in Y, and stronger evidence in J and H. Using
Rv values differing from the canonical value of 3.1 is shown to have little
effect on the results. A Hubble diagram is presented for the NIR bands and the
B band. The resulting scatter for the combined NIR bands is 0.13 mag, while the
B band produces a scatter of 0.22 mag. The data suggest that applying a
correction to SNe Ia peak luminosities for decline rate is likely to be
beneficial in the J and H bands to make SNe Ia more precise distance
indicators, but of only marginal importance in the Y band.