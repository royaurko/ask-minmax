We show how to find a minimum loop cutset in a Bayesian network with high
probability. Finding such a loop cutset is the first step in Pearl's method of
conditioning for inference. Our random algorithm for finding a loop cutset,
called "Repeated WGuessI", outputs a minimum loop cutset, after O(c 6^k k n)
steps, with probability at least 1-(1 over{6^k})^{c 6^k}), where c>1 is a
constant specified by the user, k is the size of a minimum weight loop cutset,
and n is the number of vertices. We also show empirically that a variant of
this algorithm, called WRA, often finds a loop cutset that is closer to the
minimum loop cutset than the ones found by the best deterministic algorithms
known.