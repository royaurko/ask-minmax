Recent advances in 3D modeling provide us with real 3D datasets to answer
queries, such as "What is the best position for a new billboard?" and "Which
hotel room has the best view?" in the presence of obstacles. These applications
require measuring and differentiating the visibility of an object (target) from
different viewpoints in a dataspace, e.g., a billboard may be seen from two
viewpoints but is readable only from the viewpoint closer to the target. In
this paper, we formulate the above problem of quantifying the visibility of
(from) a target object from (of) the surrounding area with a visibility color
map (VCM). A VCM is essentially defined as a surface color map of the space,
where each viewpoint of the space is assigned a color value that denotes the
visibility measure of the target from that viewpoint. Measuring the visibility
of a target even from a single viewpoint is an expensive operation, as we need
to consider factors such as distance, angle, and obstacles between the
viewpoint and the target. Hence, a straightforward approach to construct the
VCM that requires visibility computation for every viewpoint of the surrounding
space of the target, is prohibitively expensive in terms of both I/Os and
computation, especially for a real dataset comprising of thousands of
obstacles. We propose an efficient approach to compute the VCM based on a key
property of the human vision that eliminates the necessity of computing the
visibility for a large number of viewpoints of the space. To further reduce the
computational overhead, we propose two approximations; namely, minimum bounding
rectangle and tangential approaches with guaranteed error bounds. Our extensive
experiments demonstrate the effectiveness and efficiency of our solutions to
construct the VCM for real 2D and 3D datasets.