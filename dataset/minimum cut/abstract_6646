We propose a new approach for estimating the parameters of a probability
distribution. It consists on combining two new methods of estimation. The first
is based on the definition of a new distance measuring the difference between
variations of two distributions on a finite number of points from their support
and on using this measure for estimation purposes by the method of minimum
distance. For the second method, given an empirical discrete distribution, we
build up an auxiliary discrete theoretical distribution having the same support
of the first and depending on the same parameters of the parent distribution of
the data from which the empirical distribution emanated. We estimate then the
parameters from the empirical distribution by the usual statistical methods. In
practice, we propose to compute the two estimations, the second based on
maximum likelihood principle of known theoretical properties, and the first
being as a control of the effectiveness of the obtained estimation, and for
which we prove the convergence in probability, so we have also a criterion on
the quality of the information contained in the observations. We apply the
approach to truncated or grouped and censored data situations to give the
flavour on the effectiveness of the approach. We give also some interesting
perspectives of the approach including model selection from truncated data,
estimation of the initial trial value in the celebrate EM algorithm in the case
of truncation and merged normal populations, a test of goodness of fit based on
the new distance, quality of estimations and data.