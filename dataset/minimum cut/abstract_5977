Saliency modeling has been an active research area in computer vision for
about two decades. Existing state of the art models perform very well in
predicting where people look in natural scenes. There is, however, the risk
that these models may have been overfitting themselves to available small scale
biased datasets, thus trapping the progress in a local minimum. To gain a
deeper insight regarding current issues in saliency modeling and to better
gauge progress, we recorded eye movements of 120 observers while they freely
viewed a large number of naturalistic and artificial images. Our stimuli
includes 4000 images; 200 from each of 20 categories covering different types
of scenes such as Cartoons, Art, Objects, Low resolution images, Indoor,
Outdoor, Jumbled, Random, and Line drawings. We analyze some basic properties
of this dataset and compare some successful models. We believe that our dataset
opens new challenges for the next generation of saliency models and helps
conduct behavioral studies on bottom-up visual attention.