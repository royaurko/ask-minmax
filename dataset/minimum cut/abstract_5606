Using terminologies of information geometry, we derive upper and lower bounds
of the tail probability of the sample mean. Employing these bounds, we obtain
upper and lower bounds of the minimum error probability of the 2nd kind of
error under the exponential constraint for the error probability of the 1st
kind of error in a simple hypothesis testing for a finite-length Markov chain,
which yields the Hoeffding type bound. For these derivations, we derive upper
and lower bounds of cumulant generating function for Markov chain. As a
byproduct, we obtain another simple proof of central limit theorem for Markov
chain.