This paper experimentally and theoretically investigates the fundamental
bounds on radio localization precision of far-field Received Signal Strength
(RSS) measurements. RSS measurements are proportional to power-flow
measurements time-averaged over periods long compared to the coherence time of
the radiation. Our experiments are performed in a novel localization setup
using 2.4GHz quasi-monochromatic radiation, which corresponds to a mean
wavelength of 12.5cm. These experiments show for the first time that
time-averaged far-field RSS measurements are not independent but
cross-correlated over a spatial region. We experimentally and theoretically
show that the minimum radius of the cross-correlated region approaches the
diffraction limit, which equals half the mean wavelength of the radiation.
Measuring RSS beyond a sampling density of one sample per half the mean
wavelength is shown not to increase localization precision, as the
Root-Mean-Squared-Error (RMSE) converges asymptotically to roughly half the
mean wavelength. This adds to the evidence that the diffraction limit
determines the fundamental lower bound on the RMSE rather than the spread in
independent noise as is usually assumed in Cramer-Rao Lower Bound (CRLB)
analyses on RSS and Time-Of-Flight (TOF) signals. For the first time, we
experimentally validate the theoretical relations between Fisher information,
CRLB and uncertainty, where uncertainty is lower bounded by diffraction as
derived from coherence and speckle theory.