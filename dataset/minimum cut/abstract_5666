In this paper, we describe the leftmost eigenvalue of the non-selfadjoint
operator $\mathcal{A}_h = -h^2\Delta+iV(x)$ with Dirichlet boundary conditions
on a smooth bounded domain $\Omega\subset\mathbb{R}^n\,$, as $h\rightarrow0\,$.
$V$ is assumed to be a Morse function without critical point at the boundary of
$\Omega\,$. More precisely, we compare $\inf\Re\sigma(\mathcal{A}_h)$ with the
minimum of the spectrum's real part for some model operator. In the case where
$V$ has no critical point, the spectrum is determined by the boundary points
where $\nabla V$ is orthogonal, and the model operator involves a
$1$-dimensional complex Airy operator in $\mathbb{R}^+\,$. If $V$ is a Morse
function with critical points in $\Omega\,$, the behavior of the operator near
the critical points prevails, and the model operator is a complex harmonic
oscillator.
  This question is related to the decay of associated semigroups. In
particular, it allows to recover, in a simplified setting, some stability
results by Almog in superconductivity theory.