We study a model of learning on social networks in dynamic environments,
describing a group of agents who are each trying to estimate an underlying
state that varies over time, given access to weak signals and the estimates of
their social network neighbors.
  We study three models of agent behavior. In the "fixed response" model,
agents use a fixed linear combination to incorporate information from their
peers into their own estimate. This can be thought of as an extension of the
DeGroot model to a dynamic setting. In the "best response" model, players
calculate minimum variance linear estimators of the underlying state.
  We show that regardless of the initial configuration, fixed response dynamics
converge to a steady state, and that the same holds for best response on the
complete graph. We show that best response dynamics can, in the long term, lead
to estimators with higher variance than is achievable using well chosen fixed
responses.
  The "penultimate prediction" model is an elaboration of the best response
model. While this model only slightly complicates the computations required of
the agents, we show that in some cases it greatly increases the efficiency of
learning, and on complete graphs is in fact optimal, in a strong sense.