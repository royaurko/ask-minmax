This paper presents an analysis of the dependence of the opacity for
high-energy gamma-rays to gamma-gamma absorption by low-energy photons, on the
polarization of the gamma-ray and target photons. This process has so far only
been considered using the polarization-averaged gamma-gamma absorption cross
section. It is demonstrated that in the case of polarized gamma-ray emission,
subject to source-intrinsic gamma-gamma absorption by polarized target photons,
this may lead to a slight over-estimation of the gamma-gamma opacity by up to ~
10 % in the case of a perfectly ordered magnetic field. Thus, for realistic
astrophysical scenarios with partially ordered magnetic fields, the use of the
polarization-averaged gamma-gamma cross section is justified for practical
purposes, such as estimates of minimum Doppler factors inferred for gamma-ray
bursts and blazars, based on gamma-gamma transparency arguments, and this paper
quantifies the small error incurred by the unpolarized-radiation approximation.
Furthermore, it is shown that polarization-dependent gamma-gamma absorption of
initially polarized gamma-rays can lead to a slight increase in the
polarization beyond the spectral break caused by gamma-gamma absorption, to an
amount distinctly different from the change in polarization expected if the
same spectral break was produced by a break in the underlying electron
distribution. This may serve as a diagnostic of whether gamma-gamma absorption
is relevant in sources such as gamma-ray bursts and blazars where the gamma-ray
emission may be intrinsically highly polarized.