The minimum energy, and, more generally, the minimum cost, to transmit one
bit of information has been recently derived for bursty communication when
information is available infrequently at random times at the transmitter. This
result assumes that the receiver is always in the listening mode and samples
all channel outputs until it makes a decision. If the receiver is constrained
to sample only a fraction f>0 of the channel outputs, what is the cost penalty
due to sparse output sampling?
  Remarkably, there is no penalty: regardless of f>0 the asynchronous capacity
per unit cost is the same as under full sampling, ie, when f=1. There is not
even a penalty in terms of decoding delay---the elapsed time between when
information is available until when it is decoded. This latter result relies on
the possibility to sample adaptively; the next sample can be chosen as a
function of past samples. Under non-adaptive sampling, it is possible to
achieve the full sampling asynchronous capacity per unit cost, but the decoding
delay gets multiplied by 1/f. Therefore adaptive sampling strategies are of
particular interest in the very sparse sampling regime.