Just as there are frictional losses associated with moving masses on a
surface, what if there were frictional losses associated with moving
information on a substrate? Indeed, many modes of communication suffer from
such frictional losses. We propose to model these losses as proportional to
"bit-meters," i.e., the product of mass of information (i.e., the number of
bits) and the distance of information transport. We use this "information-
friction" model to understand fundamental energy requirements on encoding and
decoding in communication circuitry. First, for communication across a binary
input AWGN channel, we arrive at fundamental limits on bit-meters (and thus
energy consumption) for decoding implementations that have a predetermined
input-independent length of messages. For encoding, we relax the fixed-length
assumption and derive bounds for flexible-message- length implementations.
Using these lower bounds we show that the total (transmit + encoding +
decoding) energy-per-bit must diverge to infinity as the target error
probability is lowered to zero. Further, the closer the communication rate is
maintained to the channel capacity (as the target error-probability is lowered
to zero), the faster the required decoding energy diverges to infinity.