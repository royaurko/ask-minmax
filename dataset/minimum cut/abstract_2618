For computing the exact value of the halfspace depth of a point w.r.t. a data
cloud of $n$ points in arbitrary dimension, a theoretical framework is
suggested. Based on this framework a whole class of algorithms can be derived.
In all of these algorithms the depth is calculated as the minimum over a finite
number of depth values w.r.t. proper projections of the data cloud. Three
variants of this class are studied in more detail. All of these algorithms are
capable of dealing with data that are not in general position and even with
data that contain ties. As is shown by simulations, all proposed algorithms
prove to be very efficient.