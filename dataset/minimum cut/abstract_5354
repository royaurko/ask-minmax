A major problem for the learning of Bayesian networks (BNs) is the
exponential number of parameters needed for conditional probability tables.
Recent research reduces this complexity by modeling local structure in the
probability tables. We examine the use of log-linear local models. While
log-linear models in this context are not new (Whittaker, 1990; Buntine, 1991;
Neal, 1992; Heckerman and Meek, 1997), for structure learning they are
generally subsumed under a naive Bayes model. We describe an alternative
interpretation, and use a Minimum Message Length (MML) (Wallace, 1987) metric
for structure learning of networks exhibiting causal independence, which we
term first-order networks (FONs). We also investigate local model selection on
a node-by-node basis.