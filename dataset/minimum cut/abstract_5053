Minimum error state discrimination between two mixed states \rho and \sigma
can be aided by the receipt of "classical side information" specifying which
states from some convex decompositions of \rho and \sigma apply in each run. We
quantify this phenomena by the average trace distance, and give lower and upper
bounds on this quantity as functions of \rho and \sigma. The lower bound is
simply the trace distance between \rho and \sigma, trivially seen to be tight.
The upper bound is \sqrt{1 - tr(\rho\sigma)}, and we conjecture that this is
also tight. We reformulate this conjecture in terms of the existence of a pair
of "unbiased decompositions", which may be of independent interest, and prove
it for a few special cases. Finally, we point towards a link with a notion of
non-classicality known as preparation contextuality.