The minimum divergence estimators have proved to be useful tools in the area
of robust inference. The robustness of such estimators are measured using the
classical Influence functions. However, in many complex situations like testing
a composite hypothesis using divergence require the estimators to be restricted
into some subspace of the parameter space. The robustness of these restricted
minimum divergence estimators are very important in order to have overall
robust inference. In this paper we provide a comprehensive description of the
robustness of such restricted estimators in terms of their Influence Function
for a general class of density based divergences along with their unrestricted
versions. In particular, the robustness of some popular minimum divergence
estimators are also demonstrated under certain usual restrictions. Thus this
paper provides a general framework for the influence function analysis of a
large class of minimum divergence estimators with or without restrictions on
the parameters.