Tuning parameters in supervised learning problems are often estimated by
cross-validation. The minimum value of the cross-validation error can be biased
downward as an estimate of the test error at that same value of the tuning
parameter. We propose a simple method for the estimation of this bias that uses
information from the cross-validation process. As a result, it requires
essentially no additional computation. We apply our bias estimate to a number
of popular classifiers in various settings, and examine its performance.