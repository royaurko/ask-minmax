In many polarimetry applications, including observations in the X-ray band,
the measurement of a polarization signal can be reduced to the detection and
quantification of a deviation from uniformity of a distribution of measured
angles. We explore the statistics of such polarization measurements using Monte
Carlo simulations and chi-squared fitting methods. We compare our results to
those derived using the traditional probability density used to characterize
polarization measurements and quantify how they deviate as the intrinsic
modulation amplitude grows. We derive relations for the number of counts
required to reach a given detection level (parameterized by beta, the "number
of sigma's" of the measurement) appropriate for measuring the modulation
amplitude by itself (single interesting parameter case) or jointly with the
position angle (two interesting parameters case). We show that for the former
case when the intrinsic amplitude is equal to the well known minimum detectable
polarization (MDP) it is, on average, detected at the 3-sigma level. For the
latter case, when one requires a joint measurement at the same confidence
level, then more counts are needed than that required to achieve the MDP level.
This additional factor is amplitude-dependent, but is approximately 2.2 for
intrinsic amplitudes less than about 20%. It decreases slowly with amplitude
and is 1.8 when the amplitude is 50%. We find that the position angle
uncertainty at 1-sigma confidence is well described by the relation 28.5 (deg)
/ beta.