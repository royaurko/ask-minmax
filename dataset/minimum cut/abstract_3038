Recent results strongly challenge the canonical picture of massive star
winds: various evidence indicates that currently accepted mass-loss rates,
Mdot, may need to be revised downwards significantly. This is because the most
commonly used mass-loss diagnostics are affected by ``clumping'' (small-scale
density inhomogeneities), influencing our interpretation of observed spectra
and fluxes. Such downward revisions would have dramatic consequences for the
evolution of, and feedback from, massive stars, and thus robust determinations
of the clumping properties and mass-loss rates are urgently needed. Here, we
present a first attempt to constrain the radial stratification of the so-called
clumping factor. To this end, we have analyzed a sample of 19 Galactic O-type
supergiants/giants, by combining data for Halpha, IR, mm and radio fluxes, and
using appropriate analysis methods. Clumping has been included into our
analysis in the ``conventional'' way, by assuming the inter-clump matter to be
void. Because (almost) all our diagnostics depends on the square of density, we
cannot derive absolute clumping factors, but only factors normalized to a
certain minimum. This minimum was usually found to be located in the outermost,
radio-emitting region, i.e., the radio mass-loss rates are the lowest ones,
compared to Mdot derived from Halpha and the IR. The radio rates agree well
with those predicted by theory, but are only upper limits, due to unknown
clumping in the outer wind. Our most important result concerns a (physical)
difference between denser and thinner winds: for denser winds, the innermost
region is more strongly clumped than the outermost one (with a normalized
clumping factor of 4.1+/-1.4), whereas thinner winds have similar clumping
properties in the inner and outer regions.