Given a probability distribution P, what is the minimum amount of bits needed
to store a value x sampled according to P, such that x can later be recovered
(except with some small probability)? Or, what is the maximum amount of uniform
randomness that can be extracted from x? Answering these and similar
information-theoretic questions typically boils down to computing so-called
smooth entropies. In this paper, we derive explicit and almost tight bounds on
the smooth entropies of n-fold product distributions.