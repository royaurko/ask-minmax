We present a model of multithreaded computation, combining fork-join and
single-instruction-multiple-data parallelisms, with an emphasis on estimating
parallelism overheads of programs written for modern many-core architectures.
We establish a Graham-Brent theorem for this model so as to estimate execution
time of programs running on a given number of streaming multiprocessors. We
evaluate the benefits of our model with four fundamental algorithms from
scientific computing. In each case, our model is used to minimize parallelism
overheads by determining an appropriate value range for a given program
parameter; moreover experimentation confirms the model's prediction.