We investigate the impact of high optical depth on the HI saturation observed
in the Perseus molecular cloud by using Arecibo HI emission and absorption
measurements toward 26 radio continuum sources. The spin temperature and
optical depth of individual HI components are derived along each line-of-sight,
enabling us to estimate the correction for high optical depth. We examine two
different methods for the correction, Gaussian decomposition and isothermal
methods, and find that they are consistent (maximum correction factor ~ 1.2)
likely due to the relatively low optical depth and insignificant contribution
from the diffuse radio continuum emission for Perseus. We apply the correction
to the optically thin HI column density on a pixel-by-pixel basis, and find
that the total HI mass increases by ~10%. Using the corrected HI column density
image and far-infrared data from the IRIS Survey, we then derive the H2 column
density on ~0.4 pc scales. For five dark and star-forming sub-regions, the HI
surface density is uniform with Sigma_HI ~ 7-9 solar mass/pc2, in agreement
with the minimum HI surface density required for shielding H2 against
photodissociation. As a result, Sigma_H2/Sigma_HI and Sigma_HI+Sigma_H2 show a
tight relation. Our results are consistent with predictions for H2 formation in
steady state and chemical equilibrium, and suggest that H2 formation is mainly
responsible for the Sigma_HI saturation in Perseus. We also compare the
optically thick HI with the observed "CO-dark" gas, and find that the optically
thick HI only accounts for ~20% of the "CO-dark" gas in Perseus.