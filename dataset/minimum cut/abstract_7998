Using observations from the literature, we show that the non-thermal radio
luminosity (L) of supernova remnants (SNRs) is a strong function of the average
gas surface density (Sigma) of the galaxy in which the remnants reside, from
normal spirals to luminous starbursts. We combine a simple theory for electron
cooling in SNRs with the observed radio luminosities to estimate the remnant
magnetic field strength (B_SNR): the correlation between L and Sigma implies
that B_SNR also increases with Sigma. We explore two interpretations of this
correlation: (1) B_SNR is generated by post-shock magnetic field amplification,
with B_SNR^2 proportional to Sigma and (2) B_SNR results from shock-compression
of the ambient ISM magnetic field (B_ISM), with B_ISM being larger in denser
galaxies. We find that shock compression is, on average, sufficient to produce
the observed radio emission from SNRs in the densest starbursts; amplification
of post-shock magnetic fields is not required. By contrast, in normal spirals
post-shock field amplification (by a factor of a few - 10) is consistent with
the data; we find tentative evidence that both the Alfven speed and the ratio
of B_SNR^2 to the post-shock pressure ("epsilon_B") are constant in SNRs from
galaxy to galaxy. We discuss observational tests that can be used to
distinguish between these two interpretations of the radio luminosities of
SNRs. Regardless of which is correct, the radio emission from SNRs provides an
upper limit to B_ISM that is independent of the minimum energy assumption. For
the densest starbursts, the ISM magnetic energy density is below that required
for hydrostatic equilibrium; thus magnetic fields are not dynamically important
on the largest scales in starbursts, in contrast with spiral galaxies like our
own. This dichotomy may have implications for galactic dynamo theory.