The physical relationship between the far-infrared and radio fluxes of star
forming galaxies has yet to be definitively determined. The favored
interpretation, the "calorimeter model," requires that supernova generated
cosmic ray (CR) electrons cool rapidly via synchrotron radiation. However, this
cooling should steepen their radio spectra beyond what is observed, and so
enhanced ionization losses at low energies from high gas densities are also
required. Further, evaluating the minimum energy magnetic field strength with
the traditional scaling of the synchrotron flux may underestimate the true
value in massive starbursts if their magnetic energy density is comparable to
the hydrostatic pressure of their disks. Gamma-ray spectra of starburst
galaxies, combined with radio data, provide a less ambiguous estimate of these
physical properties in starburst nuclei. While the radio flux is most sensitive
to the magnetic field, the GeV gamma-ray spectrum normalization depends
primarily on gas density. To this end, spectra above 100 MeV were constructed
for two nearby starburst galaxies, NGC 253 and M82, using Fermi data. Their
nuclear radio and far-infrared spectra from the literature are compared to new
models of the steady-state CR distributions expected from starburst galaxies.
Models with high magnetic fields, favoring galaxy calorimetry, are overall
better fits to the observations. These solutions also imply relatively high
densities and CR ionization rates, consistent with molecular cloud studies.