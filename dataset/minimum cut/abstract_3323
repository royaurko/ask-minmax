We estimate the effects of low temporal frequency modes in the time stream on
sky maps such as expected from the PLANCK experiment -- a satellite mission
designed to image the sky in the microwave band. We perform the computations in
a semi-analytic way based on a simple model of PLANCK observations, which
permits an insight into the structure of noise correlations of PLANCK-like
maps, without doing exact, computationally intensive numerical calculations. We
show that, for a set of plausible scanning strategies, marginalization over
temporal frequency modes with frequencies lower than the spin frequency of the
satellite (= 1/60 Hz) causes a nearly negligible deterioration of a quality of
the resulting sky maps. We point out that this observation implies that it
should be possible to successfully remove effects of long-term time domain
parasitic signals from the PLANCK maps during the data analysis stage.