Measurements of explosive nucleosynthesis yields in core-collapse supernovae
provide tests for explosion models. We investigate constraints on explosive
conditions derivable from measured amounts of nickel and iron after radioactive
decays using nucleosynthesis networks with parameterized thermodynamic
trajectories. The Ni/Fe ratio is for most regimes dominated by the production
ratio of 58Ni/(54Fe + 56Ni), which tends to grow with higher neutron excess and
with higher entropy. For SN 2012ec, a supernova that produced a Ni/Fe ratio of
$3.4\pm1.2$ times solar, we find that burning of a fuel with neutron excess
$\eta \approx 6\times 10^{-3}$ is required. Unless the progenitor metallicity
is over 5 times solar, the only layer in the progenitor with such a neutron
excess is the silicon shell. Supernovae producing large amounts of stable
nickel thus suggest that this deep-lying layer can be, at least partially,
ejected in the explosion. We find that common spherically symmetric models of
$M_{\rm ZAMS} \lesssim 13$ Msun stars exploding with a delay time of less than
one second ($M_{\rm cut} < 1.5$ Msun) are able to achieve such silicon-shell
ejection. Supernovae that produce solar or sub-solar Ni/Fe ratios, such as SN
1987A, must instead have burnt and ejected only oxygen-shell material, which
allows a lower limit to the mass cut to be set. Finally, we find that the
extreme Ni/Fe value of 60-75 times solar derived for the Crab cannot be
reproduced by any realistic-entropy burning outside the iron core, and
neutrino-neutronization obtained in electron-capture models remains the only
viable explanation.