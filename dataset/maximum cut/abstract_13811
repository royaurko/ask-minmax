Undirected graphs are often used to describe high dimensional distributions.
Under sparsity conditions, the graph can be estimated using
$\ell_1$-penalization methods. We propose and study the following method. We
combine a multiple regression approach with ideas of thresholding and
refitting: first we infer a sparse undirected graphical model structure via
thresholding of each among many $\ell_1$-norm penalized regression functions;
we then estimate the covariance matrix and its inverse using the maximum
likelihood estimator. We show that under suitable conditions, this approach
yields consistent estimation in terms of graphical structure and fast
convergence rates with respect to the operator and Frobenius norm for the
covariance matrix and its inverse. We also derive an explicit bound for the
Kullback Leibler divergence.