Identifying leading measurement units from a large collection is a common
inference task in various domains of large-scale inference. Testing approaches,
which measure evidence against a null hypothesis rather than effect magnitude,
tend to overpopulate lists of leading units with those associated with low
measurement error. By contrast, local maximum likelihood (ML) approaches tend
to favor units with high measurement error. Available Bayesian and empirical
Bayesian approaches rely on specialized loss functions that result in similar
deficiencies. We describe and evaluate a generic empirical Bayesian ranking
procedure that populates the list of top units in a way that maximizes the
expected overlap between the true and reported top lists for all list sizes.
The procedure relates unit-specific posterior upper tail probabilities with
their empirical distribution to yield a ranking variable. It discounts
high-variance units less than popular non-ML methods and thus achieves improved
operating characteristics in the models considered.