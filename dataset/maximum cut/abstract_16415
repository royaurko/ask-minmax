Gravitational radiation drives an instability in the r-modes of young rapidly
rotating neutron stars. This instability is expected to carry away most of the
angular momentum of the star by gravitational radiation emission, leaving a
star rotating at about 100 Hz. In this paper we model in a simple way the
development of the instability and evolution of the neutron star during the
year-long spindown phase. This allows us to predict the general features of the
resulting gravitational waveform. We show that a neutron star formed in the
Virgo cluster could be detected by the LIGO and VIRGO gravitational wave
detectors when they reach their ``enhanced'' level of sensitivity, with an
amplitude signal-to-noise ratio that could be as large as about 8 if
near-optimal data analysis techniques are developed. We also analyze the
stochastic background of gravitational waves produced by the r-mode radiation
from neutron-star formation throughout the universe. Assuming a substantial
fraction of neutron stars are born with spin frequencies near their maximum
values, this stochastic background is shown to have an energy density of about
10^-9 of the cosmological closure density, in the range 20 Hz to 1 kHz. This
radiation should be detectable by ``advanced'' LIGO as well.