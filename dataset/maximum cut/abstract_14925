The computation of the sparse principal component of a matrix is equivalent
to the identification of its principal submatrix with the largest maximum
eigenvalue. Finding this optimal submatrix is what renders the problem
${\mathcal{NP}}$-hard. In this work, we prove that, if the matrix is positive
semidefinite and its rank is constant, then its sparse principal component is
polynomially computable. Our proof utilizes the auxiliary unit vector technique
that has been recently developed to identify problems that are polynomially
solvable. Moreover, we use this technique to design an algorithm which, for any
sparsity value, computes the sparse principal component with complexity
${\mathcal O}\left(N^{D+1}\right)$, where $N$ and $D$ are the matrix size and
rank, respectively. Our algorithm is fully parallelizable and memory efficient.