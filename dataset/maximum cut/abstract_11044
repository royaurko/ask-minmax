The paper aims at reconsidering the famous Le Cam LAN theory. The main
features of the approach which make it different from the classical one are as
follows: (1) the study is nonasymptotic, that is, the sample size is fixed and
does not tend to infinity; (2) the parametric assumption is possibly
misspecified and the underlying data distribution can lie beyond the given
parametric family. These two features enable to bridge the gap between
parametric and nonparametric theory and to build a unified framework for
statistical estimation. The main results include large deviation bounds for the
(quasi) maximum likelihood and the local quadratic bracketing of the
log-likelihood process. The latter yields a number of important corollaries for
statistical inference: concentration, confidence and risk bounds, expansion of
the maximum likelihood estimate, etc. All these corollaries are stated in a
nonclassical way admitting a model misspecification and finite samples.
However, the classical asymptotic results including the efficiency bounds can
be easily derived as corollaries of the obtained nonasymptotic statements. At
the same time, the new bracketing device works well in the situations with
large or growing parameter dimension in which the classical parametric theory
fails. The general results are illustrated for the i.i.d. setup as well as for
generalized linear and median estimation. The results apply for any dimension
of the parameter space and provide a quantitative lower bound on the sample
size yielding the root-n accuracy.