We propose a novel language-independent approach for improving machine
translation for resource-poor languages by exploiting their similarity to
resource-rich ones. More precisely, we improve the translation from a
resource-poor source language X_1 into a resource-rich language Y given a
bi-text containing a limited number of parallel sentences for X_1-Y and a
larger bi-text for X_2-Y for some resource-rich language X_2 that is closely
related to X_1. This is achieved by taking advantage of the opportunities that
vocabulary overlap and similarities between the languages X_1 and X_2 in
spelling, word order, and syntax offer: (1) we improve the word alignments for
the resource-poor language, (2) we further augment it with additional
translation options, and (3) we take care of potential spelling differences
through appropriate transliteration. The evaluation for Indonesian- >English
using Malay and for Spanish -> English using Portuguese and pretending Spanish
is resource-poor shows an absolute gain of up to 1.35 and 3.37 BLEU points,
respectively, which is an improvement over the best rivaling approaches, while
using much less additional data. Overall, our method cuts the amount of
necessary "real training data by a factor of 2--5.