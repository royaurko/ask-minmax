We study the effect of communication delays on distributed consensus
algorithms. Two ways to model delays on a network are presented. The first
model assumes that each link delivers messages with a fixed (constant) amount
of delay, and the second model is more realistic, allowing for i.i.d.
time-varying bounded delays. In contrast to previous work studying the effects
of delays on consensus algorithms, the models studied here allow for a node to
receive multiple messages from the same neighbor in one iteration. The analysis
of the fixed delay model shows that convergence to a consensus is guaranteed
and the rate of convergence is reduced by no more than a factor O(B^2) where B
is the maximum delay on any link. For the time-varying delay model we also give
a convergence proof which, for row-stochastic consensus protocols, is not a
trivial consequence of ergodic matrix products. In both delay models, the
consensus value is no longer the average, even if the original protocol was an
averaging protocol. For this reason, we propose the use of a different
consensus algorithm called Push-Sum [Kempe et al. 2003]. We model delays in the
Push-Sum framework and show that convergence to the average consensus is
guaranteed. This suggests that Push-Sum might be a better choice from a
practical standpoint.