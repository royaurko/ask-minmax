A general framework is that the estimators of a distribution are obtained by
minimizing a function (the estimating function) and they are assessed through
another function (the assessment function). The estimating and assessment
functions generally estimate risks. A classical case is that both functions
estimate an information risk (specifically cross entropy); in that case Akaike
information criterion (AIC) is relevant. In more general cases, the assessment
risk can be estimated by leave-one-out crossvalidation. Since leave-one-out
crossvalidation is computationally very demanding, an approximation formula can
be very useful. A universal approximate crossvalidation criterion (UACV) for
the leave-one-out crossvalidation is given. This criterion can be adapted to
different types of estimators, including penalized likelihood and maximum a
posteriori estimators, and of assessment risk functions, including information
risk functions and continuous rank probability score (CRPS). This formula
reduces to Takeuchi information criterion (TIC) when cross entropy is the risk
for both estimation and assessment. The asymptotic distribution of UACV and of
a difference of UACV is given. UACV can be used for comparing estimators of the
distributions of ordered categorical data derived from threshold models and
models based on continuous approximations. A simulation study and an analysis
of real psychometric data are presented.