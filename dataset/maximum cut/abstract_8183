In a Bayesian approach for solving linear inverse problems one needs to
specify the prior laws for calculation of the posterior law. A cost function
can also be defined in order to have a common tool for various Bayesian
estimators which depend on the data and the hyperparameters. The Gaussian case
excepted, these estimators are not linear and so depend on the scale of the
measurements. In this paper a weaker property than linearity is imposed on the
Bayesian estimator, namely the scale invariance property (SIP).First, we state
some results on linear estimation and then we introduce and justify a scale
invariance axiom. We show that arbitrary choice of scale measurement can be
avoided if the estimator has this SIP. Some examples of classical
regularization procedures are shown to be scale invariant. Then we investigate
general conditions on classes of Bayesian estimators which satisfy this SIP, as
well as their consequences on the cost function and prior laws. We also show
that classical methods for hyperparameters estimation (i.e., Maximum Likelihood
and Generalized Maximum Likelihood) can be introduced for hyperparameters
estimation, and we verify the SIP property for them. Finally we discuss how to
choose the prior laws to obtain scale invariant Bayesian estimators. For this,
we consider two cases of prior laws: {\em entropic prior laws} and {\em
first-order Markov models}. In related preceding works
[Mohammad-Djafari90,Mohammad-Djafari93], the SIP constraints have been studied
for the case of entropic prior laws. In this paper extension to the case of
first-order Markov models is provided. KEYWORDS: Bayesian estimation, Scale
invariance, Markov modelling, Inverse Problems, Image reconstruction, Prior
model selection