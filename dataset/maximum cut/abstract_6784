In this technical report, we consider conditional density estimation with a
maximum likelihood approach. Under weak assumptions, we obtain a theoretical
bound for a Kullback-Leibler type loss for a single model maximum likelihood
estimate. We use a penalized model selection technique to select a best model
within a collection. We give a general condition on penalty choice that leads
to oracle type inequality for the resulting estimate. This construction is
applied to two examples of partition-based conditional density models, models
in which the conditional density depends only in a piecewise manner from the
covariate. The first example relies on classical piecewise polynomial densities
while the second uses Gaussian mixtures with varying mixing proportion but same
mixture components. We show how this last case is related to an unsupervised
segmentation application that has been the source of our motivation to this
study.