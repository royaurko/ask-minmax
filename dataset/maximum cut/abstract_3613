We present a systematic study of the reconstruction of a non-negative
function via maximum entropy approach utilizing the information contained in a
finite number of moments of the function. For testing the efficacy of the
approach, we reconstruct a set of functions using an iterative entropy
optimization scheme, and study the convergence profile as the number of moments
is increased. We consider a wide variety of functions that include a
distribution with a sharp discontinuity, a rapidly oscillatory function, a
distribution with singularities, and finally a distribution with several spikes
and fine structure. The last example is important in the context of the
determination of the natural density of the logistic map. The convergence of
the method is studied by comparing the moments of the approximated functions
with the exact ones. Furthermore, by varying the number of moments and
iterations, we examine to what extent the features of the functions, such as
the divergence behavior at singular points within the interval, is reproduced.
The proximity of the reconstructed maximum entropy solution to the exact
solution is examined via Kullback-Leibler divergence and variation measures for
different number of moments.