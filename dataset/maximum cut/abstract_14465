This note describes non-asymptotic variance and tail bounds for order
statistics of samples of independent identically distributed random variables.
Those bounds are checked to be asymptotically tight when the sampling
distribution belongs to a maximum domain of attraction. If the sampling
distribution has non-decreasing hazard rate (this includes the Gaussian
distribution), we derive an exponential Efron-Stein inequality for order
statistics: an inequality connecting the logarithmic moment generating function
of centered order statistics with exponential moments of Efron-Stein
(jackknife) estimates of variance. We use this general connection to derive
variance and tail bounds for order statistics of Gaussian sample. Those bounds
are not within the scope of the Tsirelson-Ibragimov-Sudakov
  Gaussian concentration inequality. Proofs are elementary and combine
R\'enyi's representation of order statistics and the so-called entropy approach
to concentration inequalities popularized by M. Ledoux.