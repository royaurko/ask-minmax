Motivated, in part, by the desire to develop an information-theoretic
foundation for compound Poisson approximation limit theorems (analogous to the
corresponding developments for the central limit theorem and for simple Poisson
approximation), this work examines sufficient conditions under which the
compound Poisson distribution has maximal entropy within a natural class of
probability measures on the nonnegative integers. We show that the natural
analog of the Poisson maximum entropy property remains valid if the measures
under consideration are log-concave, but that it fails in general. A parallel
maximum entropy result is established for the family of compound binomial
measures. The proofs are largely based on ideas related to the semigroup
approach introduced in recent work by Johnson for the Poisson family.
Sufficient conditions are given for compound distributions to be log-concave,
and specific examples are presented illustrating all the above results.