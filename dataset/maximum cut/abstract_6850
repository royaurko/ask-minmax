If the log likelihood is approximately quadratic with constant Hessian, then
the maximum likelihood estimator (MLE) is approximately normally distributed.
No other assumptions are required. We do not need independent and identically
distributed data. We do not need the law of large numbers (LLN) or the central
limit theorem (CLT). We do not need sample size going to infinity or anything
going to infinity. Presented here is a combination of Le Cam style theory
involving local asymptotic normality (LAN) and local asymptotic mixed normality
(LAMN) and Cram\'er style theory involving derivatives and Fisher information.
The main tool is convergence in law of the log likelihood function and its
derivatives considered as random elements of a Polish space of continuous
functions with the metric of uniform convergence on compact sets. We obtain
results for both one-step-Newton estimators and Newton-iterated-to-convergence
estimators.