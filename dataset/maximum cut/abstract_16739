The paper considers functional linear regression, where scalar responses
$Y_1,...,Y_n$ are modeled in dependence of random functions $X_1,...,X_n$. We
propose a smoothing splines estimator for the functional slope parameter based
on a slight modification of the usual penalty. Theoretical analysis
concentrates on the error in an out-of-sample prediction of the response for a
new random function $X_{n+1}$. It is shown that rates of convergence of the
prediction error depend on the smoothness of the slope function and on the
structure of the predictors. We then prove that these rates are optimal in the
sense that they are minimax over large classes of possible slope functions and
distributions of the predictive curves. For the case of models with
errors-in-variables the smoothing spline estimator is modified by using a
denoising correction of the covariance matrix of discretized curves. The
methodology is then applied to a real case study where the aim is to predict
the maximum of the concentration of ozone by using the curve of this
concentration measured the preceding day.