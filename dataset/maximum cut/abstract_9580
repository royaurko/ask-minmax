We develop a qualitative theory of Markov Decision Processes (MDPs) and
Partially Observable MDPs that can be used to model sequential decision making
tasks when only qualitative information is available. Our approach is based
upon an order-of-magnitude approximation of both probabilities and utilities,
similar to epsilon-semantics. The result is a qualitative theory that has close
ties with the standard maximum-expected-utility theory and is amenable to
general planning techniques.