Do two data samples come from different distributions? Recent studies of this
fundamental problem focused on embedding probability distributions into
sufficiently rich characteristic Reproducing Kernel Hilbert Spaces (RKHSs), to
compare distributions by the distance between their embeddings. We show that
Regularized Maximum Mean Discrepancy (RMMD), our novel measure for kernel-based
hypothesis testing, yields substantial improvements even when sample sizes are
small, and excels at hypothesis tests involving multiple comparisons with power
control. We derive asymptotic distributions under the null and alternative
hypotheses, and assess power control. Outstanding results are obtained on:
challenging EEG data, MNIST, the Berkley Covertype, and the Flare-Solar
dataset.