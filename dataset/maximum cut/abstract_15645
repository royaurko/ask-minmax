The thermal history of a large class of running vacuum models in which the
effective cosmological term is a truncated power series of the Hubble rate,
whose dominant term is $\Lambda (H) \propto H^{n+2}$, is discussed in detail.
Specifically, the temperature evolution law and the increasing entropy function
are analytically calculated. For the whole class of vacuum models explored here
we find that the primeval value of the comoving radiation entropy density
(associated to effectively massless particles) starts from zero and evolves
extremely fast until reaching a maximum near the end of the vacuum decay phase,
where it saturates in the present day value within the current Hubble radius.
We find that the whole class of running vacuum models predicts the same correct
value of the total entropy at present, $S_{0} \sim 10^{88}$ (in natural units),
independently of the initial conditions. If, however, we impose the
Gibbons-Hawking temperature as an initial condition, we find that the ratio
between the primeval and late time vacuum energy densities is
$\rho_{vI}/\rho_{v0} \sim 10^{123}$.