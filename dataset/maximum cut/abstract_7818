The accuracy and reliability of gamma-ray bursts (GRBs) as distance
indicators are strongly restricted by their systematic errors which are larger
than statistical errors. These systematic errors might come from either
intrinsic variations of GRBs, or systematic errors in observations. In this
paper, we consider the possible origins of systematic errors in the following
observables, (i) the spectral peak energies (Ep) estimated by Cut-off power law
(CPL) function, (ii) the peak luminosities (Lp) estimated by 1 second in
observer time. Removing or correcting them, we reveal the true intrinsic
variation of the Ep-TL-Lp relation of GRBs. Here TL is the third parameter of
GRBs defined as TL ~ Eiso / Lp. Not only the time resolution of Lp is converted
from observer time to GRB rest frame time, the time resolution with the largest
likelihood is sought for. After removing obvious origin of systematic errors in
observation mentioned above, there seems to be still remain some outliers. For
this reason, we take account another origin of the systematic error as below,
(iii) the contamination of short GRBs or other populations. To estimate the
best fit parameters of the Ep-TL-Lp relations from data including outliers, we
develop a new method which combine robust regression and an outlier
identification technique. Using our new method for 18 GRBs with {\sigma}Ep/Ep <
0.1, we detect 6 outliers and find the Ep-TL-Lp relation become the tightest
around 3 second.