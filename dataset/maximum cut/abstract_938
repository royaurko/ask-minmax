We give a new proof of the theorems on the maximum entropy principle in
Tsallis statistics. That is, we show that the $q$-canonical distribution
attains the maximum value of the Tsallis entropy, subject to the constraint on
the $q$-expectation value and the $q$-Gaussian distribution attains the maximum
value of the Tsallis entropy, subject to the constraint on the $q$-variance, as
applications of the nonnegativity of the Tsallis relative entropy, without
using the Lagrange multipliers method. In addition, we define a $q$-Fisher
information and then prove a $q$-Cram\'er-Rao inequality that the $q$-Gaussian
distribution with special $q$-variances attains the minimum value of the
$q$-Fisher information.