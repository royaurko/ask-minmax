The Fisher information matrix (FIM) has long been of interest in statistics
and other areas. It is widely used to measure the amount of information and
calculate the lower bound for the variance for maximum likelihood estimation
(MLE). In practice, we do not always know the actual FIM. This is often because
obtaining the first or second-order derivatives of the log-likelihood function
is difficult, or simply because the calculation of FIM is too formidable. In
such cases, we need to utilize the approximation of FIM. In general, there are
two ways to estimate FIM. One is to use the product of gradient and the
transpose of itself, and the other is to calculate the Hessian matrix and then
take negative sign. Mostly people use the latter method in practice. However,
this is not necessarily the optimal way. To find out which of the two methods
is better, we need to conduct a theoretical study to compare their efficiency.
In this paper we mainly focus on the case where the unknown parameter that
needs to be estimated by MLE is scalar and the random variables we have are
independent. In this scenario, Fisher information matrix is virtually Fisher
information number (FIN). Using the Central Limit Theorem (CLT), we get
asymptotic variances for the two methods, by which we compare their accuracy.
Taylor expansion assists in estimating the two asymptotic variances. A
numerical study is provided as an illustration of the conclusion. The next is a
summary of limitations of this paper. We also enumerate several fields of
interest for future study in the end of this paper.
  Key words: Fisher information matrix, Fisher information number, the Central
Limit Theorem, Taylor expansion, asymptotic variance.