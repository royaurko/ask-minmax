A new goodness-of-fit test for normality in high-dimension (and Reproducing
Kernel Hilbert Space) is proposed. It shares common ideas with the Maximum Mean
Discrepancy (MMD) it outperforms both in terms of computation time and
applicability to a wider range of data. Theoretical results are derived for the
Type-I and Type-II errors. They guarantee the control of Type-I error at
prescribed level and an exponentially fast decrease of the Type-II error.
Synthetic and real data also illustrate the practical improvement allowed by
our test compared with other leading approaches in high-dimensional settings.