A new nonparametric approach for system identification has been recently
proposed where the impulse response is modeled as the realization of a
zero-mean Gaussian process whose covariance (kernel) has to be estimated from
data. In this scheme, quality of the estimates crucially depends on the
parametrization of the covariance of the Gaussian process. A family of kernels
that have been shown to be particularly effective in the system identification
framework is the family of Diagonal/Correlated (DC) kernels. Maximum entropy
properties of a related family of kernels, the Tuned/Correlated (TC) kernels,
have been recently pointed out in the literature. In this paper we show that
maximum entropy properties indeed extends to the whole family of DC kernels.
The maximum entropy interpretation can be exploited in conjunction with results
on matrix completion problems in the graphical models literature to shed light
on the structure of the DC kernel. In particular, we prove that DC kernels
admit a closed-form inverse, determinant and factorization. Maximum likelihood
properties of the DC kernel are also highlighted. These results can be
exploited both to improve the stability and to reduce the computational
complexity associated with the computation of DC estimators, as detailed in the
paper.