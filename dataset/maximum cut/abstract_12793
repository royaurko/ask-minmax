Although commonly employed by X-ray astronomers, maximum likelihood
estimators are known to be biased. In this paper we investigate the bias
associated to the measure of the temperature from an X-ray thermal spectrum. We
show that, in the case of low surface brightness regions, commonly adopted
estimators, such as those based on chi squared and Cash statistics, return
strongly biased results. We stress that this can have strong implications when
measuring the temperature of cluster outer regions with current experiments. We
consider various approaches to overcome this problem, the most effective is a
technique which allows us to correct the bias a posteriori. Extensive
montecarlo simulations show that our correction returns excellent results under
different conditions.