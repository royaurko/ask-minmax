The effects of relativistic expansion on the late-time supernova light curves
are investigated analytically, and a correction term to the (quasi-)exponential
decay is obtained by expanding the observed flux in terms of (\beta), where
(\beta) is the maximum velocity of the ejecta divided by the speed of light
(c). It is shown that the Doppler effect brightens the light curve owing to the
delayed decay of radioactive nuclei as well as to the Lorentz boosting of the
photon energies. The leading correction term is quadratic in (\beta), thus
being proportional to (E_{\rm k}/(M_{\rm ej} c^2)), where (E_{\rm k}) and
(M_{\rm ej}) are the kinetic energy of explosion and the ejecta mass. It is
also shown that the correction term evolves as a quadratic function of time
since the explosion. The relativistic effect is negligibly small at early
phases, but becomes of considerable size at late phases. In particular, for
supernove having a very large energy(hypernova) or exploding in a jet-like or
whatever non-spherical geometry, (^{56})Ni is likely to be boosted to higher
velocities and then we might see an appreciable change in flux. However, the
actual size of deviation from the (quasi-)exponential decay will be uncertain,
depending on other possible effects such as ionization freeze-out and
contributions from other energy sources that power the light curve.