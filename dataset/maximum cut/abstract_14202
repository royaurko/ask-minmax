We consider regression models involving multilayer perceptrons (MLP) with one
hidden layer and a Gaussian noise. The data are assumed to be generated by a
true MLP model and the estimation of the parameters of the MLP is done by
maximizing the likelihood of the model. When the number of hidden units of the
true model is known, the asymptotic distribution of the maximum likelihood
estimator (MLE) and the likelihood ratio (LR) statistic is easy to compute and
converge to a $\chi^2$ law. However, if the number of hidden unit is
over-estimated the Fischer information matrix of the model is singular and the
asymptotic behavior of the MLE is unknown. This paper deals with this case, and
gives the exact asymptotic law of the LR statistics. Namely, if the parameters
of the MLP lie in a suitable compact set, we show that the LR statistics is the
supremum of the square of a Gaussian process indexed by a class of limit score
functions.