In inflationary models, gravitational waves are produced and generate B-type
polarization in the CMB. Since B polarization is only generated by gravity
waves it does not suffer from the cosmic variance. A perfect decomposition of
the CMB into B-modes and E-modes would require data from the entire sky, which
in practice is not possible because of the foreground contaminants. This leads
to mixing of E polarization into B, which introduces cosmic variance conta-
mination of B polarization and reduces sensitivity to gravity wave amplitude
even in absence of detector noise. We present numerical results for the
uncertainty in the tensor-to-scalar ratio using the Fisher matrix formalism for
various resolutions, using foreground models based on dust maps and assuming 90
GHz operating frequency. We find that the usual scaling delta(T/S) ~
f_sky^(-1/2) is significantly degraded and becomes delta(T/S) ~ f_sky^(-2) for
f_sky>0.7. This dependence is affected only weakly by the choice of sky cuts.
To achieve a T/S=10^(-3) detection at 3 sigma one needs to observe 15% of the
sky as opposed to naive expectation of 0.3%. To prevent contamination over this
large sky area at required level one must be able to remove polarized dust
emission at or better than 0.1% of unpolarized intensity, assuming the cleanest
part of the sky has been chosen. To achieve T/S=10^(-4) detection at 3 sigma
one needs to observe 70% of the sky, which is only possible if dust emission is
removed everywhere over this region at 0.01% level. Reaching T/S=10^(-2) should
be easier: 1% of the sky is needed over which polarized emission needs to be
removed at 1% of total intensity if the cleanest region is chosen. These
results suggest that foreground contamination may make it difficult to achieve
levels below T/S=10^(-3). (abridged)