Low-rank matrix estimation from incomplete measurements recently received
increased attention due to the emergence of several challenging applications,
such as recommender systems; see in particular the famous Netflix challenge.
While the behaviour of algorithms based on nuclear norm minimization is now
well understood, an as yet unexplored avenue of research is the behaviour of
Bayesian algorithms in this context. In this paper, we briefly review the
priors used in the Bayesian literature for matrix completion. A standard
approach is to assign an inverse gamma prior to the singular values of a
certain singular value decomposition of the matrix of interest; this prior is
conjugate. However, we show that two other types of priors (again for the
singular values) may be conjugate for this model: a gamma prior, and a discrete
prior. Conjugacy is very convenient, as it makes it possible to implement
either Gibbs sampling or Variational Bayes. Interestingly enough, the maximum a
posteriori for these different priors is related to the nuclear norm
minimization problems. We also compare all these priors on simulated datasets,
and on the classical MovieLens and Netflix datasets.