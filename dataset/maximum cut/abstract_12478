The probability that a number in many naturally occurring tables of numerical
data has first significant digit $d$ is predicted by Benford's Law ${\rm Prob}
(d) = \log_{10} (1 + {\displaystyle{1\over d}}), d = 1, 2 >..., 9$.
Illustrations of Benford's Law from both theoretical and real-life sources on
both science and social science areas are shown in detail with some novel ideas
and generalizations developed solely by the contributors of this paper. Three tests,
Chi-Square test, total variation distance, and maximum deviations are adopted
to examine the fitness of the datasets to Benford's distribution. Finally,
applications of Benford's Law are summarized and explored to reveal the power
of this mathematical principle.