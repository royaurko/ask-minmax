Maximum entropy models, motivated by applications in neuron science, are
natural generalizations of the $\beta$-model to weighted graphs. Similar to the
$\beta$-model, each vertex in maximum entropy models is assigned a potential
parameter, and the degree sequence is the natural sufficient statistic. Hillar
and Wibisono (2013) has proved the consistency of the maximum likelihood
estimators. In this paper, we further establish the asymptotic normality for
any finite number of the maximum likelihood estimators in the maximum entropy
models with three types of edge weights, when the total number of parameters
goes to infinity. Simulation studies are provided to illustrate the asymptotic
results.