We consider the smoothing probabilities of hidden Markov model (HMM). We show
that under fairly general conditions for HMM, the exponential forgetting still
holds, and the smoothing probabilities can be well approximated with the ones
of double sided HMM. This makes it possible to use ergodic theorems. As an
applications we consider the pointwise maximum a posteriori segmentation, and
show that the corresponding risks converge.