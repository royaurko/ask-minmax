The Renyi entropy with a free Renyi parameter $q$ is the most justified form
of information entropy, and the Tsallis entropy may be regarded as a linear
approximation to the Renyi entropy when $q\simeq 1$. When $q\to 1$, both
entropies go to the Boltzmann--Shannon entropy. The application of the
principle of maximum of information entropy (MEP) to the Renyi entropy gives
rise to the microcanonical (homogeneous) distribution for an isolated system.
Whatever the value of the Renyi parameter $q$ is, in this case the Renyi
entropy becomes the Boltzmann entropy $S_B=k_B\ln W$, that provides support for
universality of the Boltzmann's principle of statistical mechanics. For a
system being in contact with a heat bath, the application of MEP to the Renyi
entropy gives rise to Levy distribution (or, $q$-distribution) accepted as one
of the main results of the so-called nonextensive statistics. The same
distribution is derived here for a small physical system experiencing
temperature fluctuations. The long--range "tail" of the Levy distribution is
the power--law (Zipf-Pareto) distribution with the exponent $s$ expressed via
$q$. The exponent and free Renyi parameter $q$ can be uniquely determined with
the use of a further extension of MEP. Then typical values of $s$ are found
within the range $1.3\div 2$ and of $q$ within the range $0.25\div 0.5$, in
dependence on parameters of stochastic systems.