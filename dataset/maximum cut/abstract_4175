It is a generally known problem that the behaviour predicted from
perturbation theory for asymptotically free theories like QCD, i.e. asymptotic
scaling, has not been observed in Monte Carlo simulations when the series is
expressed in terms of the bare coupling g_0. This discrepancy has been
explained in the past with the poor convergence properties of the perturbative
series in the g_0. An alternative point of view, called Lattice-Distorted
Perturbation Theory proposes that lattice artifacts due to the finiteness of
the lattice spacing, a, cause the disagreement between Monte Carlo data and
perturbative scaling. Following this alternative scenario, we fit recent
quenched data from different observables to fitting functions that include
these cut-off effects, confirming that the lattice data are well reproduced by
g_0-PT with the simple addition of terms O(a^n).