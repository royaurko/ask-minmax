In this article we present an account of the state-of-the-art in acoustic
scene classification (ASC), the task of classifying environments from the
sounds they produce. Starting from a historical review of previous research in
this area, we define a general framework for ASC and present different imple-
mentations of its components. We then describe a range of different algorithms
submitted for a data challenge that was held to provide a general and fair
benchmark for ASC techniques. The dataset recorded for this purpose is
presented, along with the performance metrics that are used to evaluate the
algorithms and statistical significance tests to compare the submitted methods.
We use a baseline method that employs MFCCS, GMMS and a maximum likelihood
criterion as a benchmark, and only find sufficient evidence to conclude that
three algorithms significantly outperform it. We also evaluate the human
classification accuracy in performing a similar classification task. The best
performing algorithm achieves a mean accuracy that matches the median accuracy
obtained by humans, and common pairs of classes are misclassified by both
computers and humans. However, all acoustic scenes are correctly classified by
at least some individuals, while there are scenes that are misclassified by all
algorithms.