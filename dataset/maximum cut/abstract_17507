It is important to detect a low-dimensional linear dependency in
high-dimensional data. We provide a perspective on this problem, called the
rank-extreme (ReX) association, through studies of the maximum norm of a vector
of $p$ standard Gaussian variables that has a covariance matrix of rank $d \le
p$. We find a simple asymptotic upper bound of such extreme values as
$\sqrt{d(1-p^{-2/(d-1)})}$. This upper bound is shown to be sharp when the
entries of the correlation matrix are generated by inner products of i.i.d.
uniformly distributed unit vectors. This upper bound also takes on an
interesting trichotomy phenomenon depending on the limit of $d/\log{p}$. Based
on this ReX approach, we propose several methods for high-dimensional
inference. These applications include a test of the overall significance in
regressions, a refinement of valid post-selection inference when the size of
selected models is restricted, a classification of deficient ranks based on the
magnitude of the extreme, and an inference method for low-ranks. One advantage
of this approach is that the asymptotics are in the dimensions $d$ and $p$ but
not in the sample size $n$. Thus, the inference can be made even when $n < d
\le p$, which allows fast detection of low-dimensional structure. Furthermore,
the higher the dimension is, the more accurate the inference is. Therefore,
these results can be regarded as a "blessing of dimensionality."