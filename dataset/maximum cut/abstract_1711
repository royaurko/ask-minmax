The main purpose of this paper is to introduce and study the behavior of
minimum {\phi}-divergence estimators as an alternative to the maximum
likelihood estimator in latent class models for binary items. As it will become
clear below, minimum {\phi}-divergence estimators are a natural extension of
the maximum likelihood estimator. The asymptotic properties of minimum
{\phi}-divergence estimators for latent class models for binary data are
developed. Finally, to compare the efficiency and robustness of these new
estimators with those obtained through maximum likelihood when the sample size
is not big enough to apply the asymptotic results, we have carried out a
simulation study.