American Sign Language (ASL) uses a series of hand based gestures as a
replacement for words to allow the deaf to communicate. Previous work has shown
that although it takes longer to make signs than to say the equivalent words,
on average sentences can be completed in about the same time. This leaves
unresolved, however, precisely why that should be the case. This paper reports
a determination of the empirical entropy and redundancy in the set of
handshapes of ASL. In this context, the entropy refers to the average
information content in a unit of data. It is found that the handshapes, as
fundamental units of ASL, are less redundant than phonemes, the equivalent
fundamental units of spoken English, and that their entropy is much closer to
the maximum possible information content. This explains why the slower signs
can produce sentences in the same time as speaking; the low redundancy
compensates for the slow rate of sign production. In addition to this precise
quantification, this work is also novel in its approach towards quantifying an
aspect of the ASL alphabet. Unlike spoken and written languages, frequency
analysis of ASL is difficult due to the fact that every sign is composed of
phonemes that are created through a combination of manual and a relatively
large and imprecise set of bodily features. Focusing on handshapes as the
ubiquitous and universal feature of all sign languages permits a precise
quantitative analysis. As interest in visual electronic communication explodes
within the deaf community, this work also paves the way for more precise
automated sign recognition and synthesis.