Future galaxy surveys require one percent precision in the theoretical
knowledge of the power spectrum over a large range including very nonlinear
scales. While this level of accuracy is easily obtained in the linear regime
with perturbation theory, it represents a serious challenge for small scales
where numerical simulations are required. In this paper we quantify the
accuracy of present-day $N$-body methods, identifying main potential error
sources from the set-up of initial conditions to the measurement of the final
power spectrum. We directly compare three widely used $N$-body codes, Ramses,
Pkdgrav3, and Gadget3 which represent three main discretisation techniques: the
particle-mesh method, the tree method, and a hybrid combination of the two. For
standard run parameters, the codes agree to within one percent at $k\leq1$
$h\,\rm Mpc^{-1}$ and to within three percent at $k\leq10$ $h\,\rm Mpc^{-1}$.
In a second step, we quantify potential errors due to initial conditions, box
size, and resolution using an extended suite of simulations performed with our
fastest code {\tt Pkdgrav3}. We demonstrate that both a minimum box size of
$L=500$ $h^{-1}\rm Mpc$ and a maximum particle mass of $M_{\rm p}=10^{9}$
$h^{-1}\rm M_{\odot}$ are required to obtain one percent precision of the
matter power spectrum. As a consequence, numerical simulations covering large
survey volumes of upcoming missions such as DES, LSST, and Euclid will need
more than a trillion particles to reproduce clustering properties at the
targeted accuracy.