Deep Convolutional Neural Networks (CNNs) have gained great success in image
classification and object detection. In these fields, the outputs of all layers
of CNNs are usually considered as a high dimensional feature vector extracted
from an input image and the correspondence between finer level feature vectors
and concepts that the input image contains is all-important. However, fewer
studies focus on this deserving issue. On considering the correspondence, we
propose a novel approach which generates an edited version for each original
CNN feature vector by applying the maximum entropy principle to abandon
particular vectors. These selected vectors correspond to the unfriendly
concepts in each image category. The classifier trained from merged feature
sets can significantly improve model generalization of individual categories
when training data is limited. The experimental results for
classification-based object detection on canonical datasets including VOC 2007
(60.1%), 2010 (56.4%) and 2012 (56.3%) show obvious improvement in mean average
precision (mAP) with simple linear support vector machines.