Estimation of autocorrelations and spectral densities is of fundamental
importance in many fields of science, from identifying pulsar signals in
astronomy to measuring heart beats in medicine. In circumstances where one is
interested in specific autocorrelation functions that do not fit into any
simple families of models, such as auto-regressive moving average (ARMA),
estimating model parameters is generally approached in one of two ways: by
fitting the model autocorrelation function to a non-parameteric autocorrelation
estimate via regression analysis or by fitting the model autocorrelation
function directly to the data via maximum likelihood. Prior literature suggests
that variogram regression yields parameter estimates of comparable quality to
maximum likelihood. In this letter we demonstrate that, as sample size is
increases, the accuracy of the maximum-likelihood estimates (MLE) ultimately
improves by orders of magnitude beyond that of variogram regression. For
relatively continuous and Gaussian processes, this improvement can occur for
sample sizes of less than 100. Moreover, even where the accuracy of these
methods is comparable, the MLE remains almost universally better and, more
critically, variogram regression does not provide reliable confidence
intervals. Inaccurate regression parameter estimates are typically accompanied
by underestimated standard errors, whereas likelihood provides reliable
confidence intervals.