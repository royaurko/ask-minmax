This paper applies the recently axiomatized Optimum Information Principle
(minimize the Kullback-Leibler information subject to all relevant information)
to nonparametric density estimation, which provides a theoretical foundation as
well as a computational algorithm for maximum entropy density estimation. The
estimator, called optimum information estimator, approximates the true density
arbitrarily well. As a by-product I obtain a measure of goodness of fit of
parametric models (both conditional and unconditional) and an absolute
criterion for model selection, as opposed to other conventional methods such as
AIC and BIC which are relative measures.