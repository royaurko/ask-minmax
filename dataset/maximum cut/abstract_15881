Based on detailed models for the explosions, light curves and NLTE-spectra,
evolutionary effects of Type Ia Supernovae (SNe Ia) with redshift have been
studied to evaluate their size on cosmological time scales,how the effects can
be recognized and how one may be able to correct for them. We show that delayed
detonation models can account for the majority of observations of spectra and
LCs. IR observations are a new and powerful tools to constrain explosion
models, e.g. by a strong MgII line at propagation in the WD. A strong Mg II
line at 1.05 mu shows that nuclear burning takes place at the outer, low
density layers. This requires a transition from the deflagration to the
detonation regime of the nuclear burning front, or a very fast deflagration. We
put the models into context with the empirical brightness decline relation
which is widely applied to use SNe Ia as yardsticks on cosmological distance
scales. This relation can be well understood in the framework of M(Ch)-WDs as a
consequence of the opacity effects in combination with the amount of 56Ni which
determines the brightness. We show that evolution may produce an offset in the
brightness decline relation but it is restricted to a few tenth of a magnitude.
Effects reveal themself by changes in the U and UV fluxes, and in a change in
the maximum brightness/decline relation by DM is about 0.1Dt where Dt is the do
difference between local and distant SN-samples. According to new data by Alde-
ring et al.(2000), Dt<1day and, likely, evolution will not eliminate Lambda.