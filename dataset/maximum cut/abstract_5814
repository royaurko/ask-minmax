We show empirically that fits to the color-magnitude relation of Type Ia
supernovae after optical maximum can provide accurate relative extragalactic
distances. We report the discovery of an empirical color relation for Type Ia
light curves: During much of the first month past maximum, the magnitudes of
Type Ia supernovae defined at a given value of color index have a very small
magnitude dispersion; moreover, during this period the relation between $B$
magnitude and $B-V$ color (or $B-R$ or $B-I$ color) is strikingly linear, to
the accuracy of existing well-measured data. These linear relations can provide
robust distance estimates, in particular, by using the magnitudes when the
supernova reaches a given color. After correction for light curve strech factor
or decline rate, the dispersion of the magnitudes taken at the intercept of the
linear color-magnitude relation are found to be around 0$^m$.08 for the
sub-sample of supernovae with \BVm $\le 0^m.05$, and around 0$^m$.11 for the
sub-sample with \BVm $\le 0^m.2$. This small dispersion is consistent with
being mostly due to observational errors. The method presented here and the
conventional light curve fitting methods can be combined to further improve
statistical dispersions of distance estimates. It can be combined with the
magnitude at maximum to deduce dust extinction. The slopes of the
color-magnitude relation may also be used to identify intrinsically different
SN Ia systems. The method provides a tool that is fundamental to using SN Ia to
estimate cosmological parameters such as the Hubble constant and the mass and
dark energy content of the universe.