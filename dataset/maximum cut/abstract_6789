Approximate Bayesian computation (ABC) is a popular technique for
approximating likelihoods and is often used in parameter estimation when the
likelihood functions are analytically intractable. Although the use of ABC is
widespread in many fields, there has been little investigation of the
theoretical properties of the resulting estimators. In this paper we give a
theoretical analysis of the asymptotic properties of ABC based maximum
likelihood parameter estimation for hidden Markov models. In particular, we
derive results analogous to those of consistency and asymptotic normality for
standard maximum likelihood estimation. We also discuss how Sequential Monte
Carlo methods provide a natural method for implementing likelihood based ABC
procedures.