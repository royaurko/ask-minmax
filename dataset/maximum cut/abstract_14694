The generalized likelihood ratio (GLR) test proposed by Fan, Zhang and Zhang
[Ann. Statist. 29 (2001) 153-193] and Fan and Yao [Nonlinear Time Series:
Nonparametric and Parametric Methods (2003) Springer] is a generally applicable
nonparametric inference procedure. In this paper, we show that although it
inherits many advantages of the parametric maximum likelihood ratio (LR) test,
the GLR test does not have the optimal power property. We propose a generally
applicable test based on loss functions, which measure discrepancies between
the null and nonparametric alternative models and are more relevant to
decision-making under uncertainty. The new test is asymptotically more powerful
than the GLR test in terms of Pitman's efficiency criterion. This efficiency
gain holds no matter what smoothing parameter and kernel function are used and
even when the true likelihood function is available for the GLR test.