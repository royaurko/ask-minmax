We calculate the type Ia supernova rate for different star formation
histories in galaxies by adopting the most popular and recent progenitor
models. We show that the timescale for the maximum in the type Ia supernova
rate, which corresponds also to time of the maximum enrichment, is not unique
but is a strong function of the adopted stellar lifetimes, initial mass
function and star formation rate. This timescale varies from $\sim 40-50$ Myr
for an instantaneous starburst to $\sim$ 0.3 Gyr for a typical elliptical
galaxy to $\sim 4.0-5.0$ Gyr for a disk of a spiral Galaxy like the Milky Way.
We also show that the typical timescale of 1 Gyr, often quoted as the typical
timescale for the type Ia supernovae, is just the time at which, in the solar
neighbourhood, the Fe production from supernovae Ia starts to become important
and not the time at which SNe Ia start to explode. As a cosequence of this, a
change in slope in the [O/Fe] ratio is expected in correspondance of this
timescale. We conclude that the suggested lack of supernovae Ia at low
metallicities produces results at variance with the observed [O/Fe] vs. [Fe/H]
relation in the solar region. We also compute the supernova Ia rates for
different galaxies as a function of redshift and predict an extended maximum
between redshift $z \sim 3.6$ and $z \sim 1.6$ for elliptical galaxies, and two
maxima, one at $z \sim 3$ and the other at $z \sim 1$, for spiral galaxies,
under the assumption that galaxies start forming stars at $z_f \sim 5$ and
$\Omega_M = 0.3$, $\Omega_{\Lambda} = 0.7$.