We consider a transport-diffusion equation of the form $\partial_t \theta +v
\cdot \nabla \theta + \nu \A \theta =0$, where $v$ is a given time-dependent
vector field on $\mathbb R^d$. The operator $\A$ represents log-modulated
fractional dissipation: $\A=\frac
{|\nabla|^{\gamma}}{\log^{\beta}(\lambda+|\nabla|)}$ and the parameters $\nu\ge
0$, $\beta\ge 0$, $0\le \gamma \le 2$, $\lambda>1$. We introduce a novel
nonlocal decomposition of the operator $\A$ in terms of a weighted integral of
the usual fractional operators $|\nabla|^{s}$, $0\le s \le \gamma$ plus a
smooth remainder term which corresponds to an $L^1$ kernel. For a general
vector field $v$ (possibly non-divergence-free) we prove a generalized
$L^\infty$ maximum principle of the form $ |\theta(t)|_\infty \le e^{Ct}
|\theta_0|_{\infty}$ where the constant $C=C(\nu,\beta,\gamma)>0$. In the case
$\text{div}(v)=0$ the same inequality holds for $|\theta(t)|_p$ with $1\le p
\le \infty$. At the cost of an exponential factor, this extends a recent result
of Hmidi (2011) to the full regime $d\ge 1$, $0\le \gamma \le 2$ and removes
the incompressibility assumption in the $L^\infty$ case.