McCullagh and Yang (2006) suggest a family of classification algorithms based
on Cox processes. We further investigate the log Gaussian variant which has a
number of appealing properties. Conditioned on the covariates, the distribution
over labels is given by a type of conditional Markov random field. In the
supervised case, computation of the predictive probability of a single test
point scales linearly with the number of training points and the multiclass
generalization is straightforward. We show new links between the supervised
method and classical nonparametric methods. We give a detailed analysis of the
pairwise graph representable Markov random field, which we use to extend the
model to semi-supervised learning problems, and propose an inference method
based on graph min-cuts. We give the first experimental analysis on supervised
and semi-supervised datasets and show good empirical performance.