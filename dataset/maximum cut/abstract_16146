Collisionless stellar systems are driven towards equilibrium by mixing of
phase-space elements. I show that the excess-mass function D(f)= int_{F(x,v)>f}
(F(x,v)-f) d^3x d^3v (with F(x,v) the coarse-grained distribution function)
always decreases on mixing. D(f) gives the excess mass from values of
F(x,v))>f. This novel form of the mixing theorem extends the maximum
phase-space density argument to all values of f. The excess-mass function can
be computed from N-body simulations and is additive: the excess mass of a
combination of non-overlapping systems is the sum of their individual D(f). I
propose a novel interpretation for the coarse-grained distribution function,
which avoids conceptual problems with the mixing theorem.
  As an example application, I show that for self-gravitating cusps (rho propto
r^{-gamma} as r->0) the excess mass D propto f^{-2(3-gamma)/(6-gamma)} as
f->oo, i.e. steeper cusps are less mixed than shallower ones, independent of
the shape of surfaces of constant density or details of the distribution
function (e.g. anisotropy). This property, together with the additivity of D(f)
and the mixing theorem, implies that a merger remnant cannot have a cusp
steeper than the steepest of its progenitors. Furthermore, I argue that the
remnant's cusp should not be shallower either, implying that the steepest cusp
always survives.