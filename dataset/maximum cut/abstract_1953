Thompson scattering of cosmic microwave background (CMB) photons off of free
electrons during the reionization epoch induces a correlation between the
distribution of galaxies and the polarization pattern of the CMB, the magnitude
of which is proportional to the quadrupole moment of radiation at the time of
scattering. Since the quadrupole moment generated by gravitational waves (GWs)
gives rise to a different polarization pattern than that produced by scalar
modes, one can put interesting constraints on the strength of GWs on large
scales by cross-correlating the small scale galaxy distribution and CMB
polarization. We use this method together with Fisher analysis to predict how
well future surveys can measure the tensor-to-scalar ratio $r$. We find that
with a future CMB experiment with detector noise Delta_P = 2 mu K-arcmin and a
beam width theta_FWHM = 2' and a future galaxy survey with limiting magnitude
I<25.6 one can measure the tensor-to-scalar ratio with an error sigma_r \simeq
0.09. To measure r \approx 0.01, however, one needs Delta_P \simeq 0.5 mu
K-radian and theta_FWHM \simeq 1'. We also investigate a few systematic
effects, none of which turn out to add any biases to our estimators, but they
increase the error bars by adding to the cosmic variance. The incomplete sky
coverage has the most dramatic effect on our constraints on r for large sky
cuts, with a reduction in signal-to-noise smaller than one would expect from
the naive estimate (S/N)^2 \propto f_sky. Specifically, we find a degradation
factor of f_deg=0.32 \pm 0.01 for a sky cut of |b|>10^\circ (f_sky=0.83) and
f_deg=0.056 \pm 0.004 for a sky cut of |b|>20^\circ (f_sky=0.66). Nonetheless,
given that our method has different systematics than the more conventional
method of observing the large scale B modes directly, it may be used as an
important check in the case of a detection.