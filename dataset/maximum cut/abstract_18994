A longer sensing time improves the sensing performance; however, with a fixed
frame size, the longer sensing time will reduce the allowable data transmission
time of the secondary user (SU). In this paper, we try to address the tradeoff
between sensing the primary channel for $\tau$ seconds of the time slot
proceeded by randomly accessing it and randomly accessing primary channel
without sensing to avoid wasting $\tau$ seconds in sensing. The SU senses
primary channel to exploit the periods of silence, if the primary user (PU) is
declared to be idle the SU randomly accesses the channel with some access
probability $a_s$. In addition to randomly accesses the channel if the PU is
sensed to be idle, it possibly accesses it if the channel is declared to be
busy with some access probability $b_s$. This is because the probability of
false alarm and misdetection cause significant secondary throughput degradation
and affect the PU QoS. We propose variable sensing duration schemes where the
SU optimizes over the optimal sensing time to achieve the maximum stable
throughput for both primary and secondary queues. The results reveal the
performance gains of the proposed schemes over the conventional sensing scheme,
i.e., the SU senses the primary channel for $\tau$ seconds and accesses with
probability 1 if the PU is declared to be idle. Also, the proposed schemes
overcome random access without sensing scheme.
  The theoretical and numerical results show that pairs of misdetection and
false alarm probabilities may exist such that sensing the primary channel for
very small duration overcomes sensing it for large portion of the time slot. In
addition, for certain average arrival rate to the primary queue pairs of
misdetection and false alarm probabilities may exist such that the random
access without sensing overcomes the random access with long sensing duration.