We propose a new approach for deriving probabilistic inequalities based on
bounding likelihood ratios. We demonstrate that this approach is more general
and powerful than the classical method frequently used for deriving
concentration inequalities such as Chernoff bounds. We discover that the
proposed approach is inherently related to statistical concepts such as
monotone likelihood ratio, maximum likelihood, and the method of moments for
parameter estimation. A connection between the proposed approach and the large
deviation theory is also established. We show that, without using moment
generating functions, tightest possible concentration inequalities may be
readily derived by the proposed approach. We have derived new concentration
inequalities using the proposed approach, which cannot be obtained by the
classical approach based on moment generating functions.