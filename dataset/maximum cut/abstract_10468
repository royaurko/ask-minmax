In this paper, we study the approximation and estimation of $s$-concave
densities via R\'enyi divergence. We first show that the approximation of a
probability measure $Q$ by an $s$-concave densities exists and is unique via
the procedure of minimizing a divergence functional proposed by Koenker and
Mizera (2010) if and only if $Q$ admits full-dimensional support and a first
moment. We also show continuity of the divergence functional in $Q$: if $Q_n
\to Q$ in the Wasserstein metric, then the projected densities converge in
weighted $L_1$ metrics and uniformly on closed subsets of the continuity set of
the limit. Moreover, directional derivatives of the projected densities also
enjoy local uniform convergence. This contains both on-the-model and
off-the-model situations, and entails strong consistency of the divergence
estimator of an $s$-concave density under mild conditions. One interesting and
important feature for the R\'enyi divergence estimator of an $s$-concave
density is that the estimator is intrinsically related with the estimation of
log-concave densities via maximum likelihood methods. In fact, we show that for
$d=1$ at least, the R\'enyi divergence estimators for $s$-concave densities
converge to the maximum likelihood estimator of a log-concave density as $s
\nearrow 0$. The R\'enyi divergence estimator shares similar characterizations
as the MLE for log-concave distributions, which allows us to develop pointwise
asymptotic distribution theory assuming that the underlying density is
$s$-concave.