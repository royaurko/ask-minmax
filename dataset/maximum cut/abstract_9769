Hidden semi-Markov models (HSMMs) are latent variable models which allow
latent state persistence and can be viewed as a generalization of the popular
hidden Markov models (HMMs). In this paper, we introduce a novel spectral
algorithm to perform inference in HSMMs. Unlike expectation maximization (EM),
our approach correctly estimates the probability of given observation sequence
based on a set of training sequences. Our approach is based on estimating
certain sample moments, whose order depends only logarithmically on the maximum
length of the hidden state persistence. Moreover, the algorithm requires only a
few spectral decompositions and is therefore computationally efficient.
Empirical evaluations on synthetic and real data demonstrate the promise of the
algorithm.