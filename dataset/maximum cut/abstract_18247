We calculate the maximum fraction of matter which is able to condense out of
the expanding background universe, for any universe which will expand forever.
We use a simple spherical model for the growth of density fluctuations in the
universe. This model includes open, matter-dominated universe and universes in
which there is an uniform background component (e.g. the cosmological constant
or "quintessence"). In these background universes, Omega eventually drops
significantly below unity. When this happens, gravitational instability is
suppressed and, with it, so is the growth of the collapsed fraction.
  We identify a limitation of the Press-Schechter (PS) approximation. In this
approximation, the mass function determined from the predicted collapse of
overdense regions is multiplied by a correction factor of 2, assuming that each
bound fluctuation will accrete an equal share of mass from nearby underdense
regions. Our model determines the actual value of the correction factor. We
show that, while the factor of 2 adopted by the PS approximation is correct for
an Einstein-de Sitter universe, it is not correct when the freeze-out of
fluctuation growth inherent in the more general class of background universes
described above occurs. When freeze-out occurs, the correction factor reduces
to unity and the PS approximation must overestimate the collapsed fraction.
  We apply our model to open CDM and flat Lambda-CDM models. For H0=70 and
Omega0=0.3, these models yield asymptotic collapsed fractions of 0.0361 and
0.0562, respectively, on the galaxy cluster mass-scale, only 55% of the values
determined by the PS approximation. These results have implications for the use
of the latter approximation to compare the observed space density of X-ray
clusters today with that predicted by cosmological models.