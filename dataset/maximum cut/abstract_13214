In this paper we propose a new regression interpretation of the Cholesky
factor of the covariance matrix, as opposed to the well known regression
interpretation of the Cholesky factor of the inverse covariance, which leads to
a new class of regularized covariance estimators suitable for high-dimensional
problems. Regularizing the Cholesky factor of the covariance via this
regression interpretation always results in a positive definite estimator. In
particular, one can obtain a positive definite banded estimator of the
covariance matrix at the same computational cost as the popular banded
estimator proposed by Bickel and Levina (2008b), which is not guaranteed to be
positive definite. We also establish theoretical connections between banding
Cholesky factors of the covariance matrix and its inverse and constrained
maximum likelihood estimation under the banding constraint, and compare the
numerical performance of several methods in simulations and on a sonar data
example.