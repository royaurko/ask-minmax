Stationary ergodic processes with finite alphabets are estimated by finite
memory processes from a sample, an n-length realization of the process, where
the memory depth of the estimator process is also estimated from the sample
using penalized maximum likelihood (PML). Under some assumptions on the
continuity rate and the assumption of non-nullness, a rate of convergence in
$\bar{d}$-distance is obtained, with explicit constants. The result requires an
analysis of the divergence of PML Markov order estimators for not necessarily
finite memory processes. This divergence problem is investigated in more
generality for three information criteria: the Bayesian information criterion
with generalized penalty term yielding the PML, and the normalized maximum
likelihood and the Krichevsky-Trofimov code lengths. Lower and upper bounds on
the estimated order are obtained. The notion of consistent Markov order
estimation is generalized for infinite memory processes using the concept of
oracle order estimates, and generalized consistency of the PML Markov order
estimator is presented.