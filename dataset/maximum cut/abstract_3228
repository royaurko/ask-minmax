This paper modifies Jaynes's axioms of plausible reasoning and derives the
minimum relative entropy principle, Bayes's rule, as well as maximum likelihood
from first principles. The new axioms, which I call the Optimum Information
Principle, is applicable whenever the decision maker is given the data and the
relevant background information. These axioms provide an answer to the question
"why maximize entropy when faced with incomplete information?"