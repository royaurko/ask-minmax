We propose modal Markov logic as an extension of propositional Markov logic
to reason under the principle of maximum entropy for modal logics K45, KD45,
and S5. Analogous to propositional Markov logic, the knowledge base consists of
weighted formulas, whose weights are learned from data. However, in contrast to
Markov logic, in our framework we use the knowledge base to define a
probability distribution over non-equivalent epistemic situations (pointed
Kripke structures) rather than over atoms, and use this distribution to assign
probabilities to modal formulas. As in all probabilistic representations, the
central task in our framework is inference. Although the size of the state
space grows doubly exponentially in the number of propositions in the domain,
we provide an algorithm that scales only exponentially in the size of the
knowledge base. Finally, we briefly discuss the case of languages with an
infinite number of propositions.