We propose a regularized saddle-point algorithm for convex networked
optimization problems with resource allocation constraints. Standard
distributed gradient methods suffer from slow convergence and require excessive
communication when applied to problems of this type. Our approach offers an
alternative way to address these problems, and ensures that each iterative
update step satisfies the resource allocation constraints. We derive step-size
conditions under which the distributed algorithm converges geometrically to the
regularized optimal value, and show how these conditions are affected by the
underlying network topology. We illustrate our method on a robotic network
application example where a group of mobile agents strive to maintain a moving
target in the barycenter of their positions.