We consider an \textit{Adaptive Random Convolutional Network Coding} (ARCNC)
algorithm to address the issue of field size in random network coding for
multicast, and study its memory and decoding delay performances through both
analysis and numerical simulations. ARCNC operates as a convolutional code,
with the coefficients of local encoding kernels chosen randomly over a small
finite field. The cardinality of local encoding kernels increases with time
until the global encoding kernel matrices at related sink nodes have full
rank.ARCNC adapts to unknown network topologies without prior knowledge, by
locally incrementing the dimensionality of the convolutional code. Because
convolutional codes of different constraint lengths can coexist in different
portions of the network, reductions in decoding delay and memory overheads can
be achieved. We show that this method performs no worse than random linear
network codes in terms of decodability, and can provide significant gains in
terms of average decoding delay or memory in combination, shuttle and random
geometric networks.