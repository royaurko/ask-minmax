We consider the task of generative dialogue modeling for movie scripts. To
this end, we extend the recently proposed hierarchical recurrent encoder
decoder neural network and demonstrate that this model is competitive with
state-of-the-art neural language models and backoff n-gram models. We show that
its performance can be improved considerably by bootstrapping the learning from
a larger question-answer pair corpus and from pretrained word embeddings.