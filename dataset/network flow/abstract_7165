Carbon nanotubes are often seen as the only alternative technology to silicon
transistors. While they are the most likely short-term one, other longer-term
alternatives should be studied as well. While contemplating biological neurons
as an alternative component may seem preposterous at first sight, significant
recent progress in CMOS-neuron interface suggests this direction may not be
unrealistic; moreover, biological neurons are known to self-assemble into very
large networks capable of complex information processing tasks, something that
has yet to be achieved with other emerging technologies. The first step to
designing computing systems on top of biological neurons is to build an
abstract model of self-assembled biological neural networks, much like computer
architects manipulate abstract models of transistors and circuits. In this
article, we propose a first model of the structure of biological neural
networks. We provide empirical evidence that this model matches the biological
neural networks found in living organisms, and exhibits the small-world graph
structure properties commonly found in many large and self-organized systems,
including biological neural networks. More importantly, we extract the simple
local rules and characteristics governing the growth of such networks, enabling
the development of potentially large but realistic biological neural networks,
as would be needed for complex information processing/computing tasks. Based on
this model, future work will be targeted to understanding the evolution and
learning properties of such networks, and how they can be used to build
computing systems.