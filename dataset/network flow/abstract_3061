A measure is derived to quantify directed information transfer between pairs
of vertices in a weighted network, over paths of a specified maximal length.
Our approach employs a general, probabilistic model of network traffic, from
which the informational distance between dynamics on two weighted networks can
be naturally expressed as a Jensen Shannon Divergence (JSD). Our network
transfer entropy measure is shown to be able to distinguish and quantify causal
relationships between network elements, in applications to simple synthetic
networks and a biological signalling network. We conclude with a theoretical
extension of our framework, in which the square root of the JSD induces a
metric on the space of dynamics on weighted networks. We prove a convergence
criterion, demonstrating that a form of convergence in the structure of
weighted networks in a family of matrix metric spaces implies convergence of
their dynamics with respect to the square root JSD metric.