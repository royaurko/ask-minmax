In this paper we study the application of convolutional neural networks for
jointly detecting objects depicted in still images and estimating their 3D
pose. We identify different feature representations of oriented objects, and
energies that lead a network to learn this representations. The choice of the
representation is crucial since the pose of an object has a natural, continuous
structure while its category is a discrete variable. We evaluate the different
approaches on the joint object detection and pose estimation task of the
Pascal3D+ benchmark using Average Viewpoint Precision. We show that a
classification approach on discretized viewpoints achieves state-of-the-art
performance for joint object detection and pose estimation, and significantly
outperforms existing baselines on this benchmark.