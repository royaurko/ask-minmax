The Turing test aimed to recognize the behavior of a human from that of a
computer algorithm. Such challenge is more relevant than ever in today's social
media context, where limited attention and technology constrain the expressive
power of humans, while incentives abound to develop software agents mimicking
humans. These social bots interact, often unnoticed, with real people in social
media ecosystems, but their abundance is uncertain. While many bots are benign,
one can design harmful bots with the goals of persuading, smearing, or
deceiving. Here we discuss the characteristics of modern, sophisticated social
bots, and how their presence can endanger online ecosystems and our society. We
then review current efforts to detect social bots on Twitter. Features related
to content, network, sentiment, and temporal patterns of activity are imitated
by bots but at the same time can help discriminate synthetic behaviors from
human ones, yielding signatures of engineered social tampering.