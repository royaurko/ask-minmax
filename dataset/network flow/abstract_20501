We discuss the dissipation of turbulent kinetic energy Ek in the global ISM
by means of 2-D, MHD, non-isothermal simulations in the presence of model
radiative heating and cooling. We argue that dissipation in 2D is
representative of that in three dimensions as long as it is dominated by shocks
rather than by a turbulent cascade. Energy is injected at a few isolated sites
in space, over relatively small scales, and over short time periods. This leads
to the coexistence of forced and decaying regimes in the same flow. We find
that the ISM-like flow dissipates its turbulent energy rapidly. In simulations
with forcing, the input parameters are the radius l_f of the forcing region,
the total kinetic energy e_k each source deposits into the flow, and the rate
of formation of those regions, sfr_OB. The global dissipation time t_d depends
mainly on l_f. In terms of measurable properties of the ISM, t_d >= Sigma_g
u_rms^2/(e_k sfr_OB), where Sigma_g is the average gas surface density and
u_rms is the rms velocity dispersion. For the solar neighborhood, t_d >=
1.5x10^7 yr. The global dissipation time is consistently smaller than the
crossing time of the largest energy-containing scales. In decaying simulations,
Ek decreases with time as t^-n, where n~0.8-0.9. This suggests a decay with
distance d as Ek\propto d^{-2n/(2-n)} in the mixed forced+decaying case. If
applicable to the vertical direction, our results support models of galaxy
evolution in which stellar energy injection provides significant support for
the gas disk thickness, but not models of galaxy formation in which this energy
injection is supposed to reheat an intra-halo medium at distances of up to
10-20 times the optical galaxy size, as the dissipation occurs on distances
comparable to the disk height.