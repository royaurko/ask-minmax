We calculate the multifractal spectrum of the partition of the coupling space
of a perceptron induced by random input-output pairs with non-zero mean. From
the results we infer the influence of the input and output bias respectively on
both the storage and generalization properties of the network. It turns out
that the value of the input bias is irrelevant as long as it is different from
zero. The generalization problem with output bias is new and shows an
interesting two-level scenario. To compare our analytical results with
simulations we introduce a simple and efficient algorithm to implement Gibbs
learning.