The scaling of transient times to zero-lag synchronization in networks
composed of excitable units is shown to be governed by three features of the
graph representing the network: the longest path between pairs of neurons
(diameter), the largest loop (circumference) and the loop with the maximal
average out degree. The upper bound of transient times can vary between O(1)
and O(N2), where N is the size of the network, and its scaling can be predicted
in many scenarios from finite time accumulated information of the transient.
Results challenge the assumption that functionality of neural networks might
depend solely upon the synchronized repeated activation such as zero-lag
synchronization.