Within a Kuhn-Tucker cavity method introduced in a former paper, we study
optimal stability learning for situations, where in the replica formalism the
replica symmetry may be broken, namely
  (i) the case of a simple perceptron above the critical loading, and
  (ii) the case of two-layer AND-perceptrons, if one learns with maximal
stability.
  We find that the deviation of our cavity solution from the replica symmetric
one in these cases is a clear indication of the necessity of replica symmetry
breaking. In any case the cavity solution tends to underestimate the storage
capabilities of the networks.