In this work, we analyze the generalization ability of distributed online
learning algorithms under stationary and non-stationary environments. We derive
bounds for the excess-risk attained by each node in a connected network of
learners and study the performance advantage that diffusion strategies have
over individual non-cooperative processing. We conduct extensive simulations to
illustrate the results.