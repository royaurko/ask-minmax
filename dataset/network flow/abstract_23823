We consider a dynamic server control problem for two parallel queues with
randomly varying connectivity and server switchover time between the queues. At
each time slot the server decides either to stay with the current queue or
switch to the other queue based on the current connectivity and the queue
length information. The introduction of switchover time is a new modeling
component of this problem, which makes the problem much more challenging. We
develop a novel approach to characterize the stability region of the system by
using state action frequencies, which are stationary solutions to a Markov
Decision Process (MDP) formulation of the corresponding saturated system. We
characterize the stability region explicitly in terms of the connectivity
parameters and develop a frame-based dynamic control (FBDC) policy that is
shown to be throughput-optimal. In fact, the FBDC policy provides a new
framework for developing throughput-optimal network control policies using
state action frequencies. Furthermore, we develop simple Myopic policies that
achieve more than 96% of the stability region. Finally, simulation results show
that the Myopic policies may achieve the full stability region and are more
delay efficient than the FBDC policy in most cases.