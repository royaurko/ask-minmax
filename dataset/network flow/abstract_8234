The ability of a deterministic, plastic system to learn to imitate stochastic
behavior is analyzed. Two neural networks -actually, two perceptrons- are put
to play a zero-sum game one against the other. The competition, by acting as a
kind of mutually supervised learning, drives the networks to produce an
approximation to the optimal strategy, that is to say, a random signal.