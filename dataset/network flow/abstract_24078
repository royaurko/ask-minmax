Maintaining high quality content is one of the foremost objectives of any
web-based collaborative service that depends on a large number of users. In
such systems, it is nearly impossible for automated scripts to judge semantics
as it is to expect all editors to review the content. This catalyzes the need
for trust-based mechanisms to ensure quality of an article immediately after an
edit. In this paper, we build on previous work and develop a framework based on
the `web of trust' concept to calculate satisfaction scores for all users
without the need for perusing the article. We derive some bounds for systems
based on our mechanism and show that the optimization problem of selecting the
best users to review an article is NP-Hard. Extensive simulations validate our
model and results, and show that trust-based mechanisms are essential to
improve efficiency in any online collaborative editing platform.