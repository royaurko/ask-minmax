We propose a Bayesian model of iterative learning on social networks that is
computationally tractable; the agents of this model are fully rational, and
their calculations can be performed with modest computational resources for
large networks. Furthermore, learning is efficient, in the sense that the
process results in an information-theoretically optimal belief. This result
extends Condorcet's Jury Theorem to general social networks, preserving
rationality, computational feasibility and efficient learning. The model
consists of a group of agents who belong to a social network, so that a pair of
agents can observe each other's actions only if they are neighbors. We assume
that the network is connected and that the agents have full knowledge of the
structure of the network, so that they know the members of the network and
their social connections. The agents try to estimate some state of the world S
(say, the price of oil a year from today). Each agent has a private
measurement: an independently acquired piece of information regarding S. This
is modeled, for agent v, by a number S_v picked from a Gaussian distribution
with mean S and standard deviation one. Accordingly, agent v's prior belief
regarding S is a normal distribution with mean S_v and standard deviation one.
The agents start acting iteratively. At each iteration, each agent takes the
optimal action given its current belief. This action reveals its mean estimate
of S to its neighbors. Then, observing its neighbors' actions, each agent
updates its belief, using Bayes' Law. We show that this process is efficient:
all the agents converge to the belief that they would have, had they access to
all the private measurements. Additionally, and in contrast to other iterative
Bayesian models on networks, it is computationally efficient, so that each
agent's calculation can be easily carried out.