We study a tandem of agents who make decisions about an underlying binary
hypothesis, where the distribution of the agent observations under each
hypothesis comes from an uncertainty class. We investigate both decentralized
detection rules, where agents collaborate to minimize the error probability of
the final agent, and social learning rules, where each agent minimizes its own
local minimax error probability. We then extend our results to the infinite
tandem network, and derive necessary and sufficient conditions on the
uncertainty classes for the minimax error probability to converge to zero when
agents know their positions in the tandem. On the other hand, when agents do
not know their positions in the network, we study the cases where agents
collaborate to minimize the asymptotic minimax error probability, and where
agents seek to minimize their worst-case minimax error probability (over all
possible positions in the tandem). We show that asymptotic learning of the true
hypothesis is no longer possible in these cases, and derive characterizations
for the minimax error performance.