Continuous time Bayesian networks (CTBNs) describe structured stochastic
processes with finitely many states that evolve over continuous time. A CTBN is
a directed (possibly cyclic) dependency graph over a set of variables, each of
which represents a finite state continuous time Markov process whose transition
model is a function of its parents. As shown previously, exact inference in
CTBNs is intractable. We address the problem of approximate inference, allowing
for general queries conditioned on evidence over continuous time intervals and
at discrete time points. We show how CTBNs can be parameterized within the
exponential family, and use that insight to develop a message passing scheme in
cluster graphs and allows us to apply expectation propagation to CTBNs. The
clusters in our cluster graph do not contain distributions over the cluster
variables at individual time points, but distributions over trajectories of the
variables throughout a duration. Thus, unlike discrete time temporal models
such as dynamic Bayesian networks, we can adapt the time granularity at which
we reason for different variables and in different conditions.