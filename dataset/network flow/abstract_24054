Virtualization technology facilitates a dynamic, demand-driven allocation and
migration of servers. This paper studies how the flexibility offered by network
virtualization can be used to improve Quality-of-Service parameters such as
latency, while taking into account allocation costs. A generic use case is
considered where both the overall demand issued for a certain service (for
example, an SAP application in the cloud, or a gaming application) as well as
the origins of the requests change over time (e.g., due to time zone effects or
due to user mobility), and we present online and optimal offline strategies to
compute the number and location of the servers implementing this service. These
algorithms also allow us to study the fundamental benefits of dynamic resource
allocation compared to static systems. Our simulation results confirm our
expectations that the gain of flexible server allocation is particularly high
in scenarios with moderate dynamics.