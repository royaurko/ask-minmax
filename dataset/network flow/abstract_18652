In this paper, we empirically evaluate algorithms for learning four types of
Bayesian network (BN) classifiers - Naive-Bayes, tree augmented Naive-Bayes, BN
augmented Naive-Bayes and general BNs, where the latter two are learned using
two variants of a conditional-independence (CI) based BN-learning algorithm.
Experimental results show the obtained classifiers, learned using the CI based
algorithms, are competitive with (or superior to) the best known classifiers,
based on both Bayesian networks and other formalisms; and that the
computational time for learning and using these classifiers is relatively
small. Moreover, these results also suggest a way to learn yet more effective
classifiers; we demonstrate empirically that this new algorithm does work as
expected. Collectively, these results argue that BN classifiers deserve more
attention in machine learning and data mining communities.