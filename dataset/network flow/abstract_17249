The conventional classification schemes -- notably multinomial logistic
regression -- used in conjunction with convolutional networks (convnets) are
classical in statistics, designed without consideration for the usual coupling
with convnets, stochastic gradient descent, and backpropagation. In the
specific application to supervised learning for convnets, a simple
scale-invariant classification stage turns out to be more robust than
multinomial logistic regression, appears to result in slightly lower errors on
several standard test sets, has similar computational costs, and features
precise control over the actual rate of learning. "Scale-invariant" means that
multiplying the input values by any nonzero scalar leaves the output unchanged.