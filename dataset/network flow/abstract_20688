Neural networks can synchronize by learning from each other. In the case of
discrete weights full synchronization is achieved in a finite number of steps.
Additional networks can be trained by using the inputs and outputs generated
during this process as examples. Several learning rules for both tasks are
presented and analyzed. In the case of Tree Parity Machines synchronization is
much faster than learning. Scaling laws for the number of steps needed for full
synchronization and successful learning are derived using analytical models.
They indicate that the difference between both processes can be controlled by
changing the synaptic depth. In the case of bidirectional interaction the
synchronization time increases proportional to the square of this parameter,
but it grows exponentially, if information is transmitted in one direction
only. Because of this effect neural synchronization can be used to construct a
cryptographic key-exchange protocol. Here the partners benefit from mutual
interaction, so that a passive attacker is usually unable to learn the
generated key in time. The success probabilities of different attack methods
are determined by numerical simulations and scaling laws are derived from the
data. They show that the partners can reach any desired level of security by
just increasing the synaptic depth. Then the complexity of a successful attack
grows exponentially, but there is only a polynomial increase of the effort
needed to generate a key. Further improvements of security are possible by
replacing the random inputs with queries generated by the partners.