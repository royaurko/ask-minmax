Model-free learning has been considered as an efficient tool for designing
control mechanisms when the model of the system environment or the interaction
between the decision-making entities is not available as a-priori knowledge.
With model-free learning, the decision-making entities adapt their behaviors
based on the reinforcement through their interaction with the environment, and
are able to (implicitly) build the understanding of the system through
try-and-error mechanisms. Such a characteristics of model-free learning is
highly in accordance with the requirement of cognition and intelligence for
wireless devices in cognitive wireless networks. Recently, model-free learning
has been considered as one key implementation approach to adaptive,
self-organized network control in cognitive wireless networks. In this paper,
we provide a comprehensive survey on the applications of the state-of-art
model-free learning mechanisms in wireless networks. A systematic overview of
the learning algorithms in the domains of both multi-agent systems and
multi-player games is provided. Furthermore, the applications of model-free
learning to various problems in wireless networks are discussed with the focus
on how the learning mechanisms helps to provide the solutions to these problems
and improve the network performance over the existing model-based, non-adaptive
methods. Finally, a broad spectrum of challenges and open issues are discussed
to offer a guideline for the future research directions.