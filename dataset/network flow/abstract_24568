The Distributed Cooperative Modeling System (DCMS) solves complex decision
problems involving a lot of participants with different viewpoints by network
based distributed modeling and multi-template aggregation.
  This thesis aims at extending the system with support for dynamic decision
making process. First, the thesis presents a discussion of characteristics and
optimal policy finding Markov Decision Process as well as a brief introduction
to dynamic Bayesian decision network, which is inherently equal to MDP. After
that, discussion and implementation of prediction in Markov process for both
discrete and continuous random variable are given, as well as several different
kinds of correlation analysis among multiple indices which could help
decision-makers to realize the interaction of indices and design appropriate
policy.
  Appending history data of Macau industry, as the foundation of extending
DCMS, is introduced. Additional works include rearrangement of graphical class
hierarchy in DCMS, which in turn allows convenient implementation of curve
relation-line, which makes template modeling clearer and friendlier.