While recent experiments with relatively large neural populations show
significant beyond-pairwise, or {\it higher-order} correlations (HOC), the
impact of HOC on the network's ability to encode information is poorly
understood. We investigate how the biophysical properties of neurons in
networks shape HOC, and how HOC affect population coding. Specifically, we show
that input nonlinearities similar to those observed in physiology experiments
are equivalent to beyond-pairwise interactions in spin-glass-type statistical
models. We then discuss one such model with parameterized pairwise- and
higher-order interactions, revealing conditions under which beyond-pairwise
interactions increase the mutual information between a given stimulus type and
the population responses. For jointly Gaussian stimuli, coding performance is
improved by shaping output HOC via input nonlinearities when neural firing
rates are constrained to be sufficiently low. For natural image stimuli,
performance improves for a broader range of firing rates. Our work suggests
surprising connections between single-neuron biophysics, population activity
statistics, and normative theories of population coding.