A repeated network game where agents have quadratic utilities that depend on
information externalities -- an unknown underlying state -- as well as payoff
externalities -- the actions of all other agents in the network -- is
considered. Agents play Bayesian Nash Equilibrium strategies with respect to
their beliefs on the state of the world and the actions of all other nodes in
the network. These beliefs are refined over subsequent stages based on the
observed actions of neighboring peers. This paper introduces the Quadratic
Network Game (QNG) filter that agents can run locally to update their beliefs,
select corresponding optimal actions, and eventually learn a sufficient
statistic of the network's state. The QNG filter is demonstrated on a Cournot
market competition game and a coordination game to implement navigation of an
autonomous team.