We explore the use of convolutional neural networks for the semantic
classification of remote sensing scenes. Two recently proposed architectures,
CaffeNet and GoogLeNet, are adopted, with three different learning modalities.
Besides conventional training from scratch, we resort to pre-trained networks
that are only fine-tuned on the target data, so as to avoid overfitting
problems and reduce design time. Experiments on two remote sensing datasets,
with markedly different characteristics, testify on the effectiveness and wide
applicability of the proposed solution, which guarantees a significant
performance improvement over all state-of-the-art references.