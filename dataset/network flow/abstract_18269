In this work, the beta-decay halflives problem is dealt as a nonlinear
optimization problem, which is resolved in the statistical framework of Machine
Learning (LM). Continuing past similar approaches, we have constructed
sophisticated Artificial Neural Networks (ANNs) and Support Vector Regression
Machines (SVMs) for each class with even-odd character in Z and N to global
model the systematics of nuclei that decay 100% by the beta-minus-mode in their
ground states. The arising large-scale lifetime calculations generated by both
types of machines are discussed and compared with each other, with the
available experimental data, with previous results obtained with neural
networks, as well as with estimates coming from traditional global nuclear
models. Particular attention is paid on the estimates for exotic and halo
nuclei and we focus to those nuclides that are involved in the r-process
nucleosynthesis. It is found that statistical models based on LM can at least
match or even surpass the predictive performance of the best conventional
models of beta-decay systematics and can complement the latter.