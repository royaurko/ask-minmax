In studies of complex heterogeneous networks, particularly of the Internet,
significant attention was paid to analyzing network failures caused by hardware
faults or overload, where the network reaction was modeled as rerouting of
traffic away from failed or congested elements. Here we model another type of
the network reaction to congestion -- a sharp reduction of the input traffic
rate through congested routes which occurs on much shorter time scales. We
consider the onset of congestion in the Internet where local mismatch between
demand and capacity results in traffic losses and show that it can be described
as a phase transition characterized by strong non-Gaussian loss fluctuations at
a mesoscopic time scale. The fluctuations, caused by noise in input traffic,
are exacerbated by the heterogeneous nature of the network manifested in a
scale-free load distribution. They result in the network strongly overreacting
to the first signs of congestion by significantly reducing input traffic along
the communication paths where congestion is utterly negligible.