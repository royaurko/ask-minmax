Bidirectional recurrent neural networks (RNN) are trained to predict both in
the positive and negative time directions simultaneously. They have not been
used commonly in unsupervised tasks, because a probabilistic interpretation of
the model is difficult. As an example of an unsupervised task, we study the
problem of filling in gaps in high-dimensional time series with complex
dynamics. Although unidirectional RNNs have recently been trained successfully
to model such time series, inference in the negative time direction is
non-trivial. We propose two probabilistic interpretations of bidirectional RNNs
that can be used to reconstruct missing gaps efficiently. Our experiments on
text data show that both proposed methods are much more accurate than
unidirectional reconstructions, although a bit less accurate than a
computationally complex bidirectional Bayesian inference on the unidirectional
RNN. We also provide results on music data for which the Bayesian inference is
computationally infeasible.