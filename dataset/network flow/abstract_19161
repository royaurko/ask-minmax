We introduce two Python frameworks to train neural networks on large
datasets: Blocks and Fuel. Blocks is based on Theano, a linear algebra compiler
with CUDA-support. It facilitates the training of complex neural network models
by providing parametrized Theano operations, attaching metadata to Theano's
symbolic computational graph, and providing an extensive set of utilities to
assist training the networks, e.g. training algorithms, logging, monitoring,
visualization, and serialization. Fuel provides a standard format for machine
learning datasets. It allows the user to easily iterate over large datasets,
performing many types of pre-processing on the fly.