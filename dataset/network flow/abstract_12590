We study upper bounds on the sum-rate of multiple-unicasts. We approximate
the Generalized Network Sharing Bound (GNS cut) of the multiple-unicasts
network coding problem with $k$ independent sources. Our approximation
algorithm runs in polynomial time and yields an upper bound on the joint source
entropy rate, which is within an $O(\log^2 k)$ factor from the GNS cut. It
further yields a vector-linear network code that achieves joint source entropy
rate within an $O(\log^2 k)$ factor from the GNS cut, but \emph{not} with
independent sources: the code induces a correlation pattern among the sources.
  Our second contribution is establishing a separation result for vector-linear
network codes: for any given field $\mathbb{F}$ there exist networks for which
the optimum sum-rate supported by vector-linear codes over $\mathbb{F}$ for
independent sources can be multiplicatively separated by a factor of
$k^{1-\delta}$, for any constant ${\delta>0}$, from the optimum joint entropy
rate supported by a code that allows correlation between sources. Finally, we
establish a similar separation result for the asymmetric optimum vector-linear
sum-rates achieved over two distinct fields $\mathbb{F}_{p}$ and
$\mathbb{F}_{q}$ for independent sources, revealing that the choice of field
can heavily impact the performance of a linear network code.