We apply large deviations theory to study asymptotic performance of running
consensus distributed detection in sensor networks. Running consensus is a
stochastic approximation type algorithm, recently proposed. At each time step
k, the state at each sensor is updated by a local averaging of the sensor's own
state and the states of its neighbors (consensus) and by accounting for the new
observations (innovation). We assume Gaussian, spatially correlated
observations. We allow the underlying network be time varying, provided that
the graph that collects the union of links that are online at least once over a
finite time window is connected. This paper shows through large deviations
that, under stated assumptions on the network connectivity and sensors'
observations, the running consensus detection asymptotically approaches in
performance the optimal centralized detection. That is, the Bayes probability
of detection error (with the running consensus detector) decays exponentially
to zero as k goes to infinity at the Chernoff information rate-the best
achievable rate of the asymptotically optimal centralized detector.