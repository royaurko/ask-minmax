A challenging problem when studying a dynamical system is to find the
interdependencies among its individual components. Several algorithms have been
proposed to detect directed dynamical influences between time series. Two of
the most used approaches are a model-free one (transfer entropy) and a
model-based one (Granger causality). Several pitfalls are related to the
presence or absence of assumptions in modeling the relevant features of the
data. We tried to overcome those pitfalls using a neural network approach in
which a model is built without any a priori assumptions. In this sense this
method can be seen as a bridge between model-free and model-based approaches.
The experiments performed will show that the method presented in this work can
detect the correct dynamical information flows occurring in a system of time
series. Additionally we adopt a non-uniform embedding framework according to
which only the past states that actually help the prediction are entered into
the model, improving the prediction and avoiding the risk of overfitting. This
method also leads to a further improvement with respect to traditional Granger
causality approaches when redundant variables (i.e. variables sharing the same
information about the future of the system) are involved. Neural networks are
also able to recognize dynamics in data sets completely different from the ones
used during the training phase.