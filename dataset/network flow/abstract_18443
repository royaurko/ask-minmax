Learning in networks of binary synapses is known to be an NP-complete
problem. A combined stochastic local search strategy in the synaptic weight
space is constructed to further improve the learning performance of a single
random walker. We apply two correlated random walkers guided by their Hamming
distance and associated energy costs (the number of unlearned patterns) to
learn a same large set of patterns. Each walker first learns a small part of
the whole pattern set (partially different for both walkers but with the same
amount of patterns) and then both walkers explore their respective weight
spaces cooperatively to find a solution to classify the whole pattern set
correctly. The desired solutions locate at the common parts of weight spaces
explored by these two walkers. The efficiency of this combined strategy is
supported by our extensive numerical simulations and the typical Hamming
distance as well as energy cost is estimated by an annealed computation.