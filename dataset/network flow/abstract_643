Datacenters are the cornerstone of the big data infrastructure supporting
numerous online services. The demand for interactivity, which significantly
impacts user experience and provider revenue, is translated into stringent
timing requirements for flows in datacenter networks. Thus low latency
networking is becoming a major concern of both industry and academia.
  We provide a short survey of recent progress made by the networking community
for low latency datacenter networks. We propose a taxonomy to categorize
existing work based on four main techniques, reducing queue length,
accelerating retransmissions, prioritizing mice flows, and exploiting
multi-path. Then we review select papers, highlight the principal ideas, and
discuss their pros and cons. We also present our perspectives of the research
challenges and opportunities, hoping to aspire more future work in this space.