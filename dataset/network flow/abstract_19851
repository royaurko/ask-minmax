The evolution of entropy is derived with respect to dynamical systems. For a
stochastic system, its relative entropy $D$ evolves in accordance with the
second law of thermodynamics; its absolute entropy $H$ may also be so, provided
that the stochastic perturbation is additive and the flow of the vector field
is nondivergent. For a deterministic system, $dH/dt$ is equal to the
mathematical expectation of the divergence of the flow (a result obtained
before), and, remarkably, $dD/dt = 0$. That is to say, relative entropy is
always conserved. So, for a nonlinear system, though the trajectories of the
state variables, say $\ve x$, may appear chaotic in the phase space, say
$\Omega$, those of the density function $\rho(\ve x)$ in the new ``phase
space'' $L^1(\Omega)$ are not; the corresponding Lyapunov exponent is always
zero. This result is expected to have important implications for the ensemble
predictions in many applied fields, and may help to analyze chaotic data sets.