Inference of causality is central in nonlinear time series analysis and
science in general. A popular approach to infer causality between two processes
is to measure the information flow between them in terms of transfer entropy.
Using dynamics of coupled oscillator networks, we show that although transfer
entropy can successfully detect information flow in two processes, it often
results in erroneous identification of network connections under the presence
of indirect interactions, dominance of neighbors, or anticipatory couplings.
Such effects are found to be profound for time-dependent networks. To overcome
these limitations, we develop a measure called causation entropy and show that
its application can lead to reliable identification of true couplings.