In Bayesian networks, exact belief propagation is achieved through message
passing algorithms. These algorithms (ex: inward and outward) provide only a
recursive definition of the corresponding messages. In contrast, when working
on hidden Markov models and variants, one classically first defines explicitly
these messages (forward and backward quantities), and then derive all results
and algorithms. In this paper, we generalize the hidden Markov model approach
by introducing an explicit definition of the messages in Bayesian networks,
from which we derive all the relevant properties and results including the
recursive algorithms that allow to compute these messages. Two didactic
examples (the precipitation hidden Markov model and the pedigree Bayesian
network) are considered along the paper to illustrate the new formalism and
standalone R source code is provided in the appendix.