This paper proposes novel spectrum sensing algorithm, and examines the
sensing throughput tradeoff for cognitive radio (CR) networks under noise
variance uncertainty. It is assumed that there are one white sub-band, and one
target sub-band which is either white or non-white. Under this assumption,
first we propose a novel generalized energy detector (GED) for examining the
target sub-band by exploiting the noise information of the white sub-band,
then, we study the tradeoff between the sensing time and achievable throughput
of the CR network. To study this tradeoff, we consider the sensing time
optimization for maximizing the throughput of the CR network while
appropriately protecting the primary network. The sensing time is optimized by
utilizing the derived detection and false alarm probabilities of the GED. The
proposed GED does not suffer from signal to noise ratio (SNR) wall (i.e.,
robust against noise variance uncertainty) and outperforms the existing signal
detectors. Moreover, the relationship between the proposed GED and conventional
energy detector (CED) is quantified analytically. We show that the optimal
sensing times with perfect and imperfect noise variances are not the same. In
particular, when the frame duration is 2s, and SNR is -20dB, and each of the
bandwidths of the white and target sub-bands is 6MHz, the optimal sensing times
are 28.5ms and 50.6ms with perfect and imperfect noise variances, respectively.