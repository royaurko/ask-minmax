This paper aims to theoretically prove by applying Marotto's Theorem that
both transiently chaotic neural networks (TCNN) and discrete-time recurrent
neural networks (DRNN) have chaotic structure. A significant property of TCNN
and DRNN is that they have only one fixed point, when absolute values of the
self-feedback connection weights in TCNN and the difference time in DRNN are
sufficiently large. We show that this unique fixed point can actually evolve
into a snap-back repeller which generates chaotic structure, if several
conditions are satisfied. On the other hand, by using the Lyapunov functions,
we also derive sufficient conditions on asymptotical stability for symmetrical
versions of both TCNN and DRNN, under which TCNN and DRNN asymptotically
converge to a fixed point. Furthermore, generic bifurcations are also
considered in this paper. Since both of TCNN and DRNN are not special but
simple and general, the obtained theoretical results hold for a wide class of
discrete-time neural networks. To demonstrate the theoretical results of this
paper better, several numerical simulations are provided as illustrating
examples.