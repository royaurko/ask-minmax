Various distributed optimization methods have been developed for solving
problems which have simple local constraint sets and whose objective function
is the sum of local cost functions of distributed agents in a network.
Motivated by emerging applications in smart grid and distributed sparse
regression, this paper studies distributed optimization methods for solving
general problems which have a coupled global cost function and have inequality
constraints. We consider a network scenario where each agent has no global
knowledge and can access only its local mapping and constraint functions. To
solve this problem in a distributed manner, we propose a consensus-based
distributed primal-dual perturbation (PDP) algorithm. In the algorithm, agents
employ the average consensus technique to estimate the global cost and
constraint functions via exchanging messages with neighbors, and meanwhile use
a local primal-dual perturbed subgradient method to approach a global optimum.
The proposed PDP method not only can handle smooth inequality constraints but
also non-smooth constraints such as some sparsity promoting constraints arising
in sparse optimization. We prove that the proposed PDP algorithm converges to
an optimal primal-dual solution of the original problem, under standard problem
and network assumptions. Numerical results illustrating the performance of the
proposed algorithm for a distributed demand response control problem in smart
grid are also presented.