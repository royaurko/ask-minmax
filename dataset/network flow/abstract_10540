One of the frequently stated advantages of neural networks is that they can
work effectively with non-normally distributed data. But optimal results are
possible with normalized data.In this paper, how normality of the input affects
the behaviour of a K-means fast learning artificial neural network(KFLANN) for
grouping the data is presented. Basically, the grouping of high dimensional
input data is controlled by additional neural network input parameters namely
vigilance and tolerance.Neural networks learn faster and give better
performance if the input variables are pre-processed before being fed to the
input units of the neural network. A common way of dealing with data that is
not normally distributed is to perform some form of mathematical transformation
on the data that shifts it towards a normal distribution.In a neural network,
data preprocessing transforms the data into a format that will be more easily
and effectively processed for the purpose of the user. Among various methods,
Normalization is one which organizes data for more efficient access.
Experimental results on several artificial and synthetic data sets indicate
that the groups formed in the data vary with non-normally distributed data and
normalized data and also depends on the normalization method used.