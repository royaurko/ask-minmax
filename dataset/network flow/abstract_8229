We perform a systematic analytical study of finite size effects in separable
recurrent neural network models with sequential dynamics, away from saturation.
We find two types of finite size effects: thermal fluctuations, and
disorder-induced `frozen' corrections to the mean-field laws. The finite size
effects are described by equations that correspond to a time-dependent
Ornstein-Uhlenbeck process. We show how the theory can be used to understand
and quantify various finite size phenomena in recurrent neural networks, with
and without detailed balance.