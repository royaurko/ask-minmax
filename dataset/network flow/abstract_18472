Greedy Maximal Scheduling (GMS) is an attractive low-complexity scheme for
scheduling in wireless networks. Recent work has characterized its throughput
for the case when there is no fading/channel variations. This paper aims to
understand the effect of channel variations on the relative throughput
performance of GMS vis-a-vis that of an optimal scheduler facing the same
fading. The effect is not a-priori obvious because, on the one hand, fading
could help by decoupling/precluding global states that lead to poor GMS
performance, while on the other hand fading adds another degree of freedom in
which an event unfavourable to GMS could occur.
  We show that both these situations can occur when fading is adversarial. In
particular, we first define the notion of a {\em Fading Local Pooling factor
(F-LPF)}, and show that it exactly characterizes the throughput of GMS in this
setting. We also derive general upper and lower bounds on F-LPF. Using these
bounds, we provide two example networks - one where the relative performance of
GMS is worse than if there were no fading, and one where it is better.