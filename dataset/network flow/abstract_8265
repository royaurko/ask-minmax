The average length and average relaxation time of attractors in sequence
processing neural networks are investigated. The simulation results show that a
critical point of $\alpha $, the loading ratio, is found. Below the turning
point, the average length is equal to the number of stored patterns;
conversely, the ratio of length and numbers of stored patterns, grow with an
exponential dependence $\exp (A\alpha) $. Moreover, we find that the logarithm
of average relaxation time is only linearly associated with $\alpha $ and the
turning point of coupling degree is located for examining robustness of
networks.