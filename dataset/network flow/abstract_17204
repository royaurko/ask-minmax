In this paper we provide a complete algebraic characterization of the model
implied by a Bayesian network with latent variables when the observed variables
are discrete. We show that it is algebraically equivalent to the so-called
nested Markov model, meaning that the two are the same up to inequality
constraints on the joint probabilities. The nested Markov model is therefore
the best possible approximation to the latent variable model whilst avoiding
inequalities, which are extremely complicated in general. Latent variable
models also suffer from difficulties of unidentifiable parameters and
non-regular asymptotics; in contrast the nested Markov model is fully
identifiable, represents a curved exponential family of known dimension, and
can easily be fitted using an explicit parameterization.