Artificial neural networks have already shown their success in face
recognition and similar complex pattern recognition tasks. However, a major
disadvantage of the technique is that it is extremely slow during training for
larger classes and hence not suitable for real-time complex problems such as
pattern recognition. This is an attempt to develop a parallel framework for the
training algorithm of a perceptron. In this paper, two general architectures
for a Multilayer Perceptron (MLP) have been demonstrated. The first
architecture is All-Class-in-One-Network (ACON) where all the classes are
placed in a single network and the second one is One-Class-in-One-Network
(OCON) where an individual single network is responsible for each and every
class. Capabilities of these two architectures were compared and verified in
solving human face recognition, which is a complex pattern recognition task
where several factors affect the recognition performance like pose variations,
facial expression changes, occlusions, and most importantly illumination
changes. Both the structures were implemented and tested for face recognition
purpose and experimental results show that the OCON structure performs better
than the generally used ACON ones in term of training convergence speed of the
network. Unlike the conventional sequential approach of training the neural
networks, the OCON technique may be implemented by training all the classes of
the face images simultaneously.