We introduce the diffusion and superposition distances as two metrics to
compare signals supported in the nodes of a network. Both metrics consider the
given vectors as initial temperature distributions and diffuse heat trough the
edges of the graph. The similarity between the given vectors is determined by
the similarity of the respective diffusion profiles. The superposition distance
computes the instantaneous difference between the diffused signals and
integrates the difference over time. The diffusion distance determines a
distance between the integrals of the diffused signals. We prove that both
distances define valid metrics and that they are stable to perturbations in the
underlying network. We utilize numerical experiments to illustrate their
utility in classifying signals in a synthetic network as well as in classifying
ovarian cancer histologies using gene mutation profiles of different patients.
We also reinterpret diffusion as a transformation of interrelated feature
spaces and use it as preprocessing tool for learning. We use diffusion to
increase the accuracy of handwritten digit classification.