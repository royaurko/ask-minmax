When eliciting probability models from experts, knowledge engineers may
compare the results of the model with expert judgment on test scenarios, then
adjust model parameters to bring the behavior of the model more in line with
the expert's intuition. This paper presents a methodology for analytic
computation of sensitivity values to measure the impact of small changes in a
network parameter on a target probability value or distribution. These values
can be used to guide knowledge elicitation. They can also be used in a gradient
descent algorithm to estimate parameter values that maximize a measure of
goodness-of-fit to both local and holistic probability assessments.