Motivated by current challenges in data-intensive sensor networks, we
formulate a coverage optimization problem for mobile visual sensors as a
(constrained) repeated multi-player game. Each visual sensor tries to optimize
its own coverage while minimizing the processing cost. We present two
distributed learning algorithms where each sensor only remembers its own
utility values and actions played during the last plays. These algorithms are
proven to be convergent in probability to the set of (constrained) Nash
equilibria and global optima of certain coverage performance metric,
respectively.