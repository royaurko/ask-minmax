We investigate supervised learning in neural networks. We consider a
multi-layered feed-forward network with back propagation. We find that the
network of small-world connectivity reduces the learning error and learning
time when compared to the networks of regular or random connectivity. Our study
has potential applications in the domain of data-mining, image processing,
speech recognition, and pattern recognition.