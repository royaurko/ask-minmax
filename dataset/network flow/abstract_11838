We generalize previous studies on critical phenomena in communication
networks by adding computational capabilities to the nodes. A set of tasks with
random origin, destination and computational structure is distributed on a
network modeled as a graph and the latency of each task is computed during
impulsive load simulations. The sum of all latencies is used as the energy in a
Montecarlo simulation in which a near-zero temperature leads to optimal
resource allocation whereas higher values mimic actual balancing algorithms. We
study the transition to congestion by varying two parameters: system load
(number of tasks) and temperature (resource assignment optimality). Finally,
the time-evolution of the latency is approximately recovered by interpolating
the latency probability distributions from the set of impulsive load
simulations. The time-evolution of the system allows us to study the standard
transition to the congested phase by varying the $\lambda$ parameter governing
the Poisson task production rate. This approach allows us to reproduce, at
least qualitatively, the main known results on network congestion and to gain a
deeper insight over the maximum theoretical performance of a system.