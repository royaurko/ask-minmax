A complete self-control mechanism is proposed in the dynamics of neural
networks through the introduction of a time-dependent threshold, determined in
function of both the noise and the pattern activity in the network. Especially
for sparsely coded models this mechanism is shown to considerably improve the
storage capacity, the basins of attraction and the mutual information content
of the network.