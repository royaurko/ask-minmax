We perform a deeper analysis of an axiomatic approach to the concept of
intrinsic dimension of a dataset proposed by us in the IJCNN'07 paper
(arXiv:cs/0703125). The main features of our approach are that a high intrinsic
dimension of a dataset reflects the presence of the curse of dimensionality (in
a certain mathematically precise sense), and that dimension of a discrete
i.i.d. sample of a low-dimensional manifold is, with high probability, close to
that of the manifold. At the same time, the intrinsic dimension of a sample is
easily corrupted by moderate high-dimensional noise (of the same amplitude as
the size of the manifold) and suffers from prohibitevely high computational
complexity (computing it is an $NP$-complete problem). We outline a possible
way to overcome these difficulties.