The information processing capacity of a complex dynamical system is
reflected in the partitioning of its state space into disjoint basins of
attraction, with state trajectories in each basin flowing towards their
corresponding attractor. We introduce a novel network parameter, the basin
entropy, as a measure of the complexity of information that such a system is
capable of storing. By studying ensembles of random Boolean networks, we find
that the basin entropy scales with system size only in critical regimes,
suggesting that the informationally optimal partition of the state space is
achieved when the system is operating at the critical boundary between the
ordered and disordered phases.