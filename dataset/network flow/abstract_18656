We derive learning rules for finding the connections between units in
stochastic dynamical networks from the recorded history of a ``visible'' subset
of the units. We consider two models. In both of them, the visible units are
binary and stochastic. In one model the ``hidden'' units are continuous-valued,
with sigmoidal activation functions, and in the other they are binary and
stochastic like the visible ones. We derive exact learning rules for both
cases. For the stochastic case, performing the exact calculation requires, in
general, repeated summations over an number of configurations that grows
exponentially with the size of the system and the data length, which is not
feasible for large systems. We derive a mean field theory, based on a
factorized ansatz for the distribution of hidden-unit states, which offers an
attractive alternative for large systems. We present the results of some
numerical calculations that illustrate key features of the two models and, for
the stochastic case, the exact and approximate calculations.