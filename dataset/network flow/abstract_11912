In this paper, we investigate the global exponential stability for
complex-valued recurrent neural networks with asynchronous time delays by
decomposing complex-valued networks to real and imaginary parts and construct
an equivalent real-valued system. The network model is described by a
continuous-time equation. There are two main differences of this paper with
previous works: (1), time delays can be asynchronous, i.e., delays between
different nodes are different, which makes our model more general; (2), we
prove the exponential convergence directly, while the existence and uniqueness
of the equilibrium point is just a direct consequence of the exponential
convergence. By using three generalized norms, we present some sufficient
conditions for the uniqueness and global exponential stability of the
equilibrium point for delayed complex-valued neural networks. These conditions
in our results are less restrictive because of our consideration of the
excitatory and inhibitory effects between neurons, so previous works of other
researchers can be extended. Finally, some numerical simulations are given to
demonstrate the correctness of our obtained results.