Deep neural networks have been demonstrated impressive results in various
cognitive tasks such as object detection and image classification. In order to
execute large networks, Von Neumann computers store the large number of weight
parameters in external memories, and processing elements are timed-shared,
which leads to power-hungry I/O operations and processing bottlenecks. This
paper describes a neuromorphic computing system that is designed from the
ground up for the energy-efficient evaluation of large-scale neural networks.
The computing system consists of a non-conventional compiler, a neuromorphic
architecture, and a space-efficient microarchitecture that leverages existing
integrated circuit design methodologies. The compiler factorizes a trained,
feedforward network into a sparsely connected network, compresses the weights
linearly, and generates a time delay neural network reducing the number of
connections. The connections and units in the simplified network are mapped to
silicon synapses and neurons. We demonstrate an implementation of the
neuromorphic computing system based on a field-programmable gate array that
performs the MNIST hand-written digit classification with 97.64% accuracy.