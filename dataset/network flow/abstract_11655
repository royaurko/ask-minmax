The potential of synthetic biology techniques for designing complex cellular
circuits able to solve complicated computations opens a whole domain of
exploration, beyond experiments and theory. Such cellular circuits could be
used to carry out hard tasks involving decision-making, storage of information,
or signal processing. Since Gene Regulatory Networks (GRNs) are the best known
technical approach to synthetic designs, it would be desirable to know in
advance the potential of such circuits in performing tasks and how classical
approximations dealing with neural networks can be translated into GRNs. In
this paper such a potential is analyzed. Here we show that feed-forward GRNs
are capable of performing classic machine intelligence tasks. Therefore, two
important milestones in the success of Artificial Neural Networks are reached
for models of GRNs based on Hill equations, namely the back-propagation
algorithm and the proof that GRNs can approximate arbitrary positive functions.
Potential extensions and implications for synthetic designs are outlined.