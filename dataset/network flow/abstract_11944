Here, we consider the open issue of how the energy efficiency of neural
information transmission process in a general neuronal array constrains the
network size, and how well this network size ensures the neural information
being transmitted reliably in a noisy environment. By direct mathematical
analysis, we have obtained general solutions proving that there exists an
optimal neuronal number in the network with which the average coding energy
cost (defined as energy consumption divided by mutual information) per neuron
passes through a global minimum for both subthreshold and superthreshold
signals. Varying with increases in background noise intensity, the optimal
neuronal number decreases for subthreshold and increases for suprathreshold
signals. The existence of an optimal neuronal number in an array network
reveals a general rule for population coding stating that the neuronal number
should be large enough to ensure reliable information transmission robust to
the noisy environment but small enough to minimize energy cost.