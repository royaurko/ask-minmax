In diffusion-based algorithms for adaptive distributed estimation, each node
of an adaptive network estimates a target parameter vector by creating an
intermediate estimate and then combining the intermediate estimates available
within its closed neighborhood. We analyze the performance of a
reduced-communication diffusion least mean-square (RC-DLMS) algorithm, which
allows each node to receive the intermediate estimates of only a subset of its
neighbors at each iteration. This algorithm eases the usage of network
communication resources and delivers a trade-off between estimation performance
and communication cost. We show analytically that the RC-DLMS algorithm is
stable and convergent in both mean and mean-square senses. We also calculate
its theoretical steady-state mean-square deviation. Simulation results
demonstrate a good match between theory and experiment.