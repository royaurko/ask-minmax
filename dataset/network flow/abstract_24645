Extreme learning machine (ELM), proposed by Huang et al., has been shown a
promising learning algorithm for single-hidden layer feedforward neural
networks (SLFNs). Nevertheless, because of the random choice of input weights
and biases, the ELM algorithm sometimes makes the hidden layer output matrix H
of SLFN not full column rank, which lowers the effectiveness of ELM. This paper
discusses the effectiveness of ELM and proposes an improved algorithm called
EELM that makes a proper selection of the input weights and bias before
calculating the output weights, which ensures the full column rank of H in
theory. This improves to some extend the learning rate (testing accuracy,
prediction accuracy, learning time) and the robustness property of the
networks. The experimental results based on both the benchmark function
approximation and real-world problems including classification and regression
applications show the good performances of EELM.