This paper considers a conjecture-based distributed learning approach that
enables autonomous nodes to independently optimize their transmission
probabilities in random access networks. We model the interaction among
multiple self-interested nodes as a game. It is well-known that the Nash
equilibria in this game result in zero throughput for all the nodes if they
take myopic best-response, thereby leading to a network collapse. This paper
enables nodes to behave as intelligent entities which can proactively gather
information, form internal conjectures on how their competitors would react to
their actions, and update their beliefs according to their local observations.
In this way, nodes are capable to autonomously "learn" the behavior of their
competitors, optimize their own actions, and eventually cultivate reciprocity
in the random access network. To characterize the steady-state outcome, the
conjectural equilibrium is introduced. Inspired by the biological phenomena of
"derivative action" and "gradient dynamics", two distributed conjecture-based
action update mechanisms are proposed to stabilize the random access network.
The sufficient conditions that guarantee the proposed conjecture-based learning
algorithms to converge are derived. Moreover, it is shown that all the
achievable operating points in the throughput region are essentially stable
conjectural equilibria corresponding to different conjectures. We investigate
how the conjectural equilibrium can be selected in heterogeneous networks and
how the proposed methods can be extended to ad-hoc networks. Simulations verify
that the system performance significantly outperforms existing protocols, such
as IEEE 802.11 DCF protocol and the PMAC protocol, in terms of throughput,
fairness, convergence, and stability.