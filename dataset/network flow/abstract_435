The existence of considerable amount of redundancy in the Internet traffic at
the packet level has stimulated the deployment of packet-level redundancy
elimination techniques within the network by enabling network nodes to memorize
data packets. Redundancy elimination results in traffic reduction which in turn
improves the efficiency of network links. In this paper, the concept of network
compression is introduced that aspires to exploit the statistical correlation
beyond removing large duplicate strings from the flow to better suppress
redundancy.
  In the first part of the paper, we introduce "memory-assisted compression",
which utilizes the memorized content within the network to learn the statistics
of the information source generating the packets which can then be used toward
reducing the length of codewords describing the packets emitted by the source.
Using simulations on data gathered from real network traces, we show that
memory-assisted compression can result in significant traffic reduction.
  In the second part of the paper, we study the scaling of the average
network-wide benefits of memory-assisted compression. We discuss routing and
memory placement problems in network for the reduction of overall traffic. We
derive a closed-form expression for the scaling of the gain in Erdos-Renyi
random network graphs, where obtain a threshold value for the number of
memories deployed in a random graph beyond which network-wide benefits start to
shine. Finally, the network-wide benefits are studied on Internet-like
scale-free networks. We show that non-vanishing network compression gain is
obtained even when only a tiny fraction of the total number of nodes in the
network are memory-enabled.