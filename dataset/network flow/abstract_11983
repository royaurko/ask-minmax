Feed-forward multilayer neural networks implementing random input-output
mappings develop characteristic correlations between the activity of their
hidden nodes which are important for the understanding of the storage and
generalization performance of the network. It is shown how these correlations
can be calculated from the joint probability distribution of the aligning
fields at the hidden units for arbitrary decoder function between hidden layer
and output. Explicit results are given for the parity-, and-, and
committee-machines with arbitrary number of hidden nodes near saturation.