We extend present Shannon's static statistical information theory to dynamic
processes and establish a dynamic statistical information theory. We derive the
nonlinear evolution equations of dynamic information density and dynamic
information entropy density. We present the expressions of drift information
flow and diffusion information flow, the formulas of information entropy
production rate and information dissipation rate. The information dissipation
rate is equal to the information entropy production rate in a same dynamic
system. Information diffusion and information dissipation occur at the same
time. We obtain the dynamic mutual information and dynamic channel capacity
reflecting the dynamic dissipation character in the transmission process. These
derivations and results are unified and rigorous from evolution equations of
dynamic information and dynamic information entropy without adding any extra
assumption. Two actual dynamic topics are discussed.