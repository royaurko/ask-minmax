This paper proposes a novel approach to reduce the computational cost of
evaluation of convolutional neural networks, a factor that has hindered their
deployment in low-power devices such as mobile phones. Our method is inspired
by the loop perforation technique from source code optimization and accelerates
the evaluation of bottleneck convolutional layers by exploiting the spatial
redundancy of the network. A key element of this approach is the choice of the
perforation mask. We propose and analyze different strategies for constructing
the perforation mask that can achieve the desired evaluation time with limited
loss in accuracy. We demonstrate our approach on modern CNN architectures
proposed in the literature and show that our method is able to reduce the
evaluation time by 50% with a minimal drop in accuracy.