Wireless information-centric networks consider storage as one of the network
primitives, and propose to cache data within the network in order to improve
latency and reduce bandwidth consumption. We study the throughput capacity and
delay in an information-centric network when the data cached in each node has a
limited lifetime. The results show that with some fixed request and cache
expiration rates, the order of the data access time does not change with
network growth, and the maximum throughput order is inversely proportional to
the square root and logarithm of the network size $n$ in cases of grid and
random networks, respectively. Comparing these values with the corresponding
throughput and latency with no cache capability (throughput inversely
proportional to the network size, and latency of order $\sqrt{n}$ and
$\sqrt{\frac{n}{\log n}}$ in grid and random networks, respectively), we can
actually quantify the asymptotic advantage of caching. Moreover, we compare
these scaling laws for different content discovery mechanisms and illustrate
that not much gain is lost when a simple path search is used.