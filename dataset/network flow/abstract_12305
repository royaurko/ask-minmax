Data representation is an important pre-processing step in many machine
learning algorithms. There are a number of methods used for this task such as
Deep Belief Networks (DBNs) and Discrete Fourier Transforms (DFTs). Since some
of the features extracted using automated feature extraction methods may not
always be related to a specific machine learning task, in this paper we propose
two methods in order to make a distinction between extracted features based on
their relevancy to the task. We applied these two methods to a Deep Belief
Network trained for a face recognition task.