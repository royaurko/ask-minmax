Why are most empirical networks, with the prominent exception of social ones,
generically degree-degree anticorrelated, i.e. disassortative? With a view to
answering this long-standing question, we define a general class of
degree-degree correlated networks and obtain the associated Shannon entropy as
a function of parameters. It turns out that the maximum entropy does not
typically correspond to uncorrelated networks, but to either assortative
(correlated) or disassortative (anticorrelated) ones. More specifically, for
highly heterogeneous (scale-free) networks, the maximum entropy principle
usually leads to disassortativity, providing a parsimonious explanation to the
question above. Furthermore, by comparing the correlations measured in some
real-world networks with those yielding maximum entropy for the same degree
sequence, we find a remarkable agreement in various cases. Our approach
provides a neutral model from which, in the absence of further knowledge
regarding network evolution, one can obtain the expected value of correlations.
In cases in which empirical observations deviate from the neutral predictions
-- as happens in social networks -- one can then infer that there are specific
correlating mechanisms at work.