Internet-scale distributed systems such as content delivery networks (CDNs)
operate hundreds of thousands of servers deployed in thousands of data center
locations around the globe. Since the energy costs of operating such a large IT
infrastructure are a significant fraction of the total operating costs, we
argue for redesigning CDNs to incorporate energy optimizations as a first-order
principle. We propose techniques to turn off CDN servers during periods of low
load while seeking to balance three key design goals: maximize energy
reduction, minimize the impact on client-perceived service availability (SLAs),
and limit the frequency of on-off server transitions to reduce wear-and-tear
and its impact on hardware reliability. We propose an optimal offline algorithm
and an online algorithm to extract energy savings both at the level of local
load balancing within a data center and global load balancing across data
centers. We evaluate our algorithms using real production workload traces from
a large commercial CDN. Our results show that it is possible to reduce the
energy consumption of a CDN by more than 55% while ensuring a high level of
availability that meets customer SLA requirements and incurring an average of
one on-off transition per server per day. Further, we show that keeping even
10% of the servers as hot spares helps absorb load spikes due to global flash
crowds with little impact on availability SLAs. Finally, we show that
redistributing load across proximal data centers can enhance service
availability significantly, but has only a modest impact on energy savings.