The popularization of cloud computing has raised concerns over the energy
consumption that takes place in data centers. In addition to the energy
consumed by servers, the energy consumed by large numbers of network devices
emerges as a significant problem. Existing work on energy-efficient data center
networking primarily focuses on traffic engineering, which is usually adapted
from traditional networks. We propose a new framework to embrace the new
opportunities brought by combining some special features of data centers with
traffic engineering. Based on this framework, we characterize the problem of
achieving energy efficiency with a time-aware model, and we prove its
NP-hardness with a solution that has two steps. First, we solve the problem of
assigning virtual machines (VM) to servers to reduce the amount of traffic and
to generate favorable conditions for traffic engineering. The solution reached
for this problem is based on three essential principles that we propose.
Second, we reduce the number of active switches and balance traffic flows,
depending on the relation between power consumption and routing, to achieve
energy conservation. Experimental results confirm that, by using this
framework, we can achieve up to 50 percent energy savings. We also provide a
comprehensive discussion on the scalability and practicability of the
framework.