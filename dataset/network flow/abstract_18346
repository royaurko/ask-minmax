Nonlinear Noisy Leaky Integrate and Fire (NNLIF) models for neurons networks
can be written as Fokker-Planck-Kolmogorov equations on the probability density
of neurons, the main parameters in the model being the connectivity of the
network and the noise. We analyse several aspects of the NNLIF model: the
number of steady states, a priori estimates, blow-up issues and convergence
toward equilibrium in the linear case. In particular, for excitatory networks,
blow-up always occurs for initial data concentrated close to the firing
potential. These results show how critical is the balance between noise and
excitatory/inhibitory interactions to the connectivity parameter.