Caching and multicasting at base stations are two promising approaches to
support massive content delivery over wireless networks. However, existing
scheduling designs do not make full use of the advantages of the two
approaches. In this paper, we consider the optimal dynamic multicast scheduling
to jointly minimize the average delay, power and fetching costs for
cache-enabled content-centric wireless networks. We formulate this stochastic
optimization problem as an infinite horizon average cost Markov decision
process (MDP). It is well-known to be a difficult problem and there generally
only exist numerical solutions. By using \emph{relative value iteration
algorithm} and the special structures of the request queue dynamics, we analyze
the properties of the value function and the state-action cost function of the
MDP for both the uniform and nonuniform channel cases. Based on these
properties, we show that the optimal policy, which is adaptive to the request
queue state, has a switch structure in the uniform case and a partial switch
structure in the nonuniform case. Moreover, in the uniform case with two
contents, we show that the switch curve is monotonically non-decreasing. The
optimality properties obtained in this paper can provide design insights for
practical networks.