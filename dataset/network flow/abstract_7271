Working memory, the ability to maintain and use information for several
seconds, is central to many functions of the brain. In the context continuous
variables, an important theoretical model of working memory is based on neural
networks, whose dynamics possess a continuum of marginally stable steady
states. It has been unclear whether this theoretical idea is compatible with
one of the main proposals for the architecture of cortical circuits, the
balanced network. Here we study a network with random connectivity which
generates a balanced state. We find an architecture for which the network has a
continuum of balanced states, in the limit of many neurons and many synapses
per neuron. Finite networks can sustain slow dynamics in a certain direction in
the mean activities space, but the chaotic dynamics drive diffusive motion
along the line attractor, which gradually degrades the stored memory. We
analyse the coefficient of diffusion along the attractor, and show that it
scales inversely with the system size. For a large enough (but realistic)
network size, and with suitable tuning of the network connections, it is
possible to obtain persistence over time intervals which are larger by several
orders of magnitude than the single neuron time scale.