Several methods have recently been developed for joint structure learning of
multiple (related) graphical models or networks. These methods treat individual
networks as exchangeable, such that each pair of networks are equally
encouraged to have similar structures. However, in many practical applications,
exchangeability in this sense may not hold, as some pairs of networks may be
more closely related than others, for example due to group and sub-group
structure in the data. Here we present a novel Bayesian formulation that
generalises joint structure learning beyond the exchangeable case. In addition
to a general framework for joint learning, we (i) provide a novel default prior
over the joint structure space that requires no user input; (ii) allow for
latent networks; (iii) give an efficient, exact algorithm for the case of time
series data and dynamic Bayesian networks. We present empirical results on
non-exchangeable populations, including a real data example from biology, where
cell-line-specific networks are related according to genomic features.