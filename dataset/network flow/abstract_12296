A low-complexity model for signal quality prediction in a nonlinear
fiber-optical network is developed. The model, which builds on the Gaussian
noise model, takes into account the signal degradation caused by a combination
of chromatic dispersion, nonlinear signal distortion, and amplifier noise. The
center frequencies, bandwidths, and transmit powers can be chosen independently
for each channel, which makes the model suitable for analysis and optimization
of resource allocation, routing, and scheduling in large-scale optical networks
applying flexible-grid wavelength-division multiplexing.