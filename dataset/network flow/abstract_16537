We demonstrate that the fraction of pattern sets that can be stored in
single- and hidden-layer perceptrons exhibits finite size scaling. This feature
allows to estimate the critical storage capacity \alpha_c from simulations of
relatively small systems. We illustrate this approach by determining \alpha_c,
together with the finite size scaling exponent \nu, for storing Gaussian
patterns in committee and parity machines with binary couplings and up to K=5
hidden units.