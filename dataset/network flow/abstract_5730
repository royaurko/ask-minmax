In the context of attractor neural networks, we study how the equilibrium
analog neural activities, reached by the network dynamics during memory
retrieval, may improve storage performance by reducing the interferences
between the recalled pattern and the other stored ones. We determine a simple
dynamics that stabilizes network states which are highly correlated with the
retrieved pattern, for a number of stored memories that does not exceed
$\alpha_{\star} N$, where $\alpha_{\star}\in[0,0.41]$ depends on the global
activity level in the network and $N$ is the number of neurons.