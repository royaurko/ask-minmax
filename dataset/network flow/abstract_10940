The storage capacity of the Hopfield model is about 15% of the network size.
It can be increased significantly in the Potts-glass model of the associative
memory only. In this model neurons can be in more than two different states. We
show that even greater storage capacity can be achieved in the parametrical
neural network (PNN) that is based on the parametrical four-wave mixing process
that is well-known in nonlinear optics. We present a uniform formalism allowing
us to describe both PNN and the Potts-glass associative memory. To estimate the
storage capacity we use the Chebyshev-Chernov statistical technique.