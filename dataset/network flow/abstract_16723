A Mean-Field theory is presented and applied to a Cellular Automata model of
distributed packet-switched networks. It is proved that, under a certain set of
assumptions, the critical input traffic is inversely proportional to the free
packet delay of the model. The applicability of Mean-Field theory in queue
length estimation is also investigated. Results of theoretical derivations are
compared with simulation samples to demonstrate the availability of the
Mean-Field approach.