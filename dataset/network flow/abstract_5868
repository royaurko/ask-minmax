Chaotic neural networks have received a great deal of attention these last
years. In this paper we establish a precise correspondence between the
so-called chaotic iterations and a particular class of artificial neural
networks: global recurrent multi-layer perceptrons. We show formally that it is
possible to make these iterations behave chaotically, as defined by Devaney,
and thus we obtain the first neural networks proven chaotic. Several neural
networks with different architectures are trained to exhibit a chaotical
behavior.