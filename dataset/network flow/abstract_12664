Mapping the Internet generally consists in sampling the network from a
limited set of sources by using traceroute-like probes. This methodology, akin
to the merging of different spanning trees to a set of destination, has been
argued to introduce uncontrolled sampling biases that might produce statistical
properties of the sampled graph which sharply differ from the original ones. In
this paper we explore these biases and provide a statistical analysis of their
origin. We derive an analytical approximation for the probability of edge and
vertex detection that exploits the role of the number of sources and targets
and allows us to relate the global topological properties of the underlying
network with the statistical accuracy of the sampled graph. In particular, we
find that the edge and vertex detection probability depends on the betweenness
centrality of each element. This allows us to show that shortest path routed
sampling provides a better characterization of underlying graphs with broad
distributions of connectivity. We complement the analytical discussion with a
throughout numerical investigation of simulated mapping strategies in network
models with different topologies. We show that sampled graphs provide a fair
qualitative characterization of the statistical properties of the original
networks in a fair range of different strategies and exploration parameters.
Moreover, we characterize the level of redundancy and completeness of the
exploration process as a function of the topological properties of the network.
Finally, we study numerically how the fraction of vertices and edges discovered
in the sampled graph depends on the particular deployements of probing sources.
The results might hint the steps toward more efficient mapping strategies.