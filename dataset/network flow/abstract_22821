In this paper, we describe a simple strategy for mitigating variability in
temporal data series by shifting focus onto long-term, frequency domain
features that are less susceptible to variability. We apply this method to the
human action recognition task and demonstrate how working in the frequency
domain can yield good recognition features for commonly used optical flow and
articulated pose features, which are highly sensitive to small differences in
motion, viewpoint, dynamic backgrounds, occlusion and other sources of
variability. We show how these frequency-based features can be used in
combination with a simple forest classifier to achieve good and robust results
on the popular KTH Actions dataset.