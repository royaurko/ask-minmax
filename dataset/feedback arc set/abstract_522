Active learning strategies respond to the costly labelling task in a
supervised classification by selecting the most useful unlabelled examples in
training a predictive model. Many conventional active learning algorithms focus
on refining the decision boundary, rather than exploring new regions that can
be more informative. In this setting, we propose a sequential algorithm named
EG-Active that can improve any Active learning algorithm by an optimal random
exploration. Experimental results show a statistically significant and
appreciable improvement in the performance of our new approach over the
existing active feedback methods.