We propose a parsimonious extension of the classical latent class model to
cluster categorical data by relaxing the class conditional independence
assumption. Under this new mixture model, named Conditional Modes Model,
variables are grouped into conditionally independent blocks. The corresponding
block distribution is a parsimonious multinomial distribution where the few
free parameters correspond to the most likely modality crossings, while the
remaining probability mass is uniformly spread over the other modality
crossings. Thus, the proposed model allows to bring out the intra-class
dependency between variables and to summarize each class by a few
characteristic modality crossings. The model selection is performed via a
Metropolis-within-Gibbs sampler to overcome the computational intractability of
the block structure search. As this approach involves the computation of the
integrated complete-data likelihood, we propose a new method (exact for the
continuous parameters and approximated for the discrete ones) which avoids the
biases of the \textsc{bic} criterion pointed out by our experiments. Finally,
the parameters are only estimated for the best model via an \textsc{em}
algorithm. The characteristics of the new model are illustrated on simulated
data and on two biological data sets. These results strengthen the idea that
this simple model allows to reduce biases involved by the conditional
independence assumption and gives meaningful parameters. Both applications were
performed with the R package \texttt{CoModes}