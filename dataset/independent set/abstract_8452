In this paper we introduce randomized $t$-type statistics that will be
referred to as randomized pivots. We show that these randomized pivots yield
central limit theorems with a significantly smaller magnitude of error as
compared to that of their classical counterparts under the same conditions.
This constitutes a desirable result when a relatively small number of data is
available. When a data set is too big to be processed, we use our randomized
pivots to make inference about the mean based on significantly smaller
sub-samples. The approach taken is shown to relate naturally to estimating
distributions of both small and big data sets.