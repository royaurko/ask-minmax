We consider the problem of learning causal information between random
variables in directed acyclic graphs (DAGs) when allowing arbitrarily many
latent and selection variables. The FCI (Fast Causal Inference) algorithm has
been explicitly designed to infer conditional independence and causal
information in such settings. However, FCI is computationally infeasible for
large graphs. We therefore propose the new RFCI algorithm, which is much faster
than FCI. In some situations the output of RFCI is slightly less informative,
in particular with respect to conditional independence information. However, we
prove that any causal information in the output of RFCI is correct in the
asymptotic limit. We also define a class of graphs on which the outputs of FCI
and RFCI are identical. We prove consistency of FCI and RFCI in sparse
high-dimensional settings, and demonstrate in simulations that the estimation
performances of the algorithms are very similar. All software is implemented in
the R-package pcalg.