We address some computational issues that may hinder the use of AMP chain
graphs in practice. Specifically, we show how a discrete probability
distribution that satisfies all the independencies represented by an AMP chain
graph factorizes according to it. We show how this factorization makes it
possible to perform inference and parameter learning efficiently, by adapting
existing algorithms for Markov and Bayesian networks. Finally, we turn our
attention to another issue that may hinder the use of AMP CGs, namely the lack
of an intuitive interpretation of their edges. We provide one such
interpretation.