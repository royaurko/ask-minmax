Goodness-of-fit tests gauge whether a given set of observations is consistent
(up to expected random fluctuations) with arising as independent and
identically distributed (i.i.d.) draws from a user-specified probability
distribution known as the "model." The standard gauges involve the discrepancy
between the model and the empirical distribution of the observed draws. Some
measures of discrepancy are cumulative; others are not. The most popular
cumulative measure is the Kolmogorov-Smirnov statistic; when all probability
distributions under consideration are discrete, a natural noncumulative measure
is the Euclidean distance between the model and the empirical distributions. In
the present paper, both mathematical analysis and its illustration via various
data sets indicate that the Kolmogorov-Smirnov statistic tends to be more
powerful than the Euclidean distance when there is a natural ordering for the
values that the draws can take -- that is, when the data is ordinal -- whereas
the Euclidean distance is more reliable and more easily understood than the
Kolmogorov-Smirnov statistic when there is no natural ordering (or partial
order) -- that is, when the data is nominal.