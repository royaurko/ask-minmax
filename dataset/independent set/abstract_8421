We review a nonparametric version of Amari's Information Geometry in which
the set of positive probability densities on a given sample space is endowed
with an atlas of charts to form a differentiable manifold modeled on Orlicz
Banach spaces. This nonparametric setting is used to discuss the setting of
typical problems in Machine Learning and Statistical Physics, such as relaxed
optimization, Kullback-Leibler divergence, Boltzmann entropy, Boltzmann
equation