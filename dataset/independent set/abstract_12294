This paper investigates the minimum mean square error (MMSE) estimation of x,
given the observation y = Hx+n, when x and n are independent and Gaussian
Mixture (GM) distributed. The introduction of GM distributions, represents a
generalization of the more familiar and simpler Gaussian signal and Gaussian
noise instance. We present the necessary theoretical foundation and derive the
MMSE estimator for x in a closed form. Furthermore, we provide upper and lower
bounds for its mean square error (MSE). These bounds are validated through
Monte Carlo simulations.