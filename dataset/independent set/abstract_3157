Online estimation and modelling of i.i.d. data for short sequences over large
or complex "alphabets" is a ubiquitous (sub)problem in machine learning,
information theory, data compression, statistical language processing, and
document analysis. The Dirichlet-Multinomial distribution (also called Polya
urn scheme) and extensions thereof are widely applied for online i.i.d.
estimation. Good a-priori choices for the parameters in this regime are
difficult to obtain though. I derive an optimal adaptive choice for the main
parameter via tight, data-dependent redundancy bounds for a related model. The
1-line recommendation is to set the 'total mass' = 'precision' =
'concentration' parameter to m/2ln[(n+1)/m], where n is the (past) sample size
and m the number of different symbols observed (so far). The resulting
estimator (i) is simple, (ii) online, (iii) fast, (iv) performs well for all m,
small, middle and large, (v) is independent of the base alphabet size, (vi)
non-occurring symbols induce no redundancy, (vii) the constant sequence has
constant redundancy, (viii) symbols that appear only finitely often have
bounded/constant contribution to the redundancy, (ix) is competitive with
(slow) Bayesian mixing over all sub-alphabets.