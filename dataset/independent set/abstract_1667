In [Chen, D., Owen, Ann. Stat., 39, 673--701, 2011] Markov chain Monte Carlo
(MCMC) was studied under the assumption that the driver sequence is a
deterministic sequence rather than independent U(0,1) random variables. Therein
it was shown that as long as the driver sequence is completely uniformly
distributed, the Markov chain consistently samples the target distribution. The
present work extends these results by providing bounds on the convergence rate
of the discrepancy between the empirical distribution of the Markov chain and
the target distribution, under the assumption that the Markov chain is
uniformly ergodic.
  In a general setting we show the existence of driver sequences for which the
discrepancy of the Markov chain from the target distribution with respect to
certain test sets converges with (almost) the usual Monte Carlo rate of
$n^{-1/2}$.