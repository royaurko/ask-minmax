Spectral methods that are based on eigenvectors and eigenvalues of discrete
graph Laplacians, such as Diffusion Maps and Laplacian Eigenmaps are often used
for manifold learning and non-linear dimensionality reduction. It was
previously shown by Belkin and Niyogi \cite{belkin_niyogi:2007} that the
eigenvectors and eigenvalues of the graph Laplacian converge to the
eigenfunctions and eigenvalues of the Laplace-Beltrami operator of the manifold
in the limit of infinitely many data points sampled independently from the
uniform distribution over the manifold. Recently, we introduced Vector
Diffusion Maps and showed that the connection Laplacian of the tangent bundle
of the manifold can be approximated from random samples. In this paper, we
present a unified framework for approximating other connection Laplacians over
the manifold by considering its principle bundle structure. We prove that the
eigenvectors and eigenvalues of these Laplacians converge in the limit of
infinitely many independent random samples. We generalize the spectral
convergence results to the case where the data points are sampled from a
non-uniform distribution, and for manifolds with and without boundary.