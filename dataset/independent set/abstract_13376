The fate of ionizing radiation is vital for understanding cosmic ionization,
energy budgets in the interstellar and intergalactic medium, and star formation
rate indicators. The low observed escape fractions of ionizing radiation have
not been adequately explained, and there is evidence that some starbursts have
high escape fractions. We examine the spectral energy distributions of a sample
of local star-forming galaxies, containing thirteen local starburst galaxies
and ten of their ordinary star-forming counterparts, to determine if there
exist significant differences in the fate of ionizing radiation in these
galaxies. We find that the galaxy-to-galaxy variations in the SEDs is much
larger than any systematic differences between starbursts and non-starbursts.
For example, we find no significant differences in the total absorption of
ionizing radiation by dust, traced by the 24um, 70um, and 160um MIPS bands of
the Spitzer Space Telescope, although the dust in starburst galaxies appears to
be hotter than that of non-starburst galaxies. We also observe no excess
ultraviolet flux in the GALEX bands that could indicate a high escape fraction
of ionizing photons in starburst galaxies. The small H-alpha fractions of the
diffuse, warm ionized medium in starburst galaxies are apparently due to
temporarily boosted H-alpha luminosity within the star-forming regions
themselves, with an independent, constant WIM luminosity. This independence of
the WIM and starburst luminosities contrasts with WIM behavior in non-starburst
galaxies and underscores our poor understanding of radiation transfer in both
ordinary and starburst galaxies.