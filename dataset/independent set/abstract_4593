Let ${\cal{D}}$ = $\{d_1, d_2, d_3, ..., d_D\}$ be a given set of $D$
(string) documents of total length $n$. The top-$k$ document retrieval problem
is to index $\cal{D}$ such that when a pattern $P$ of length $p$, and a
parameter $k$ come as a query, the index returns the $k$ most relevant
documents to the pattern $P$. Hon et. al. \cite{HSV09} gave the first linear
space framework to solve this problem in $O(p + k\log k)$ time. This was
improved by Navarro and Nekrich \cite{NN12} to $O(p + k)$. These results are
powerful enough to support arbitrary relevance functions like frequency,
proximity, PageRank, etc. In many applications like desktop or email search,
the data resides on disk and hence disk-bound indexes are needed. Despite of
continued progress on this problem in terms of theoretical, practical and
compression aspects, any non-trivial bounds in external memory model have so
far been elusive. Internal memory (or RAM) solution to this problem decomposes
the problem into $O(p)$ subproblems and thus incurs the additive factor of
$O(p)$. In external memory, these approaches will lead to $O(p)$ I/Os instead
of optimal $O(p/B)$ I/O term where $B$ is the block-size. We re-interpret the
problem independent of $p$, as interval stabbing with priority over tree-shaped
structure. This leads us to a linear space index in external memory supporting
top-$k$ queries (with unsorted outputs) in near optimal $O(p/B + \log_B n +
\log^{(h)} n + k/B)$ I/Os for any constant $h${$\log^{(1)}n =\log n$ and
$\log^{(h)} n = \log (\log^{(h-1)} n)$}. Then we get $O(n\log^*n)$ space index
with optimal $O(p/B+\log_B n + k/B)$ I/Os.