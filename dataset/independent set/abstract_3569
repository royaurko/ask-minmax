Given a weighted graph $G$ and an error parameter $\epsilon > 0$, the {\em
graph sparsification} problem requires sampling edges in $G$ and giving the
sampled edges appropriate weights to obtain a sparse graph $G_{\epsilon}$
(containing O(n\log n) edges in expectation) with the following property: the
weight of every cut in $G_{\epsilon}$ is within a factor of $(1\pm \epsilon)$
of the weight of the corresponding cut in $G$. We provide a generic framework
that sets out sufficient conditions for any particular sampling scheme to
result in good sparsifiers, and obtain a set of results by simple
instantiations of this framework. The results we obtain include the following:
(1) We improve the time complexity of graph sparsification from O(m\log^3 n) to
O(m + n\log^4 n) for graphs with polynomial edge weights. (2) We improve the
time complexity of graph sparsification from O(m\log^3 n) to O(m\log^2 n) for
graphs with arbitrary edge weights. (3) If the size of the sparsifier is
allowed to be O(n\log^2 n/\epsilon^2) instead of O(n\log n/\epsilon^2), we
improve the time complexity of sparsification to O(m) for graphs with
polynomial edge weights. (4) We show that sampling using standard
connectivities results in good sparsifiers, thus resolving an open question of
Benczur and Karger. As a corollary, we give a simple proof of (a slightly
weaker version of) a result due to Spielman and Srivastava showing that
sampling using effective resistances produces good sparsifiers. (5) We give a
simple proof showing that sampling using strong connectivities results in good
sparsifiers, a result obtained previously using a more involved proof by
Benczur and Karger. A key ingredient of our proofs is a generalization of
bounds on the number of small cuts in an undirected graph due to Karger; this
generalization might be of independent interest.