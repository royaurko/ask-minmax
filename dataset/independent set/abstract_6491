We consider an independence feature screening technique for identifying
explanatory variables that locally contribute to the response variable in
high-dimensional regression analysis. Without requiring a specific parametric
form of the underlying data model, our approach accommodates a wide spectrum of
nonparametric and semiparametric model families. To detect the local
contributions of explanatory variables, our approach constructs empirical
likelihood locally in conjunction with marginal nonparametric regressions.
Since our approach actually requires no estimation, it is advantageous in
scenarios such as the single-index models where even specification and
identification of a marginal model is an issue. By automatically incorporating
the level of variation of the nonparametric regression and directly assessing
the strength of data evidence supporting local contribution from each
explanatory variable, our approach provides a unique perspective for solving
feature screening problems. Theoretical analysis shows that our approach can
handle data dimensionality growing exponentially with the sample size. With
extensive theoretical illustrations and numerical examples, we show that the
local independence screening approach performs promisingly.