The first-order moving average model or MA(1) is given by
$X_t=Z_t-\theta_0Z_{t-1}$, with independent and identically distributed
$\{Z_t\}$. This is arguably the simplest time series model that one can write
down. The MA(1) with unit root ($\theta_0=1$) arises naturally in a variety of
time series applications. For example, if an underlying time series consists of
a linear trend plus white noise errors, then the differenced series is an MA(1)
with unit root. In such cases, testing for a unit root of the differenced
series is equivalent to testing the adequacy of the trend plus noise model. The
unit root problem also arises naturally in a signal plus noise model in which
the signal is modeled as a random walk. The differenced series follows a MA(1)
model and has a unit root if and only if the random walk signal is in fact a
constant. The asymptotic theory of various estimators based on Gaussian
likelihood has been developed for the unit root case and nearly unit root case
($\theta=1+\beta/n,\beta\le0$). Unlike standard $1/\sqrt{n}$-asymptotics, these
estimation procedures have $1/n$-asymptotics and a so-called pile-up effect, in
which P$(\hat{\theta}=1)$ converges to a positive value. One explanation for
this pile-up phenomenon is the lack of identifiability of $\theta$ in the
Gaussian case. That is, the Gaussian likelihood has the same value for the two
sets of parameter values $(\theta,\sigma^2)$ and $(1/\theta,\theta^2\sigma^2$).
It follows that $\theta=1$ is always a critical point of the likelihood
function. In contrast, for non-Gaussian noise, $\theta$ is identifiable for all
real values. Hence it is no longer clear whether or not the same pile-up
phenomenon will persist in the non-Gaussian case. In this paper, we focus on
limiting pile-up probabilities for estimates of $\theta_0$ based on a Laplace
likelihood. In some cases, these estimates can be viewed as Least Absolute
Deviation (LAD) estimates. Simulation results illustrate the limit theory.