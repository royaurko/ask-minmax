We study the capacity with which a system of independent neuron-like units
represents a given set of stimuli. We assume that each neuron provides a fixed
amount of information, and that the information provided by different neurons
has a random overlap. We derive analytically the dependence of the mutual
information between the set of stimuli and the neural responses on the number
of units sampled. For a large set of stimuli, the mutual information rises
linearly with the number of neurons, and later saturates exponentially at its
maximum value.