We investigate the question under which conditions the algebraic difference
between two independent random Cantor sets $C_1$ and $C_2$ almost surely
contains an interval, and when not. The natural condition is whether the sum
$d_1+d_2$ of the Hausdorff dimensions of the sets is smaller (no interval) or
larger (an interval) than 1. Palis conjectured that \emph{generically} it
should be true that $d_1+d_2>1$ should imply that $C_1-C_2$ contains an
interval. We prove that for 2-adic random Cantor sets generated by a vector of
probabilities $(p_0,p_1)$ the interior of the region where the Palis conjecture
does not hold is given by those $p_0,p_1$ which satisfy $p_0+p_1>\sqrt{2}$ and
$p_0p_1(1+p_0^2+p_1^2)<1$. We furthermore prove a general result which
characterizes the interval/no interval property in terms of the lower spectral
radius of a set of $2\times 2$ matrices.