We present an end-to-end, domain-independent neural encoder-aligner-decoder
model for selective generation, i.e., the joint task of content selection and
surface realization. Our model first encodes the full set of over-determined
database event records (e.g., in weather forecasting and sportscasting) via a
memory-based recurrent neural network (LSTM), then utilizes a novel
coarse-to-fine (hierarchical), multi-input aligner to identify the small subset
of salient records to talk about, and finally employs a decoder to generate
free-form descriptions of the aligned, selected records. Our model achieves up
to 54% relative improvement over the current state-of-the-art on the benchmark
WeatherGov dataset, despite using no specialized features or resources. Using a
simple k-nearest neighbor beam helps further. Finally, we also demonstrate the
generalizability of our method on the RoboCup dataset, where it gets results
that are competitive with state-of-the-art, despite being severely
data-starved.