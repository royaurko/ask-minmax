Shannon's Entropy Power Inequality can be viewed as characterizing the
minimum differential entropy achievable by the sum of two independent random
variables with fixed differential entropies. The entropy power inequality has
played a key role in resolving a number of problems in information theory. It
is therefore interesting to examine the existence of a similar inequality for
discrete random variables. In this paper we obtain an entropy power inequality
for random variables taking values in an abelian group of order 2^n, i.e. for
such a group G we explicitly characterize the function f_G(x,y) giving the
minimum entropy of the sum of two independent G-valued random variables with
respective entropies x and y. Random variables achieving the extremum in this
inequality are thus the analogs of Gaussians in this case, and these are also
determined. It turns out that f_G(x,y) is convex in x for fixed y and, by
symmetry, convex in y for fixed x. This is a generalization to abelian groups
of order 2^n of the result known as Mrs. Gerber's Lemma.