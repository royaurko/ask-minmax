Learning-based control methods are an attractive approach for addressing
performance and efficiency challenges in robotics and automation systems. One
such technique that has found application in these domains is learning-based
model predictive control (LBMPC). An important novelty of LBMPC lies in the
fact that its robustness and stability properties are independent of the type
of online learning used. This allows the use of advanced statistical or machine
learning methods to provide the adaptation for the controller. This paper is
concerned with providing practical comparisons of different optimization
algorithms for implementing the LBMPC method, for the special case where the
dynamic model of the system is linear and the online learning provides linear
updates to the dynamic model. For comparison purposes, we have implemented a
primal-dual infeasible start interior point method that exploits the sparsity
structure of LBMPC. Our open source implementation (called LBmpcIPM) is
available through a BSD license and is provided freely to enable the rapid
implementation of LBMPC on other platforms. This solver is compared to the
dense active set solvers LSSOL and qpOASES using a quadrotor helicopter
platform. Two scenarios are considered: The first is a simulation comparing
hovering control for the quadrotor, and the second is on-board control
experiments of dynamic quadrotor flight. Though the LBmpcIPM method has better
asymptotic computational complexity than LSSOL and qpOASES, we find that for
certain integrated systems (like our quadrotor testbed) these methods can
outperform LBmpcIPM. This suggests that actual benchmarks should be used when
choosing which algorithm is used to implement LBMPC on practical systems.