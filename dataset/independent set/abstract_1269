We say a multivariate function or a probability measure is one-component
regularly varying if it exhibits regular variation with respect to one of its
components. We generalize the representation theorem and Karamata's theorem for
one-component regular variation, and as a consequence we characterize
homogeneous probability distributions.
  Inferring the distribution of a random vector $\boldsymbol X$ given that its
norm exceeds a large threshold requires modeling a homogeneous limiting
density. We suggest an approach based on graphical models which is suitable for
high-dimensional vectors. We propose the notion of asymptotic conditional
independence and generalize the Hammersley-Clifford theorem to asymptotic
settings.