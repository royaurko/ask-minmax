Understanding a neural code requires knowledge both of the elementary symbols
that transmit information and of the algorithm for translating these symbols
into sensory signals or motor actions. We show that these questions can be
separated: the information carried by any candidate symbol in the code--- a
pattern of spikes across time or across a population of cells---can be
measured, independent of assumptions about what these patterns might represent.
By comparing the information carried by a compound pattern with the information
carried independently by its parts, we measure directly the synergy among these
parts. We illustrate the use of these methods by applying them to experiments
on the motion sensitive neuron H1 of the fly's visual system, where we confirm
that two spikes close together in time carry far more than twice the
information carried by a single spike. We analyze the sources of this synergy,
and provide evidence that pairs of spikes close together in time may be special
symbols in the code of H1.