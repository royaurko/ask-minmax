To define and identify a region-of-interest (ROI) in a digital image, the
shape descriptor of the ROI has to be described in terms of its boundary
characteristics. To address the generic issues of contour tracking, the yConvex
Hypergraph (yCHG) model was proposed by Kanna et al [1]. In this work, we
propose a parallel approach to implement the yCHG model by exploiting massively
parallel cores of NVIDIA's Compute Unified Device Architecture (CUDA). We
perform our experiments on the MODIS satellite image database by NASA, and
based on our analysis we observe that the performance of the serial
implementation is better on smaller images, but once the threshold is achieved
in terms of image resolution, the parallel implementation outperforms its
sequential counterpart by 2 to 10 times (2x-10x). We also conclude that an
increase in the number of hyperedges in the ROI of a given size does not impact
the performance of the overall algorithm.