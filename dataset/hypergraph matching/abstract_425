We present a new model for LT codes which simplifies the analysis of the
error probability of decoding by belief propagation. For any given degree
distribution, we provide the first rigorous expression for the limiting error
probability as the length of the code goes to infinity via recent results in
random hypergraphs [Darling-Norris 2005]. For a code of finite length, we
provide an algorithm for computing the probability of error of the decoder.
This algorithm improves the one of [Karp-Luby-Shokrollahi 2004] by a linear
factor.