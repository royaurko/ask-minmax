The strength of association between a pair of data vectors is represented by
a nonnegative real number, called matching weight. For dimensionality
reduction, we consider a linear transformation of data vectors, and define a
matching error as the weighted sum of squared distances between transformed
vectors with respect to the matching weights. Given data vectors and matching
weights, the optimal linear transformation minimizing the matching error is
solved by the spectral graph embedding of Yan et al. (2007). This method is a
generalization of the canonical correlation analysis, and will be called as
matching correlation analysis (MCA). In this paper, we consider a novel
sampling scheme where the observed matching weights are randomly sampled from
underlying true matching weights with small probability, whereas the data
vectors are treated as constants. We then investigate a cross-validation by
resampling the matching weights. Our asymptotic theory shows that the
cross-validation, if rescaled properly, computes an unbiased estimate of the
matching error with respect to the true matching weights. Existing works of
cross-validation for resampling data vectors, instead of resampling matching
weights, are not applicable here. MCA can be used for data vectors from
multiple domains with different dimensions via the "embarrassingly simple
coding" of Shimodaira (2014), and thus our results are directly applicable to
the cross-domain matching for searching closely related vectors across domains.