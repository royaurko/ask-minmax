We present a multi-GPU graph processing library that allows programmers to
easily extend single-GPU graph algorithms to achieve scalable performance on
large graph datasets with billions of edges. Our design only requires users to
specify a few algorithm-dependent blocks, hiding most multi-GPU related
implementation details. Our design effectively overlaps computation and data
transfer and implements a just-enough memory allocation scheme that allows
memory usage to scale with more GPUs. We achieve ~20 GTEPS peak performance for
BFS, demonstrating a ~6X speed-up with ~2X total GPU memory consumption on 8
GPUs. We identify synchronization/data communication patterns, graph
topologies, and partitioning algorithms as limiting factors to further
scalability.