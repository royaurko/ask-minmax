We analyze the problem of distributed power allocation for orthogonal
multiple access channels by considering a continuous non-cooperative game whose
strategy space represents the users' distribution of transmission power over
the network's channels. When the channels are static, we find that this game
admits an exact potential function and this allows us to show that it has a
unique equilibrium almost surely. Furthermore, using the game's potential
property, we derive a modified version of the replicator dynamics of
evolutionary game theory which applies to this continuous game, and we show
that if the network's users employ a distributed learning scheme based on these
dynamics, then they converge to equilibrium exponentially quickly. On the other
hand, a major challenge occurs if the channels do not remain static but
fluctuate stochastically over time, following a stationary ergodic process. In
that case, the associated ergodic game still admits a unique equilibrium, but
the learning analysis becomes much more complicated because the replicator
dynamics are no longer deterministic. Nonetheless, by employing results from
the theory of stochastic approximation, we show that users still converge to
the game's unique equilibrium.
  Our analysis hinges on a game-theoretical result which is of independent
interest: in finite player games which admit a (possibly nonlinear) convex
potential function, the replicator dynamics (suitably modified to account for
nonlinear payoffs) converge to an eps-neighborhood of an equilibrium at time of
order O(log(1/eps)).