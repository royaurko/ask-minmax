We investigate the asymptotic behavior of one version of the so-called
two-armed bandit algorithm. It is an example of stochastic approximation
procedure whose associated ODE has both a repulsive and an attractive
equilibrium, at which the procedure is noiseless. We show that if the gain
parameter is constant or goes to 0 not too fast, the algorithm does fall in the
noiseless repulsive equilibrium with positive probability, whereas it always
converges to its natural attractive target when the gain parameter goes to zero
at some appropriate rates depending on the parameters of the model. We also
elucidate the behavior of the constant step algorithm when the step goes to 0.
Finally, we highlight the connection between the algorithm and the
 Polya urn. An application to asset allocation is briefly described.