In this paper, we propose a distributed reinforcement learning (RL) technique
called distributed power control using Q-learning (DPC-Q) to manage the
interference caused by the femtocells on macro-users in the downlink. The DPC-Q
leverages Q-Learning to identify the sub-optimal pattern of power allocation,
which strives to maximize femtocell capacity, while guaranteeing macrocell
capacity level in an underlay cognitive setting. We propose two different
approaches for the DPC-Q algorithm: namely, independent, and cooperative. In
the former, femtocells learn independently from each other while in the latter,
femtocells share some information during learning in order to enhance their
performance. Simulation results show that the independent approach is capable
of mitigating the interference generated by the femtocells on macro-users.
Moreover, the results show that cooperation enhances the performance of the
femtocells in terms of speed of convergence, fairness and aggregate femtocell
capacity.