Bayesian methods are appealing in their flexibility in modeling complex data
and their ability to capture uncertainty in parameters. However, when Bayes'
rule does not result in closed-form, most approximate Bayesian inference
algorithms lacks either scalability or rigorous guarantees. To tackle this
challenge, we propose a scalable yet simple algorithm, Particle Mirror Descent
(PMD), to iteratively approximate the posterior density. PMD is inspired by
stochastic functional mirror descent where one descends in the density space
using a small batch of data points at each iteration, and by particle filtering
where one uses samples to approximate a function. We prove result of the first
kind that, after $T$ iterations, PMD provides a posterior density estimator
that converges in terms of $KL$-divergence to the true posterior in rate
$O(1/\sqrt{T})$. We show that PMD is competitive to several scalable Bayesian
algorithms in mixture models, Bayesian logistic regression, sparse Gaussian
processes and latent Dirichlet allocation.