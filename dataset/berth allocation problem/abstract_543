Recent studies inspired by results from random matrix theory [1,2,3] found
that covariance matrices determined from empirical financial time series appear
to contain such a high amount of noise that their structure can essentially be
regarded as random. This seems, however, to be in contradiction with the
fundamental role played by covariance matrices in finance, which constitute the
pillars of modern investment theory and have also gained industry-wide
applications in risk management. Our paper is an attempt to resolve this
embarrassing paradox. The key observation is that the effect of noise strongly
depends on the ratio r = n/T, where n is the size of the portfolio and T the
length of the available time series. On the basis of numerical experiments and
analytic results for some toy portfolio models we show that for relatively
large values of r (e.g. 0.6) noise does, indeed, have the pronounced effect
suggested by [1,2,3] and illustrated later by [4,5] in a portfolio optimization
context, while for smaller r (around 0.2 or below), the error due to noise
drops to acceptable levels. Since the length of available time series is for
obvious reasons limited in any practical application, any bound imposed on the
noise-induced error translates into a bound on the size of the portfolio. In a
related set of experiments we find that the effect of noise depends also on
whether the problem arises in asset allocation or in a risk measurement
context: if covariance matrices are used simply for measuring the risk of
portfolios with a fixed composition rather than as inputs to optimization, the
effect of noise on the measured risk may become very small.