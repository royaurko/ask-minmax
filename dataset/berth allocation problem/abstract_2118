As ontologies proliferate and automatic reasoners become more powerful, the
problem of protecting sensitive information becomes more serious. In
particular, as facts can be inferred from other facts, it becomes increasingly
likely that information included in an ontology, while not itself deemed
sensitive, may be able to be used to infer other sensitive information.
  We first consider the problem of testing an ontology for safeness defined as
its not being able to be used to derive any sensitive facts using a given
collection of inference rules. We then consider the problem of optimizing an
ontology based on the criterion of making as much useful information as
possible available without revealing any sensitive facts.