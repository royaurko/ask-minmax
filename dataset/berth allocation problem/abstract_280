We consider the problem of distributed load balancing in heterogenous
parallel server systems, where the service rate achieved by a user at a server
depends on both the user and the server. Such heterogeneity typically arises in
wireless networks (e.g., servers may represent frequency bands, and the service
rate of a user varies across bands). Users select servers in a distributed
manner. They initially attach to an arbitrary server. However, at random
instants of time, they may probe the load at a new server and migrate there to
improve their service rate. We analyze the system dynamics under the natural
Random Local Search (RLS) migration scheme, introduced in \cite{sig10}. Under
this scheme, when a user has the opportunity to switch servers, she does it
only if this improves her service rate. The dynamics under RLS may be
interpreted as those generated by strategic players updating their strategy in
a load balancing game. In closed systems, where the user population is fixed,
we show that this game has pure Nash Equilibriums (NEs), and we analyze their
efficiency. We further prove that when the user population grows large, pure
NEs get closer to a Proportionally Fair (PF) allocation of users to servers,
and we characterize the gap between equilibriums and this ideal allocation
depending on user population. Under the RLS algorithm, the system converges to
pure NEs: we study the time it takes for the system to reach the PF allocation
within a certain margin. In open systems, where users randomly enter the system
and leave upon service completion, we establish that the RLS algorithm
stabilizes the system whenever this it at all possible, i.e., it is
throughput-optimal.