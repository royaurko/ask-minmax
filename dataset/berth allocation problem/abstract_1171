Supervised topic models utilize document's side information for discovering
predictive low dimensional representations of documents. Existing models apply
the likelihood-based estimation. In this paper, we present a general framework
of max-margin supervised topic models for both continuous and categorical
response variables. Our approach, the maximum entropy discrimination latent
Dirichlet allocation (MedLDA), utilizes the max-margin principle to train
supervised topic models and estimate predictive topic representations that are
arguably more suitable for prediction tasks. The general principle of MedLDA
can be applied to perform joint max-margin learning and maximum likelihood
estimation for arbitrary topic models, directed or undirected, and supervised
or unsupervised, when the supervised side information is available. We develop
efficient variational methods for posterior inference and parameter estimation,
and demonstrate qualitatively and quantitatively the advantages of MedLDA over
likelihood-based topic models on movie review and 20 Newsgroups data sets.