LSQR, a Lanczos bidiagonalization based Krylov method, and its mathematically
equivalent CGLS applied to normal equations system, are commonly used for
large-scale discrete ill-posed problems. It is well known that LSQR and CGLS
have regularizing effects, where the number of iterations plays the role of the
regularization parameter. However, it has long been unknown whether the
regularizing effects are good enough to find best possible regularized
solutions. Here a best possible regularized solution means that it essentially
has the minimum 2-norm error when standard-form Tikhonov regularization is
used, or from the other perspective, it is at least as accurate as the best
regularized solution obtained by the truncated singular value decomposition
(TSVD) method. In this paper, we establish bounds for the distance between the
$k$-dimensional Krylov subspace and the $k$-dimensional dominant right singular
space. They show that the Krylov subspace captures the dominant right singular
space better for severely and moderately ill-posed problems than for mildly
ill-posed problems. Our general conclusions are that LSQR has better
regularizing effects for the first two kinds of problems than for the third
kind, and a hybrid LSQR with additional regularization, in general, is needed
for mildly ill-posed problems. Exploiting the established bounds, we derive an
estimate for the accuracy of the rank $k$ approximation generated by Lanczos
bidiagonalization. Numerical experiments illustrate that the regularizing
effects of LSQR are good enough to compute best possible regularized solutions
for severely and moderately ill-posed problems, but they are not for mildly
ill-posed problems and additional regularization is needed.