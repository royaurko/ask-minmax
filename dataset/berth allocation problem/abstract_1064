In the rapidly evolving domain of next generation sequencing and
bioinformatics analysis, data generation is one aspect that is increasing at a
concomitant rate. The burden associated with processing large amounts of
sequencing data has emphasised the need to allocate sufficient computing
resources to complete analyses in the shortest possible time with manageable
and predictable costs. A novel method for predicting time to completion for a
popular bioinformatics software (QIIME), was developed using key variables
characteristic of the input data assumed to impact processing time. Multiple
Linear Regression models were developed to determine run time for two denoising
algorithms and a general bioinformatics pipeline. The models were able to
accurately predict clock time for denoising sequences from a naturally
assembled community dataset, but not an artificial community. Speedup and
efficiency tests for AmpliconNoise also highlighted that caution was needed
when allocating resources for parallel processing of data. Accurate modelling
of computational processing time using easily measurable predictors can assist
NGS analysts in determining resource requirements for bioinformatics software
and pipelines. Whilst demonstrated on a specific group of scripts, the
methodology can be extended to encompass other packages running on multiple
architectures, either in parallel or sequentially.