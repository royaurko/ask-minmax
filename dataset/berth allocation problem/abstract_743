Recent advances in topic models have explored complicated structured
distributions to represent topic correlation. For example, the pachinko
allocation model (PAM) captures arbitrary, nested, and possibly sparse
correlations between topics using a directed acyclic graph (DAG). While PAM
provides more flexibility and greater expressive power than previous models
like latent Dirichlet allocation (LDA), it is also more difficult to determine
the appropriate topic structure for a specific dataset. In this paper, we
propose a nonparametric Bayesian prior for PAM based on a variant of the
hierarchical Dirichlet process (HDP). Although the HDP can capture topic
correlations defined by nested data structure, it does not automatically
discover such correlations from unstructured data. By assuming an HDP-based
prior for PAM, we are able to learn both the number of topics and how the
topics are correlated. We evaluate our model on synthetic and real-world text
datasets, and show that nonparametric PAM achieves performance matching the
best of PAM without manually tuning the number of topics.