With the continuous increase of online services as well as energy costs,
energy consumption becomes a significant cost factor for the evaluation of data
center operations. A significant contributor to that is the performance of
database servers which are found to constitute the backbone of online services.
From a software approach, while a set of novel data management technologies
appear in the market e.g. key-value based or in-memory databases, classic
relational database management systems (RDBMS) are still widely used. In
addition from a hardware perspective, the majority of database servers is still
using standard magnetic hard drives (HDDs) instead of solid state drives (SSDs)
due to lower cost of storage per gigabyte, disregarding the performance boost
that might be given due to high cost.
  In this study we focus on a software based assessment of the energy
consumption of a database server by running three different and complete
database workloads namely TCP-H, Star Schema Benchmark -SSB as well a modified
benchmark we have derived for this study called W22. We profile the energy
distribution among the ost important server components and by using different
resource allocation we assess the energy consumption of a typical open source
RDBMS (PostgreSQL) on a standard server in relation with its performance
(measured by query time).
  Results confirm the well-known fact that even for complete workloads,
optimization of the RDBMS results to lower energy consumption.