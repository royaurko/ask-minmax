We introduce a new framework for the convergence analysis of a class of
distributed constrained non-convex optimization algorithms in multi-agent
systems. The aim is to search for local minimizers of a non-convex objective
function which is supposed to be a sum of local utility functions of the
agents. The algorithm under study consists of two steps: a local stochastic
gradient descent at each agent and a gossip step that drives the network of
agents to a consensus. Under the assumption of decreasing stepsize, it is
proved that consensus is asymptotically achieved in the network and that the
algorithm converges to the set of Karush-Kuhn-Tucker points. As an important
feature, the algorithm does not require the double-stochasticity of the gossip
matrices. It is in particular suitable for use in a natural broadcast scenario
for which no feedback messages between agents are required. It is proved that
our result also holds if the number of communications in the network per unit
of time vanishes at moderate speed as time increases, allowing for potential
savings of the network's energy. Applications to power allocation in wireless
ad-hoc networks are discussed. Finally, we provide numerical results which
sustain our claims.