Speech recognition systems are often highly domain dependent, a fact widely
reported in the literature. However the concept of domain is complex and not
bound to clear criteria. Hence it is often not evident if data should be
considered to be out-of-domain. While both acoustic and language models can be
domain specific, work in this paper concentrates on acoustic modelling. We
present a novel method to perform unsupervised discovery of domains using
Latent Dirichlet Allocation (LDA) modelling. Here a set of hidden domains is
assumed to exist in the data, whereby each audio segment can be considered to
be a weighted mixture of domain properties. The classification of audio
segments into domains allows the creation of domain specific acoustic models
for automatic speech recognition. Experiments are conducted on a dataset of
diverse speech data covering speech from radio and TV broadcasts, telephone
conversations, meetings, lectures and read speech, with a joint training set of
60 hours and a test set of 6 hours. Maximum A Posteriori (MAP) adaptation to
LDA based domains was shown to yield relative Word Error Rate (WER)
improvements of up to 16% relative, compared to pooled training, and up to 10%,
compared with models adapted with human-labelled prior domain knowledge.