Traditional methods on video summarization are designed to generate summaries
for single-view video records; and thus they cannot fully exploit the
redundancy in multi-view video records. In this paper, we present a multi-view
metric learning framework for multi-view video summarization that combines the
advantages of maximum margin clustering with the disagreement minimization
criterion. The learning framework thus has the ability to find a metric that
best separates the data, and meanwhile to force the learned metric to maintain
original intrinsic information between data points, for example geometric
information. Facilitated by such a framework, a systematic solution to the
multi-view video summarization problem is developed. To the best of our
knowledge, it is the first time to address multi-view video summarization from
the viewpoint of metric learning. The effectiveness of the proposed method is
demonstrated by experiments.