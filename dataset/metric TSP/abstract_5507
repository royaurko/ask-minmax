The strict minimum message length (SMML) principle links data compression
with inductive inference. The corresponding estimators have many useful
properties but they can be hard to calculate. We investigate SMML estimators
for linear regression models and we show that they have close connections to
hyperbolic geometry. When equipped with the Fisher information metric, the
linear regression model with $p$ covariates and a sample size of $n$ becomes a
Riemannian manifold, and we show that this is isometric to $(p+1)$-dimensional
hyperbolic space $\mathbb{H}^{p+1}$ equipped with a metric tensor which is $2n$
times the usual metric tensor on $\mathbb{H}^{p+1}$. A natural identification
then allows us to also view the set of sufficient statistics for the linear
regression model as a hyperbolic space. We show that the partition of an SMML
estimator corresponds to a tessellation of this hyperbolic space.