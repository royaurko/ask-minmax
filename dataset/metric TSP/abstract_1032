We present a method to generate probability distributions that correspond to
metrics obeying partial differential equations generated by extremizing a
functional $J[g^{\mu\nu}(\theta^i)]$, where $g^{\mu\nu}(\theta^i)$ is the
Fisher metric. We postulate that this functional of the dynamical variable
$g^{\mu\nu}(\theta^i)$ is stationary with respect to small variations of these
variables. Our approach enables a dynamical approach to Fisher information
metric. It allows to impose symmetries on a statistical system in a systematic
way. This work is mainly motivated by the entropy approach to nonmonotonic
reasoning.