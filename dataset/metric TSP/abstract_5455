We extend the recently introduced theory of Lovasz-Bregman (LB) divergences
(Iyer & Bilmes, 2012) in several ways. We show that they represent a distortion
between a 'score' and an 'ordering', thus providing a new view of rank
aggregation and order based clustering with interesting connections to web
ranking. We show how the LB divergences have a number of properties akin to
many permutation based metrics, and in fact have as special cases forms very
similar to the Kendall-$\tau$ metric. We also show how the LB divergences
subsume a number of commonly used ranking measures in information retrieval,
like the NDCG and AUC. Unlike the traditional permutation based metrics,
however, the LB divergence naturally captures a notion of "confidence" in the
orderings, thus providing a new representation to applications involving
aggregating scores as opposed to just orderings. We show how a number of
recently used web ranking models are forms of Lovasz-Bregman rank aggregation
and also observe that a natural form of Mallow's model using the LB divergence
has been used as conditional ranking models for the 'Learning to Rank' problem.