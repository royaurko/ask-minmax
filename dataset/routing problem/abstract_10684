We study the solution of minimax problems $\min_x \max_y G(x) + \langle
K(x),y\rangle - F^*(y)$ in finite-dimensional Hilbert spaces. The functionals
$G$ and $F^*$ we assume to be convex, but the operator $K$ we allow to be
non-linear. We formulate a natural extension of the modified primal-dual hybrid
gradient method (PDHGM), originally for linear $K$, due to Chambolle and Pock.
We prove the local convergence of the method, provided various technical
conditions are satisfied. These include in particular the Aubin property of the
inverse a monotone operator at the solution. Of particular interest to us is
the case arising from reformulation of regularisation problems $\min_x
\|f-T(x)\|^2/2 + \alpha R(x)$ with the operator $T$ non-linear. For such
problems, we show that our general local convergence result holds when the
noise level of the data $f$ is low, and the regularisation parameter $\alpha$
is correspondingly small. We verify the numerical performance of the method by
applying it to problems from magnetic resonance imaging (MRI) in chemical
engineering and medicine. The specific applications are in diffusion tensor
imaging (DTI) and MR velocity imaging. These numerical studies show very
promising performance.