Transductive methods are useful in prediction problems when the training
dataset is composed of a large number of unlabeled observations and a smaller
number of labeled observations. In this paper, we propose an approach for
developing transductive prediction procedures that are able to take advantage
of the sparsity in the high dimensional linear regression. More precisely, we
define transductive versions of the LASSO and the Dantzig Selector . These
procedures combine labeled and unlabeled observations of the training dataset
to produce a prediction for the unlabeled observations. We propose an
experimental study of the transductive estimators, that shows that they improve
the LASSO and Dantzig Selector in many situations, and particularly in high
dimensional problems when the predictors are correlated. We then provide
non-asymptotic theoretical guarantees for these estimation methods.
Interestingly, our theoretical results show that the Transductive LASSO and
Dantzig Selector satisfy sparsity inequalities under weaker assumptions than
those required for the "original" LASSO.