In this paper we propose two types of new algorithms for linear programming.
The first type of these new algorithms uses algebraic methods while the second
type of these new algorithms uses geometric methods. The first type of
algorithms is based on treating the objective function as a parameter. In this
method, we form a matrix using coefficients in the system of equations
consisting objective equation and equations obtained from inequalities defining
constraint by introducing slack/surplus variables. We obtain reduced row
echelon form for this matrix containing only one variable, namely, the
objective function itself as an unknown parameter. We analyse this matrix in
the reduced row echelon form and develop a clear cut method to find the optimal
solution for the problem at hand, if and when it exists. We see that the entire
optimization process can be developed through the proper analysis of the said
matrix in the reduced row echelon form. The second type of algorithms that we
propose for linear programming are inspired by geometrical considerations. All
these algorithms pursue common aim of approaching closer and closer to centroid
or some centrally located interior point for speeding up the process of
reaching an optimal solution! We then proceed to show that the algebraic method
developed above for linear programming naturally extends to non-linear and
integer programming problems. For non-linear and integer programming problems
we use the technique of Grobner bases and the methods of solving linear
Diophantine equations respectively.