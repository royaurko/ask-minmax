We propose a method for pricing American options whose pay-off depends on the
moving average of the underlying asset price. The method uses a finite
dimensional approximation of the infinite-dimensional dynamics of the moving
average process based on a truncated Laguerre series expansion. The resulting
problem is a finite-dimensional optimal stopping problem, which we propose to
solve with a least squares Monte Carlo approach. We analyze the theoretical
convergence rate of our method and present numerical results in the
Black-Scholes framework.