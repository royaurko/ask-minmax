We use a generalization of the Lindeberg principle developed by Sourav
Chatterjee to prove universality properties for various problems in
communications, statistical learning and random matrix theory. We also show
that these systems can be viewed as the limiting case of a properly defined
sparse system. The latter result is useful when the sparse systems are easier
to analyze than their dense counterparts. The list of problems we consider is
by no means exhaustive. We believe that the ideas can be used in many other
problems relevant for information theory.