Although multi-label learning can deal with many problems with label
ambiguity, it does not fit some real applications well where the overall
distribution of the importance of the labels matters. This paper proposes a
novel learning paradigm named \emph{label distribution learning} (LDL) for such
kind of applications. The label distribution covers a certain number of labels,
representing the degree to which each label describes the instance. LDL is a
more general learning framework which includes both single-label and
multi-label learning as its special cases. This paper proposes six working LDL
algorithms in three ways: problem transformation, algorithm adaptation, and
specialized algorithm design. In order to compare their performance, six
evaluation measures are suggested for LDL algorithms, and the first batch of
label distribution datasets are collected and made publicly available.
Experimental results on one artificial and two real-world datasets show clear
advantage of the specialized algorithms, which indicates the importance of
special design for the characteristics of the LDL problem.