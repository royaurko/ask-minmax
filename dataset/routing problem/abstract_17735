We give new sublinear and parallel algorithms for the extensively studied
problem of approximating n-variable r-CSPs (constraint satisfaction problems
with constraints of arity r up to an additive error. The running time of our
algorithms is O(n/\epsilon^2) + 2^O(1/\epsilon^2) for Boolean r-CSPs and O(k^4
n / \epsilon^2) + 2^O(log k / \epsilon^2) for r-CSPs with constraints on
variables over an alphabet of size k. For any constant k this gives optimal
dependence on n in the running time unconditionally, while the exponent in the
dependence on 1/\epsilon is polynomially close to the lower bound under the
exponential-time hypothesis, which is 2^\Omega(\epsilon^(-1/2)).
  For Max-Cut this gives an exponential improvement in dependence on 1/\epsilon
compared to the sublinear algorithms of Goldreich, Goldwasser and Ron (JACM'98)
and a linear speedup in n compared to the algorithms of Mathieu and Schudy
(SODA'08). For the maximization version of k-Correlation Clustering problem our
running time is O(k^4 n / \epsilon^2) + k^O(1/\epsilon^2), improving the
previously best n k^{O(1/\epsilon^3 log k/\epsilon) by Guruswami and Giotis
(SODA'06).