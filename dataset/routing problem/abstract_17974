We propose a primal-dual algorithmic framework for a prototypical constrained
convex minimization problem. The new framework aims to trade-off the
computational difficulty between the primal and the dual subproblems. We
achieve this in our setting by replacing the standard proximal mapping
computations with linear minimization oracles in the primal space, which has
been the hallmark of the scalable Frank-Wolfe-type algorithms. Our analysis
extends Nesterov's universal gradient methods to the primal-dual setting in a
nontrivial fashion, and provides optimal convergence guarantees for the
objective residual as well as the feasibility gap without having to know the
smoothness structures of the problem. As a result, we obtain stronger
primal-dual convergence results than the existing Frank-Wolfe-type algorithms
for important machine learning problems involving sparsity and low-rank, and
also illustrate them numerically.