Propositional representation services such as truth maintenance systems offer
powerful support for incremental, interleaved, problem-model construction and
evaluation. Probabilistic inference systems, in contrast, have lagged behind in
supporting this incrementality typically demanded by problem solvers. The
problem, we argue, is that the basic task of probabilistic inference is
typically formulated at too large a grain-size. We show how a system built
around a smaller grain-size inference task can have the desired incrementality
and serve as the basis for a low-level (propositional) probabilistic
representation service.