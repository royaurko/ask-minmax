In this paper we consider a class of dynamic vehicle routing problems, in
which a number of mobile agents in the plane must visit target points generated
over time by a stochastic process. It is desired to design motion coordination
strategies in order to minimize the expected time between the appearance of a
target point and the time it is visited by one of the agents. We propose
control strategies that, while making minimal or no assumptions on
communications between agents, provide the same level of steady-state
performance achieved by the best known decentralized strategies. In other
words, we demonstrate that inter-agent communication does not improve the
efficiency of such systems, but merely affects the rate of convergence to the
steady state. Furthermore, the proposed strategies do not rely on the knowledge
of the details of the underlying stochastic process. Finally, we show that our
proposed strategies provide an efficient, pure Nash equilibrium in a game
theoretic formulation of the problem, in which each agent's objective is to
maximize the number of targets it visits. Simulation results are presented and
discussed.