In this paper, we develop verifiable and computable performance analysis of
sparsity recovery. We define a family of goodness measures for arbitrary
sensing matrices as a set of optimization problems, and design algorithms with
a theoretical global convergence guarantee to compute these goodness measures.
The proposed algorithms solve a series of second-order cone programs, or linear
programs. As a by-product, we implement an efficient algorithm to verify a
sufficient condition for exact sparsity recovery in the noise-free case. We
derive performance bounds on the recovery errors in terms of these goodness
measures. We also analytically demonstrate that the developed goodness measures
are non-degenerate for a large class of random sensing matrices, as long as the
number of measurements is relatively large. Numerical experiments show that,
compared with the restricted isometry based performance bounds, our error
bounds apply to a wider range of problems and are tighter, when the sparsity
levels of the signals are relatively low.