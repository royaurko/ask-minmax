We focus on one-sided, mixture-based stopping rules for the problem of
sequential testing a simple null hypothesis against a composite alternative.
For the latter, we consider two cases---either a discrete alternative or a
continuous alternative that can be embedded into an exponential family. For
each case, we find a mixture-based stopping rule that is nearly minimax in the
sense of minimizing the maximal Kullback-Leibler information. The proof of this
result is based on finding an almost Bayes rule for an appropriate sequential
decision problem and on high-order asymptotic approximations for the
performance characteristics of arbitrary mixture-based stopping times. We also
evaluate the asymptotic performance loss of certain intuitive mixture rules and
verify the accuracy of our asymptotic approximations with simulation
experiments.