This paper sets out to solve the Sleeping Beauty problem and various related
anthropic (self-locating belief) problems, not through the calculation of
anthropic probabilities, but through finding the correct decision to make.
Given certain simple assumptions, it turns out to be possible to do so without
knowing the underlying anthropic probabilities. Most common anthropic problems
are underspecified from the decision perspective, and this can explain some of
the differing intuitions in the subject: selfless and selfish agents, total and
average utilitarians, will all reach different decisions in the same problem.
These results are formalised into an anthropic decision theory, that is then
used to solve many anthropic problems and paradoxes, such as the Presumptuous
Philosopher, Adam and Eve, and Doomsday problems.