The predictive performance of any inferential model is critical to its
practical success, but quantifying predictive performance is a subtle
statistical problem. In this paper I show how the natural structure of any
inferential problem defines a canonical measure of relative predictive
performance and then demonstrate how approximations of this measure yield many
of the model comparison techniques popular in statistics and machine learning.