Given a selfadjoint, elliptic operator $L$, one would like to know how the
spectrum changes as the spatial domain $\Omega \subset \mathbb{R}^d$ is
deformed. For a family of domains $\{\Omega_t\}_{t\in[a,b]}$ we prove that the
Morse index of $L$ on $\Omega_a$ differs from the Morse index of $L$ on
$\Omega_b$ by the Maslov index of a path of Lagrangian subspaces on the
boundary of $\Omega$. This is particularly useful when $\Omega_a$ is a domain
for which the Morse index is known, e.g. a region with very small volume. Then
the Maslov index computes the difference of Morse indices for the "original"
problem (on $\Omega_b$) and the "simplified" problem (on $\Omega_a$). This
generalizes previous multi-dimensional Morse index theorems that were only
available on star-shaped domains or for Dirichlet boundary conditions. We also
discuss how one can compute the Maslov index using crossing forms, and present
some applications to the spectral theory of Dirichlet and Neumann boundary
value problems.