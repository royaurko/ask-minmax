Sparsity plays a central role in recent developments in signal processing,
linear algebra, statistics, optimization, and other fields. In these
developments, sparsity is promoted through the addition of an $L^1$ norm (or
related quantity) as a constraint or penalty in a variational principle. We
apply this approach to partial differential equations that come from a
variational quantity, either by minimization (to obtain an elliptic PDE) or by
gradient flow (to obtain a parabolic PDE). Also, we show that some PDEs can be
rewritten in an $L^1$ form, such as the divisible sandpile problem and
signum-Gordon. Addition of an $L^1$ term in the variational principle leads to
a modified PDE where a subgradient term appears. It is known that modified PDEs
of this form will often have solutions with compact support, which corresponds
to the discrete solution being sparse. We show that this is advantageous
numerically through the use of efficient algorithms for solving $L^1$ based
problems.