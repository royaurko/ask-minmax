Regularization of ill-posed linear inverse problems via $\ell_1$ penalization
has been proposed for cases where the solution is known to be (almost) sparse.
One way to obtain the minimizer of such an $\ell_1$ penalized functional is via
an iterative soft-thresholding algorithm. We propose an alternative
implementation to $\ell_1$-constraints, using a gradient method, with
projection on $\ell_1$-balls. The corresponding algorithm uses again iterative
soft-thresholding, now with a variable thresholding parameter. We also propose
accelerated versions of this iterative method, using ingredients of the
(linear) steepest descent method. We prove convergence in norm for one of these
projected gradient methods, without and with acceleration.