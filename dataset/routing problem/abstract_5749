We adapt the alternating linearization method for proximal decomposition to
structured regularization problems, in particular, to the generalized lasso
problems. The method is related to two well-known operator splitting methods,
the Douglas--Rachford and the Peaceman--Rachford method, but it has descent
properties with respect to the objective function. This is achieved by
employing a special update test, which decides whether it is beneficial to make
a Peaceman--Rachford step, any of the two possible Douglas--Rachford steps, or
none. The convergence mechanism of the method is related to that of bundle
methods of nonsmooth optimization. We also discuss implementation for very
large problems, with the use of specialized algorithms and sparse data
structures. Finally, we present numerical results for several synthetic and
real-world examples, including a three-dimensional fused lasso problem, which
illustrate the scalability, efficacy, and accuracy of the method.