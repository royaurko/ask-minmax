In this paper we provide theoretical and empirical evidence for a type of
asymmetry between causes and effects that is present when these are related via
linear models contaminated with additive non-Gaussian noise. This asymmetry
consists in the different levels of non-Gaussianity of the residuals of linear
fits between the multivariate random variables in the causal and anti-causal
directions: Under certain conditions, the distribution of the residuals is
closer to a Gaussian distribution when the fit is made in the incorrect
anti-causal direction. The method is closely related to causal inference
techniques based on entropy estimation, extending their range of application to
multivariate and nonlinear problems. The problem of non-linear causal inference
is addressed by performing an embedding in an extended feature space, in which
the relation between causes and effects can be assumed to be linear. In this
extended space the required computations can be efficiently carried out using
kernel techniques. The effectiveness of a method based on this type of
asymmetry is illustrated in a variety of experiments in both synthetic and
real-world cause-effect pairs. In the experiments performed one observes a
Gaussianization of the residuals if the model is fitted in the anti-causal
direction. In the problems investigated the method is competitive with
state-of-the-art techniques for causal inference.