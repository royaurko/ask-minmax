We investigate the utility in employing asymptotic results related to a
clustering criterion to the problem of testing for the presence of jumps in
financial models. We consider the Jump Diffusion model for option pricing and
demonstrate how the testing problem can be reduced to the problem of testing
for the presence of clusters in the increments data. The overarching premise
behind the proposed approach is in the isolation of the increments with
considerably larger mean pertaining to the jumps from the ones which arise from
the diffusion component. Empirical verification is provided via simulations and
the test is applied to financial datasets.