The problem of adaptive noisy clustering is investigated. Given a set of
noisy observations $Z_i=X_i+\epsilon_i$, $i=1,...,n$, the goal is to design
clusters associated with the law of $X_i$'s, with unknown density $f$ with
respect to the Lebesgue measure. Since we observe a corrupted sample, a direct
approach as the popular {\it $k$-means} is not suitable in this case. In this
paper, we propose a noisy $k$-means minimization, which is based on the
$k$-means loss function and a deconvolution estimator of the density $f$. In
particular, this approach suffers from the dependence on a bandwidth involved
in the deconvolution kernel. Fast rates of convergence for the excess risk are
proposed for a particular choice of the bandwidth, which depends on the
smoothness of the density $f$.
  Then, we turn out into the main issue of the paper: the data-driven choice of
the bandwidth. We state an adaptive upper bound for a new selection rule,
called ERC (Empirical Risk Comparison). This selection rule is based on the
Lepski's principle, where empirical risks associated with different bandwidths
are compared. Finally, we illustrate that this adaptive rule can be used in
many statistical problems of $M$-estimation where the empirical risk depends on
a nuisance parameter.