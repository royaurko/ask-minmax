This paper develops a two-layer neural network in which the neuron model
computes a user-defined similarity function between inputs and weights. The
neuron transfer function is formed by composition of an adapted logistic
function with the mean of the partial input-weight similarities. The resulting
neuron model is capable of dealing directly with variables of potentially
different nature (continuous, fuzzy, ordinal, categorical). There is also
provision for missing values. The network is trained using a two-stage
procedure very similar to that used to train a radial basis function (RBF)
neural network. The network is compared to two types of RBF networks in a
non-trivial dataset: the Horse Colic problem, taken as a case study and
analyzed in detail.