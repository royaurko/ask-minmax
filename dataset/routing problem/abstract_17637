Many problems can be formulated as recovering a low-rank tensor. Although an
increasingly common task, tensor recovery remains a challenging problem because
of the delicacy associated with the decomposition of higher order tensors. To
overcome these difficulties, existing approaches often proceed by unfolding
tensors into matrices and then apply techniques for matrix completion. We show
here that such matricization fails to exploit the tensor structure and may lead
to suboptimal procedure. More specifically, we investigate a convex
optimization approach to tensor completion by directly minimizing a tensor
nuclear norm and prove that this leads to an improved sample size requirement.
To establish our results, we develop a series of algebraic and probabilistic
techniques such as characterization of subdifferetial for tensor nuclear norm
and concentration inequalities for tensor martingales, which may be of
independent interests and could be useful in other tensor related problems.