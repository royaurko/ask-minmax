Previously in 2014, we proposed the Nearest Descent (ND) method, capable of
generating an efficient Graph, called the in-tree (IT) structure, This IT
structure has some beautiful and effective advantages, which makes it well
suited for data clustering.
  Subsequently, in order to avoid the seemingly redundant edges in the IT
structure resulted from ND, we proposed another method, called the Nearest
Neighbor Descent (NND), by adding a Neighborhood Graph constraint on ND.
Although the undesired edges between clusters no longer appear, NND proves
still not perfect. Because NND brings with it a new yet worse problem, the
over-partitioning problem.
  Now, in this paper, we proposed a method, called the Hierarchical Nearest
Neighbor Descent (H-NND), which overcomes the over-partitioning problem that
NND faces via using the hierarchical strategy. Specifically, H-NND uses ND to
effectively merge the over-segmented sub-graphs or clusters that NND produces.
Like ND, H-NND also generates an IT structure. This seemingly comes back to the
situation that ND faces. However, the redundant edges in the IT structures
generated by H-NND turn out to be generally more salient than that by ND, and
thus it becomes much easier and more reliable to identify the redundant edges
even simply via taking the edge length as the only measure. We have proven the
power of H-NND on several clustering datasets of varying shapes, dimensions and
attributes.