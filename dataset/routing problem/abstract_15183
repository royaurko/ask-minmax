Recent research indicates that many convex optimization problems with random
constraints exhibit a phase transition as the number of constraints increases.
For example, this phenomenon emerges in the $\ell_1$ minimization method for
identifying a sparse vector from random linear measurements. Indeed, the
$\ell_1$ approach succeeds with high probability when the number of
measurements exceeds a threshold that depends on the sparsity level; otherwise,
it fails with high probability.
  This paper provides the first rigorous analysis that explains why phase
transitions are ubiquitous in random convex optimization problems. It also
describes tools for making reliable predictions about the quantitative aspects
of the transition, including the location and the width of the transition
region. These techniques apply to regularized linear inverse problems with
random measurements, to demixing problems under a random incoherence model, and
also to cone programs with random affine constraints.
  The applied results depend on foundational research in conic geometry. This
paper introduces a summary parameter, called the statistical dimension, that
canonically extends the dimension of a linear subspace to the class of convex
cones. The main technical result demonstrates that the sequence of intrinsic
volumes of a convex cone concentrates sharply around the statistical dimension.
This fact leads to accurate bounds on the probability that a randomly rotated
cone shares a ray with a fixed cone.