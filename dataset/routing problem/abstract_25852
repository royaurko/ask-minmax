There is increasing interest in the problem of nonparametric regression with
high-dimensional predictors. When the number of predictors $D$ is large, one
encounters a daunting problem in attempting to estimate a $D$-dimensional
surface based on limited data. Fortunately, in many applications, the support
of the data is concentrated on a $d$-dimensional subspace with $d \ll D$.
Manifold learning attempts to estimate this subspace. Our focus is on
developing computationally tractable and theoretically supported Bayesian
nonparametric regression methods in this context. When the subspace corresponds
to a locally-Euclidean compact Riemannian manifold, we show that a Gaussian
process regression approach can be applied that leads to the minimax optimal
adaptive rate in estimating the regression function under some conditions. The
proposed model bypasses the need to estimate the manifold, and can be
implemented using standard algorithms for posterior computation in Gaussian
processes. Finite sample performance is illustrated in an example data
analysis.