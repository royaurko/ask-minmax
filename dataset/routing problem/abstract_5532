We address a problem of covariance selection, where we seek a trade-off
between a high likelihood against the number of non-zero elements in the
inverse covariance matrix. We solve a maximum likelihood problem with a penalty
term given by the sum of absolute values of the elements of the inverse
covariance matrix, and allow for imposing bounds on the condition number of the
solution. The problem is directly amenable to now standard interior-point
algorithms for convex optimization, but remains challenging due to its size. We
first give some results on the theoretical computational complexity of the
problem, by showing that a recent methodology for non-smooth convex
optimization due to Nesterov can be applied to this problem, to greatly improve
on the complexity estimate given by interior-point algorithms. We then examine
two practical algorithms aimed at solving large-scale, noisy (hence dense)
instances: one is based on a block-coordinate descent approach, where columns
and rows are updated sequentially, another applies a dual version of Nesterov's
method.