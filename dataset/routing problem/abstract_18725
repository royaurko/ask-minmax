We consider the problems of clustering, classification, and visualization of
high-dimensional data when no straightforward Euclidean representation exists.
Typically, these tasks are performed by first reducing the high-dimensional
data to some lower dimensional Euclidean space, as many manifold learning
methods have been developed for this task. In many practical problems however,
the assumption of a Euclidean manifold cannot be justified. In these cases, a
more appropriate assumption would be that the data lies on a statistical
manifold, or a manifold of probability density functions (PDFs). In this paper
we propose using the properties of information geometry in order to define
similarities between data sets using the Fisher information metric. We will
show this metric can be approximated using entirely non-parametric methods, as
the parameterization of the manifold is generally unknown. Furthermore, by
using multi-dimensional scaling methods, we are able to embed the corresponding
PDFs into a low-dimensional Euclidean space. This not only allows for
classification of the data, but also visualization of the manifold. As a whole,
we refer to our framework as Fisher Information Non-parametric Embedding
(FINE), and illustrate its uses on a variety of practical problems, including
bio-medical applications and document classification.