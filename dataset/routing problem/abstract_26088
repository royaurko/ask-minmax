We present a novel linear program for the approximation of the dynamic
programming cost-to-go function in high-dimensional stochastic control
problems. LP approaches to approximate DP have typically relied on a natural
`projection' of a well studied linear program for exact dynamic programming.
Such programs restrict attention to approximations that are lower bounds to the
optimal cost-to-go function. Our program--the `smoothed approximate linear
program'--is distinct from such approaches and relaxes the restriction to lower
bounding approximations in an appropriate fashion while remaining
computationally tractable. Doing so appears to have several advantages: First,
we demonstrate substantially superior bounds on the quality of approximation to
the optimal cost-to-go function afforded by our approach. Second, experiments
with our approach on a challenging problem (the game of Tetris) show that the
approach outperforms the existing LP approach (which has previously been shown
to be competitive with several ADP algorithms) by an order of magnitude.