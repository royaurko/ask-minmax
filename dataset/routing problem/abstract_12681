We introduce the notion of relevant information loss for the purpose of
casting the signal enhancement problem in information-theoretic terms. We show
that many algorithms from machine learning can be reformulated using relevant
information loss, which allows their application to the aforementioned problem.
As a particular example we analyze principle component analysis for
dimensionality reduction, discuss its optimality, and show that the relevant
information loss can indeed vanish if the relevant information is concentrated
on a lower-dimensional subspace of the input space.