We consider the problem of calibrating a compressed sensing measurement
system under the assumption that the decalibration consists in unknown gains on
each measure. We focus on {\em blind} calibration, using measures performed on
a few unknown (but sparse) signals. A naive formulation of this blind
calibration problem, using $\ell_{1}$ minimization, is reminiscent of blind
source separation and dictionary learning, which are known to be highly
non-convex and riddled with local minima. In the considered context, we show
that in fact this formulation can be exactly expressed as a convex optimization
problem, and can be solved using off-the-shelf algorithms. Numerical
simulations demonstrate the effectiveness of the approach even for highly
uncalibrated measures, when a sufficient number of (unknown, but sparse)
calibrating signals is provided. We observe that the success/failure of the
approach seems to obey sharp phase transitions.