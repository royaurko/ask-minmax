Manifold models provide low-dimensional representations that are useful for
processing and analyzing data in a transformation-invariant way. In this paper,
we study the problem of learning smooth pattern transformation manifolds from
image sets that represent observations of geometrically transformed signals. In
order to construct a manifold, we build a representative pattern whose
transformations accurately fit various input images. We examine two objectives
of the manifold building problem, namely, approximation and classification. For
the approximation problem, we propose a greedy method that constructs a
representative pattern by selecting analytic atoms from a continuous dictionary
manifold. We present a DC (Difference-of-Convex) optimization scheme that is
applicable to a wide range of transformation and dictionary models, and
demonstrate its application to transformation manifolds generated by rotation,
translation and anisotropic scaling of a reference pattern. Then, we generalize
this approach to a setting with multiple transformation manifolds, where each
manifold represents a different class of signals. We present an iterative
multiple manifold building algorithm such that the classification accuracy is
promoted in the learning of the representative patterns. Experimental results
suggest that the proposed methods yield high accuracy in the approximation and
classification of data compared to some reference methods, while the invariance
to geometric transformations is achieved due to the transformation manifold
model.