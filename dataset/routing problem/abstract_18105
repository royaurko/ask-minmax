We consider the problem of estimating the covariance of a collection of
vectors given extremely compressed measurements of each vector. We propose and
study an estimator based on back-projections of these compressive samples. We
show, via a distribution-free analysis, that by observing just a single
compressive measurement of each vector one can consistently estimate the
covariance matrix, in both infinity and spectral norm. Via information
theoretic techniques, we also establish lower bounds showing that our estimator
is minimax-optimal for both infinity and spectral norm estimation problems. Our
results show that the effective sample complexity for this problem is scaled by
a factor of $m^2/d^2$ where $m$ is the compression dimension and $d$ is the
ambient dimension. We mention applications to subspace learning (Principal
Components Analysis) and distributed sensor networks.