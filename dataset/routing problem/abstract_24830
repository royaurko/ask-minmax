The contributors study statistical linear inverse problems in Hilbert spaces.
Approximate solutions are sought within a class of linear one-parameter
regularization schemes, and the parameter choice is crucial to control the root
mean squared error. Here a variant of the Raus{Gfrerer rule is analyzed, and it
is shown that this parameter choice gives rise to error bounds in terms of
oracle inequalities, which in turn provide order optimal error bounds (up to
logarithmic factors). These bounds can only be established for solutions which
obey a certain self-similarity structure. The proof of the main result relies
on some auxiliary error analysis for linear inverse problems under general
noise assumptions, and this may be interesting in its own.