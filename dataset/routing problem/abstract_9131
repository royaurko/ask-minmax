Many problems of theoretical and practical interest involve finding an
optimum over a family of convex functions. For instance, finding the projection
on the convex functions in $H^k(\Omega)$, and optimizing functionals arising
from some problems in economics.
  In the continuous setting and assuming smoothness, the convexity constraints
may be given locally by asking the Hessian matrix to be positive semidefinite,
but in making discrete approximations two difficulties arise: the continuous
solutions may be not smooth, and functions with positive semidefinite discrete
Hessian need not be convex in a discrete sense.
  Previous work has concentrated on non-local descriptions of convexity, making
the number of constraints to grow super-linearly with the number of nodes even
in dimension 2, and these descriptions are very difficult to extend to higher
dimensions.
  In this paper we propose a finite difference approximation using positive
semidefinite programs and discrete Hessians, and prove convergence under very
general conditions, even when the continuous solution is not smooth, working on
any dimension, and requiring a linear number of constraints in the number of
nodes.
  Using semidefinite programming codes, we show concrete examples of
approximations to problems in two and three dimensions.