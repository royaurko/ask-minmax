While previous works on privacy-preserving serial data publishing consider
the scenario where sensitive values may persist over multiple data releases, we
find that no previous work has sufficient protection provided for sensitive
values that can change over time, which should be the more common case. In this
work we propose to study the privacy guarantee for such transient sensitive
values, which we call the global guarantee. We formally define the problem for
achieving this guarantee and derive some theoretical properties for this
problem. We show that the anonymized group sizes used in the data anonymization
is a key factor in protecting individual privacy in serial publication. We
propose two strategies for anonymization targeting at minimizing the average
group size and the maximum group size. Finally, we conduct experiments on a
medical dataset to show that our method is highly efficient and also produces
published data of very high utility.