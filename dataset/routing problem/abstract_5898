In this paper a robust second-order method is developed for the solution of
strongly convex l1-regularized problems. The main aim is to make the proposed
method as inexpensive as possible, while even difficult problems can be
efficiently solved. The proposed approach is a primal-dual Newton Conjugate
Gradients (pdNCG) method. Convergence properties of pdNCG are studied and
worst-case iteration complexity is established. Numerical results are presented
on synthetic sparse least-squares problems and real world machine learning
problems.