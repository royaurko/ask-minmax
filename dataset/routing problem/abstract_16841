Decision theory has become widely accepted in the AI community as a useful
framework for planning and decision making. Applying the framework typically
requires elicitation of some form of probability and utility information. While
much work in AI has focused on providing representations and tools for
elicitation of probabilities, relatively little work has addressed the
elicitation of utility models. This imbalance is not particularly justified
considering that probability models are relatively stable across problem
instances, while utility models may be different for each instance. Spending
large amounts of time on elicitation can be undesirable for interactive systems
used in low-stakes decision making and in time-critical decision making. In
this paper we investigate the issues of reasoning with incomplete utility
models. We identify patterns of problem instances where plans can be proved to
be suboptimal if the (unknown) utility function satisfies certain conditions.
We present an approach to planning and decision making that performs the
utility elicitation incrementally and in a way that is informed by the domain
model.