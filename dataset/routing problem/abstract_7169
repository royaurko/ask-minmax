We present a proximal quasi-Newton method in which the approximation of the
Hessian has the special format of "identity minus rank one" (IMRO) in each
iteration. The proposed structure enables us to effectively recover the
proximal point. The algorithm is applied to $l_1$-regularized least square
problem arising in many applications including sparse recovery in compressive
sensing, machine learning and statistics. Our numerical experiment suggests
that the proposed technique competes favourably with other state-of-the-art
solvers for this class of problems. We also provide a complexity analysis for
variants of IMRO, showing that it matches known best bounds.