We first present an explicit R(D) for the rate-distortion function (RDF) of
the vector Gaussian remote Wyner-Ziv problem with covariance matrix distortion
constraints. To prove the lower bound, we use a particular variant of joint
matrix diagonalization to establish a notion of the minimum of two symmetric
positive-definite matrices. We then show that from the resulting RDF, it is
possible to derive RDFs with different distortion constraints. Specifically, we
rederive the RDF for the vector Gaussian remote Wyner-Ziv problem with the
mean-squared error distortion constraint, and a rate-mutual information
function. This is done by minimizing R(D) subject to appropriate constraints on
the distortion matrix D. The key idea to solve the resulting minimization
problems is to lower-bound them with simpler optimization problems and show
that they lead to identical solutions. We thus illustrate the generality of the
covariance matrix distortion constraint in the Wyner-Ziv setup.