We present a novel statistically-based discretization paradigm and derive a
class of maximum a posteriori (MAP) estimators for solving ill-conditioned
linear inverse problems. We are guided by the theory of sparse stochastic
processes, which specifies continuous-domain signals as solutions of linear
stochastic differential equations. Accordingly, we show that the class of
admissible priors for the discretized version of the signal is confined to the
family of infinitely divisible distributions. Our estimators not only cover the
well-studied methods of Tikhonov and $\ell_1$-type regularizations as
particular cases, but also open the door to a broader class of
sparsity-promoting regularization schemes that are typically nonconvex. We
provide an algorithm that handles the corresponding nonconvex problems and
illustrate the use of our formalism by applying it to deconvolution, MRI, and
X-ray tomographic reconstruction problems. Finally, we compare the performance
of estimators associated with models of increasing sparsity.