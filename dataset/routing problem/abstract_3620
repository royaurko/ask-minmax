Motivated by problems arising in decentralized control problems and
non-cooperative Nash games, we consider a class of strongly monotone Cartesian
variational inequality (VI) problems, where the mappings either contain
expectations or their evaluations are corrupted by error. Such complications
are captured under the umbrella of Cartesian stochastic variational inequality
problems and we consider solving such problems via stochastic approximation
(SA) schemes. Specifically, we propose a scheme wherein the steplength sequence
is derived by a rule that depends on problem parameters such as monotonicity
and Lipschitz constants. The proposed scheme is seen to produce sequences that
are guaranteed to converge almost surely to the unique solution of the problem.
To cope with networked multi-agent generalizations, we provide requirements
under which independently chosen steplength rules still possess desirable
almost-sure convergence properties. In the second part of this paper, we
consider a regime where Lipschitz constants on the map are either unavailable
or difficult to derive. Here, we present a local randomization technique that
allows for deriving an approximation of the original mapping, which is then
shown to be Lipschitz continuous with a prescribed constant. Using this
technique, we introduce a locally randomized SA algorithm and provide
almost-sure convergence theory for the resulting sequence of iterates to an
approximate solution of the original variational inequality problem. Finally,
the paper concludes with some preliminary numerical results on a stochastic
rate allocation problem and a stochastic Nash-Cournot game.