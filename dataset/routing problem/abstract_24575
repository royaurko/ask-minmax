We consider the problem of learning a coefficient vector x_0\in R^N from
noisy linear observation y=Ax_0+w \in R^n. In many contexts (ranging from model
selection to image processing) it is desirable to construct a sparse estimator
x'. In this case, a popular approach consists in solving an L1-penalized least
squares problem known as the LASSO or Basis Pursuit DeNoising (BPDN).
  For sequences of matrices A of increasing dimensions, with independent
gaussian entries, we prove that the normalized risk of the LASSO converges to a
limit, and we obtain an explicit expression for this limit. Our result is the
first rigorous derivation of an explicit formula for the asymptotic mean square
error of the LASSO for random instances. The proof technique is based on the
analysis of AMP, a recently developed efficient algorithm, that is inspired
from graphical models ideas.
  Simulations on real data matrices suggest that our results can be relevant in
a broad array of practical applications.