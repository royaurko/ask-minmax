Markov Chain Monte Carlo (MCMC) algorithms play an important role in
statistical inference problems dealing with intractable probability
distributions. Recently, many MCMC algorithms such as Hamiltonian Monte Carlo
(HMC) and Riemannian Manifold HMC have been proposed to provide distant
proposals with high acceptance rate. These algorithms, however, tend to be
computationally intensive which could limit their usefulness, especially for
big data problems due to repetitive evaluations of functions and statistical
quantities that depend on the data. This issue occurs in many statistic
computing problems. In this paper, we propose a novel strategy that exploits
smoothness (regularity) of parameter space to improve computational efficiency
of MCMC algorithms. When evaluation of functions or statistical quantities are
needed at a point in parameter space, interpolation from precomputed values or
previous computed values is used. More specifically, we focus on Hamiltonian
Monte Carlo (HMC) algorithms that use geometric information for faster
exploration of probability distributions. Our proposed method is based on
precomputing the required geometric information on a set of grids before
running sampling information at nearby grids at each iteration of HMC. Sparse
grid interpolation method is used for high dimensional problems. Tests on
computational examples are shown to illustrate the advantages of our method.