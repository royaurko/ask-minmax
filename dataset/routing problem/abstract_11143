We prove a new extremal inequality, motivated by the vector Gaussian
broadcast channel and the distributed source coding with a single quadratic
distortion constraint problems. As a corollary, this inequality yields a
generalization of the classical entropy-power inequality (EPI). As another
corollary, this inequality sheds insight into maximizing the differential
entropy of the sum of two dependent random variables.