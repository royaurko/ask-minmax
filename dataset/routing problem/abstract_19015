In the present paper we consider Laplace deconvolution for discrete noisy
data observed on the interval whose length may increase with a sample size.
Although this problem arises in a variety of applications, to the best of our
knowledge, it has been given very little attention by the statistical
community. Our objective is to fill this gap and provide statistical treatment
of Laplace deconvolution problem with noisy discrete data. The main
contribution of the paper is explicit construction of an asymptotically
rate-optimal (in the minimax sense) Laplace deconvolution estimator which is
adaptive to the regularity of the unknown function. We show that the original
Laplace deconvolution problem can be reduced to nonparametric estimation of a
regression function and its derivatives on the interval of growing length T_n.
Whereas the forms of the estimators remain standard, the choices of the
parameters and the minimax convergence rates, which are expressed in terms of
T_n^2/n in this case, are affected by the asymptotic growth of the length of
the interval.
  We derive an adaptive kernel estimator of the function of interest, and
establish its asymptotic minimaxity over a range of Sobolev classes. We
illustrate the theory by examples of construction of explicit expressions of
Laplace deconvolution estimators. A simulation study shows that, in addition to
providing asymptotic optimality as the number of observations turns to
infinity, the proposed estimator demonstrates good performance in finite sample
examples.