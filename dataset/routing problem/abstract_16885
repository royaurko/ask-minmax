This article is a continuation of a previous work where we studied infinite
horizon control problems for which the dynamic, running cost and control space
may be different in two half-spaces of some euclidian space $\R^N$. In this
article we extend our results in several directions: $(i)$ to more general
domains; $(ii)$ by considering finite horizon control problems; $(iii)$ by
weaken the controlability assumptions. We use a Bellman approach and our main
results are to identify the right Hamilton-Jacobi-Bellman Equation (and in
particular the right conditions to be put on the interfaces separating the
regions where the dynamic and running cost are different) and to provide the
maximal and minimal solutions, as well as conditions for uniqueness. We also
provide stability results for such equations.