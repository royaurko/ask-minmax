Inverse problems are often ill-posed, with solutions that depend sensitively
on data. In any numerical approach to the solution of such problems,
regularization of some form is needed to counteract the resulting instability.
This paper is based on an approach to regularization, employing a Bayesian
formulation of the problem, which leads to a notion of well-posedness for
inverse problems, at the level of probability measures.
  The stability which results from this well-posedness may be used as the basis
for quantifying the approximation, in finite dimensional spaces, of inverse
problems for functions. This paper contains a theory which utilizes the
stability to estimate the distance between the true and approximate posterior
distributions, in the Hellinger metric, in terms of error estimates for
approximation of the underlying forward problem. This is potentially useful as
it allows for the transfer of estimates from the numerical analysis of forward
problems into estimates for the solution of the related inverse problem. In
particular controlling differences in the Hellinger metric leads to control on
the differences between expected values of polynomially bounded functions and
operators, including the mean and covariance operator.
  The ideas are illustrated with the classical inverse problem for the heat
equation, and then applied to some more complicated non-Gaussian inverse
problems arising in data assimilation, involving determination of the initial
condition for the Stokes or Navier-Stokes equation from Lagrangian and Eulerian
observations respectively.