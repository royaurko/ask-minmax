In this paper, the problem of training optimization for estimating a
multiple-input multiple-output (MIMO) flat fading channel in the presence of
spatially and temporally correlated Gaussian noise is studied in an
application-oriented setup. So far, the problem of MIMO channel estimation has
mostly been treated within the context of minimizing the mean square error
(MSE) of the channel estimate subject to various constraints, such as an upper
bound on the available training energy. We introduce a more general framework
for the task of training sequence design in MIMO systems, which can treat not
only the minimization of channel estimator's MSE, but also the optimization of
a final performance metric of interest related to the use of the channel
estimate in the communication system. First, we show that the proposed
framework can be used to minimize the training energy budget subject to a
quality constraint on the MSE of the channel estimator. A deterministic version
of the "dual" problem is also provided. We then focus on four specific
applications, where the training sequence can be optimized with respect to the
classical channel estimation MSE, a weighted channel estimation MSE and the MSE
of the equalization error due to the use of an equalizer at the receiver or an
appropriate linear precoder at the transmitter. In this way, the intended use
of the channel estimate is explicitly accounted for. The superiority of the
proposed designs over existing methods is demonstrated via numerical
simulations.