Compressed sensing (CS) is an important theory for sub-Nyquist sampling and
recovery of compressible data. Recently, it has been extended by Pham and
Venkatesh to cope with the case where corruption to the CS data is modeled as
impulsive noise. The new formulation, termed as robust CS, combines robust
statistics and CS into a single framework to suppress outliers in the CS
recovery. To solve the newly formulated robust CS problem, Pham and Venkatesh
suggested a scheme that iteratively solves a number of CS problems, the
solutions from which converge to the true robust compressed sensing solution.
However, this scheme is rather inefficient as it has to use existing CS solvers
as a proxy. To overcome limitation with the original robust CS algorithm, we
propose to solve the robust CS problem directly in this paper and drive more
computationally efficient algorithms by following latest advances in
large-scale convex optimization for non-smooth regularization. Furthermore, we
also extend the robust CS formulation to various settings, including additional
affine constraints, $\ell_1$-norm loss function, mixed-norm regularization, and
multi-tasking, so as to further improve robust CS. We also derive simple but
effective algorithms to solve these extensions. We demonstrate that the new
algorithms provide much better computational advantage over the original robust
CS formulation, and effectively solve more sophisticated extensions where the
original methods simply cannot. We demonstrate the usefulness of the extensions
on several CS imaging tasks.