Multiple testing problems arising in modern scientific applications can
involve simultaneously testing thousands or even millions of hypotheses, with
relatively few true signals. In this paper, we consider the multiple testing
problem where prior information is available (for instance, from an earlier
study under different experimental conditions), that can allow us to test the
hypotheses as a ranked list in order to increase the number of discoveries.
Given an ordered list of n hypotheses, the aim is to select a data-dependent
cutoff k and declare the first k hypotheses to be statistically significant
while bounding the false discovery rate (FDR). Generalizing several existing
methods, we develop a family of "accumulation tests" to choose a cutoff k that
adapts to the amount of signal at the top of the ranked list. We introduce a
new method in this family, the HingeExp method, which offers higher power to
detect true signals compared to existing techniques. Our theoretical results
prove that these methods control a modified FDR on finite samples, and
characterize the power of the methods in the family. We apply the tests to
simulated data, including a high-dimensional model selection problem for linear
regression. We also compare accumulation tests to existing methods for multiple
testing on a real data problem of identifying differential gene expression over
a dosage gradient.