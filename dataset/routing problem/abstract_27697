Convolutional neural networks (CNNs) perform well on problems such as
handwriting recognition and image classification. However, the performance of
the networks is often limited by budget and time constraints, particularly when
trying to train deep networks.
  Motivated by the problem of online handwriting recognition, we developed a
CNN for processing spatially-sparse inputs; a character drawn with a one-pixel
wide pen on a high resolution grid looks like a sparse matrix. Taking advantage
of the sparsity allowed us more efficiently to train and test large, deep CNNs.
On the CASIA-OLHWDB1.1 dataset containing 3755 character classes we get a test
error of 3.82%.
  Although pictures are not sparse, they can be thought of as sparse by adding
padding. Applying a deep convolutional network using sparsity has resulted in a
substantial reduction in test error on the CIFAR small picture datasets: 6.28%
on CIFAR-10 and 24.30% for CIFAR-100.