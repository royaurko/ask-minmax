The statistical mechanics of Gibbs is a juxtaposition of subjective,
probabilistic ideas on the one hand and objective, mechanical ideas on the
other. In this paper, we follow the path set out by Jaynes, including elements
added subsequently to that original work, to explore the consequences of the
purely statistical point of view. We show how standard methods in the
equilibrium theory could have been derived simply from a description of the
available problem information. In addition, our presentation leads to novel
insights into questions associated with symmetry and non-equilibrium
statistical mechanics. Two surprising consequences to be explored in further
work are that (in)distinguishability factors are automatically predicted from
the problem formulation and that a quantity related to the thermodynamic
entropy production is found by considering information loss in non-equilibrium
processes. Using the problem of ion channel thermodynamics as an example, we
illustrate the idea of building up complexity by successively adding
information to create progressively more complex descriptions of a physical
system. Our result is that such statistical mechanical descriptions can be used
to create transparent, computable, experimentally-relevant models that may be
informed by more detailed atomistic simulations. We also derive a theory for
the kinetic behavior of this system, identifying the nonequilibrium `process'
free energy functional. The Gibbs relation for this functional is a
fluctuation-dissipation theorem applicable arbitrarily far from equilibrium,
that captures the effect of non-local and time-dependent behavior from
transient driving forces. Based on this work, it is clear that statistical
mechanics is a general tool for constructing the relationships between
constraints on system information.