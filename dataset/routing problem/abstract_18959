This paper discusses the problem of adaptive estimation of a univariate
object like the value of a regression function at a given point or a linear
functional in a linear inverse problem. We consider an adaptive procedure
originated from Lepski [Theory Probab. Appl. 35 (1990) 454--466.] that selects
in a data-driven way one estimate out of a given class of estimates ordered by
their variability. A serious problem with using this and similar procedures is
the choice of some tuning parameters like thresholds. Numerical results show
that the theoretically recommended proposals appear to be too conservative and
lead to a strong oversmoothing effect. A careful choice of the parameters of
the procedure is extremely important for getting the reasonable quality of
estimation. The main contribution of this paper is the new approach for
choosing the parameters of the procedure by providing the prescribed behavior
of the resulting estimate in the simple parametric situation. We establish a
non-asymptotical "oracle" bound, which shows that the estimation risk is, up to
a logarithmic multiplier, equal to the risk of the "oracle" estimate that is
optimally selected from the given family. A numerical study demonstrates a good
performance of the resulting procedure in a number of simulated examples.