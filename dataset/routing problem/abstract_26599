A primary motivation for reasoning under uncertainty is to derive decisions
in the face of inconclusive evidence. However, Shafer's theory of belief
functions, which explicitly represents the underconstrained nature of many
reasoning problems, lacks a formal procedure for making decisions. Clearly,
when sufficient information is not available, no theory can prescribe actions
without making additional assumptions. Faced with this situation, some
assumption must be made if a clearly superior choice is to emerge. In this
paper we offer a probabilistic interpretation of a simple assumption that
disambiguates decision problems represented with belief functions. We prove
that it yields expected values identical to those obtained by a probabilistic
analysis that makes the same assumption. In addition, we show how the decision
analysis methodology frequently employed in probabilistic reasoning can be
extended for use with belief functions.