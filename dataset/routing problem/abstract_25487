A well-known problem in computing some matrix functions iteratively is the
lack of a clear, commonly accepted residual notion. An important matrix
function for which this is the case is the matrix exponential. Suppose the
matrix exponential of a given matrix times a given vector has to be computed.
We develop the approach of Druskin, Greenbaum and Knizhnerman (1998) and
interpret the sought-after vector as the value of a vector function satisfying
the linear system of ordinary differential equations (ODE) whose coefficients
form the given matrix. The residual is then defined with respect to the
initial-value problem for this ODE system. The residual introduced in this way
can be seen as a backward error. We show how the residual can be computed
efficiently within several iterative methods for the matrix exponential. This
completely resolves the question of reliable stopping criteria for these
methods. Further, we show that the residual concept can be used to construct
new residual-based iterative methods. In particular, a variant of the
Richardson method for the new residual appears to provide an efficient way to
restart Krylov subspace methods for evaluating the matrix exponential.