The alternating direction method with multipliers (ADMM) has been one of most
powerful and successful methods for solving various convex or nonconvex
composite problems that arise in the fields of image & signal processing and
machine learning. In convex settings, numerous convergence results have been
established for ADMM as well as its varieties. However, due to the absence of
convexity, the convergence analysis of nonconvex ADMM is generally very
difficult. In this paper we study the Bregman modification of ADMM (BADMM),
which includes the conventional ADMM as a special case and often leads to an
improvement of the performance of the algorithm. Under certain assumptions, we
prove that the iterative sequence generated by BADMM converges to a stationary
point of the associated augmented Lagrangian function. The obtained results
underline the feasibility of ADMM in applications under nonconvex settings.