It is increasingly common to encounter time-varying random fields on networks
(metabolic networks, sensor arrays, distributed computing, etc.). This paper
considers the problem of optimal, nonlinear prediction of these fields, showing
from an information-theoretic perspective that it is formally identical to the
problem of finding minimal local sufficient statistics. I derive general
properties of these statistics, show that they can be composed into global
predictors, and explore their recursive estimation properties. For the special
case of discrete-valued fields, I describe a convergent algorithm to identify
the local predictors from empirical data, with minimal prior information about
the field, and no distributional assumptions.