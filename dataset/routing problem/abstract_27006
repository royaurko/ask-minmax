The problem of transformation selection is thoroughly treated from a Bayesian
perspective. Several families of transformations are considered with a view to
achieving normality: the Box-Cox, the Modulus, the Yeo & Johnson and the Dual
transformation. Markov chain Monte Carlo algorithms have been constructed in
order to sample from the posterior distribution of the transformation parameter
$\lambda_T$ associated with each competing family $T$. We investigate different
approaches to constructing compatible prior distributions for $\lambda_T$ over
alternative transformation families, using a unit-information power-prior
approach and an alternative normal prior with approximate unit-information
interpretation. Selection and discrimination between different transformation
families is attained via posterior model probabilities. We demonstrate the
efficiency of our approach using a variety of simulated datasets. Although
there is no choice of transformation family that can be universally applied to
all problems, empirical evidence suggests that some particular data structures
are best treated by specific transformation families. For example, skewness is
associated with the Box-Cox family while fat-tailed distributions are
efficiently treated using the Modulus transformation.