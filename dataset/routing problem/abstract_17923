We extensively compare, qualitatively and quantitatively, 40 state-of-the-art
models (28 salient object detection, 10 fixation prediction, 1 objectness, and
1 baseline) over 6 challenging datasets for the purpose of benchmarking salient
object detection and segmentation methods. From the results obtained so far,
our evaluation shows a consistent rapid progress over the last few years in
terms of both accuracy and running time. The top contenders in this benchmark
significantly outperform the models identified as the best in the previous
benchmark conducted just two years ago. We find that the models designed
specifically for salient object detection generally work better than models in
closely related areas, which in turn provides a precise definition and suggests
an appropriate treatment of this problem that distinguishes it from other
problems. In particular, we analyze the influences of center bias and scene
complexity in model performance, which, along with the hard cases for
state-of-the-art models, provide useful hints towards constructing more
challenging large scale datasets and better saliency models. Finally, we
propose probable solutions for tackling several open problems such as
evaluation scores and dataset bias, which also suggest future research
directions in the rapidly-growing field of salient object detection.