The problem how to determine the intrinsic quality of a signal processing
system with respect to the inference of an unknown deterministic parameter
$\theta$ is considered. While Fisher's information measure $F(\theta)$ forms a
classical analytical tool for such a problem, direct computation of the
information measure can become difficult in certain situations. This in
particular forms an obstacle for the estimation theoretic performance analysis
of non-linear measurement systems, where the form of the conditional output
probability function can make calculation of the information measure
$F(\theta)$ difficult. Based on the Cauchy-Schwarz inequality, we establish an
alternative information measure $S(\theta)$. It forms a pessimistic
approximation to the Fisher information $F(\theta)$ and has the property that
it can be evaluated with the first four output moments at hand. These entities
usually exhibit good mathematical tractability or can be determined at
low-complexity by output measurements in a calibrated setup or via numerical
simulations. With various examples we show that $S(\theta)$ provides a good
conservative approximation for $F(\theta)$ and outline different estimation
theoretic problems where the presented information bound turns out to be
useful.