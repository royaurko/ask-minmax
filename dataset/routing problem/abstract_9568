Recognition is the fundamental task of visual cognition, yet how to formalize
the general recognition problem for computer vision remains an open issue. The
problem is sometimes reduced to the simplest case of recognizing matching
pairs, often structured to allow for metric constraints. However, visual
recognition is broader than just pair matching -- especially when we consider
multi-class training data and large sets of features in a learning context.
What we learn and how we learn it has important implications for effective
algorithms. In this paper, we reconsider the assumption of recognition as a
pair matching test, and introduce a new formal definition that captures the
broader context of the problem. Through a meta-analysis and an experimental
assessment of the top algorithms on popular data sets, we gain a sense of how
often metric properties are violated by good recognition algorithms. By
studying these violations, useful insights come to light: we make the case that
locally metric algorithms should leverage outside information to solve the
general recognition problem.