We consider the problem of optimal recovery of an element $u$ of a Hilbert
space $\mathcal{H}$ from $m$ measurements obtained through known linear
functionals on $\mathcal{H}$. Problems of this type are well studied \cite{MRW}
under an assumption that $u$ belongs to a prescribed model class, e.g. a known
compact subset of $\mathcal{H}$. Motivated by reduced modeling for parametric
partial differential equations, this paper considers another setting where the
additional information about $u$ is in the form of how well $u$ can be
approximated by a certain known subspace $V_n$ of $\mathcal{H}$ of dimension
$n$, or more generally, how well $u$ can be approximated by each
$k$-dimensional subspace $V_k$ of a sequence of nested subspaces $V_0\subset
V_1\cdots\subset V_n$. A recovery algorithm for the one-space formulation,
proposed in \cite{MPPY}, is proven here to be optimal and to have a simple
formulation, if certain favorable bases are chosen to represent $V_n$ and the
measurements. The major contribution of the present paper is to analyze the
multi-space case for which it is shown that the set of all $u$ satisfying the
given information can be described as the intersection of a family of known
ellipsoids in $\mathcal{H}$. It follows that a near optimal recovery algorithm
in the multi-space problem is to identify any point in this intersection which
can provide a much better accuracy than in the one-space problem. Two iterative
algorithms based on alternating projections are proposed for recovery in the
multi-space problem. A detailed analysis of one of them provides a posteriori
performance estimates for the iterates, stopping criteria, and convergence
rates. Since the limit of the algorithm is a point in the intersection of the
aforementioned ellipsoids, it provides a near optimal recovery for $u$.