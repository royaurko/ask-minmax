We derive the equations governing the protocols minimizing the heat released
by a continuous-time Markov jump process on a one-dimensional countable state
space during a transition between assigned initial and final probability
distributions in a finite time horizon. In particular, we identify the
hypotheses on the transition rates under which the optimal control strategy and
the probability distribution of the Markov jump problem obey a system of
differential equations of Hamilton-Bellman-Jacobi-type. As the state-space mesh
tends to zero, these equations converge to those satisfied by the diffusion
process minimizing the heat released in the Langevin formulation of the same
problem. We also show that in full analogy with the continuum case, heat
minimization is equivalent to entropy production minimization. Thus, our
results may be interpreted as a refined version of the second law of
thermodynamics.