Many popular statistical models for complex phenomena are intractable, in the
sense that the likelihood function cannot easily be evaluated. Bayesian
estimation in this setting remains challenging, with a lack of computational
methodology to fully exploit modern processing capabilities. In this paper we
introduce novel control variates for intractable likelihoods that can
dramatically reduce the Monte Carlo variance of Bayesian estimators. We prove
that our control variates are well-defined and provide a positive variance
reduction. Furthermore we show how to optimise these control variates for
variance reduction. The methodology is highly parallel and offers a route to
exploit multi-core processing architectures that complements recent research in
this direction. Indeed, our work shows that it may not be necessary to
parallelise the sampling process itself in order to harness the potential of
massively multi-core architectures. Simulation results presented on the Ising
model, exponential random graph models and non-linear stochastic differential
equation models support our theoretical findings.