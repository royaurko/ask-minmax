In this paper we deal with the problem of chromaticity, i.e. apparent
position variation of stellar images with their spectral distribution, using
neural networks to analyse and process astronomical images. The goal is to
remove this relevant source of systematic error in the data reduction of high
precision astrometric experiments, like Gaia. This task can be accomplished
thanks to the capability of neural networks to solve a nonlinear approximation
problem, i.e. to construct an hypersurface that approximates a given set of
scattered data couples. Images are encoded associating each of them with
conveniently chosen moments, evaluated along the y axis. The technique
proposed, in the current framework, reduces the initial chromaticity of few
milliarcseconds to values of few microarcseconds.