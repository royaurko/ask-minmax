Let $X|\mu\sim N_p(\mu,v_xI)$ and $Y|\mu\sim N_p(\mu,v_yI)$ be independent
$p$-dimensional multivariate normal vectors with common unknown mean $\mu$.
Based on observing $X=x$, we consider the problem of estimating the true
predictive density $p(y|\mu)$ of $Y$ under expected Kullback--Leibler loss. Our
focus here is the characterization of admissible procedures for this problem.
We show that the class of all generalized Bayes rules is a complete class, and
that the easily interpretable conditions of Brown and Hwang [Statistical
Decision Theory and Related Topics (1982) III 205--230] are sufficient for a
formal Bayes rule to be admissible.