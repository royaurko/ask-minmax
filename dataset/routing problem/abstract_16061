For decades, researchers have been applying computer simulation to address
problems in biology. However, many of these "grand challenges" in computational
biology, such as simulating how proteins fold, remained unsolved due to their
great complexity. Indeed, even to simulate the fastest folding protein would
require decades on the fastest modern CPUs. Here, we review novel methods to
fundamentally speed such previously intractable problems using a new
computational paradigm: distributed computing. By efficiently harnessing tens
of thousands of computers throughout the world, we have been able to break
previous computational barriers. However, distributed computing brings new
challenges, such as how to efficiently divide a complex calculation of many PCs
that are connected by relatively slow networking. Moreover, even if the
challenge of accurately reproducing reality can be conquered, a new challenge
emerges: how can we take the results of these simulations (typically tens to
hundreds of gigabytes of raw data) and gain some insight into the questions at
hand. This challenge of the analysis of the sea of data resulting from
large-scale simulation will likely remain for decades to come.