Some risks have extremely high stakes. For example, a worldwide pandemic or
asteroid impact could potentially kill more than a billion people.
Comfortingly, scientific calculations often put very low probabilities on the
occurrence of such catastrophes. In this paper, we argue that there are
important new methodological problems which arise when assessing global
catastrophic risks and we focus on a problem regarding probability estimation.
When an expert provides a calculation of the probability of an outcome, they
are really providing the probability of the outcome occurring, given that their
argument is watertight. However, their argument may fail for a number of
reasons such as a flaw in the underlying theory, a flaw in the modeling of the
problem, or a mistake in the calculations. If the probability estimate given by
an argument is dwarfed by the chance that the argument itself is flawed, then
the estimate is suspect. We develop this idea formally, explaining how it
differs from the related distinctions of model and parameter uncertainty. Using
the risk estimates from the Large Hadron Collider as a test case, we show how
serious the problem can be when it comes to catastrophic risks and how best to
address it.