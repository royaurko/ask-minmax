Over the last decade computer simulations have had an increasing role in
shedding light on difficult statistical physical phenomena and in particular on
the ubiquitous problem of the glass transition. Here in a wide variety of
materials the viscosity of a super-cooled liquid increases by many orders of
magnitude upon decreasing the temperature over a modest range. A natural
concern in these computer simulation is the very small size of the simulated
systems compared to experimental ones, raising the issue of how to assess the
thermodynamic limit. Here we offer a theory for the glass transition based on
finite size scaling, a method that was found very useful in the context of
critical phenomena and other interesting problems. As is known, the
construction of such a theory rests crucially on the existence of a growing
{\em static} length scale upon decreasing the temperature. We demonstrate that
the static length scale that was discovered in Ref. \cite{12KLP} fits the bill
extremely well, allowing us to provide a finite size scaling theory for the
$\alpha$ relaxation time of the glass transition, including predictions for the
thermodynamic limit based on simulations in small systems.