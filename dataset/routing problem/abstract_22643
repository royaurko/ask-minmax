In this thesis, a Bayes linear methodology for the adjustment of covariance
matrices is presented and discussed. A geometric framework for quantifying
uncertainties about covariance matrices is set up, and an inner-product for
spaces of random matrices is motivated and constructed. The inner-product on
this space captures aspects of our beliefs about the relationship between
covariance matrices of interest to us, providing a structure rich enough for us
to adjust beliefs about unknown matrices in the light of data such as sample
covariance matrices, exploiting second-order exchangeability and related
specifications to obtain representations allowing analysis.
  Adjustment is associated with orthogonal projection, and illustrated with
examples of adjustments for some common problems. The problem of adjusting
the covariance matrices underlying exchangeable random vectors is tackled
and discussed. Learning about the covariance matrices associated with
multivariate time series dynamic linear models is shown to be amenable to a
similar approach. Diagnostics for matrix adjustments are also discussed.