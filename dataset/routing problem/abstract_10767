The problem of solving a system of polynomial equations is one of the most
fundamental problems in applied mathematics. Among them, the problem of solving
a system of binomial equations form a important subclass for which specialized
techniques exist. For both theoretic and applied purposes, the degree of the
solution set of a system of binomial equations often plays an important role in
understanding the geometric structure of the solution set. Its computation,
however, is computationally intensive. This paper proposes a specialized
parallel algorithm for computing the degree on GPUs that takes advantage of the
massively parallel nature of GPU devices. The preliminary implementation shows
remarkable efficiency and scalability when compared to the closest CPU-based
counterpart. Applied to the "master space problem of $\mathcal{N}=1$ gauge
theories" the GPU-based implementation achieves nearly 30 fold speedup over its
CPU-only counterpart enabling the discovery of previously unknown results.
Equally important to note is the far superior scalability: with merely 3 GPU
devices on a single workstation, the GPU-based implementation shows better
performance, on certain problems, than a small cluster totaling 100 CPU cores.