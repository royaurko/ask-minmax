The `Signal plus Noise' model for nonparametric regression can be extended to
the case of observations taken at the vertices of a graph. This model includes
many familiar regression problems. This article discusses the use of the edges
of a graph to measure roughness in penalized regression. Distance between
estimate and observation is measured at every vertex in the $L_2$ norm, and
roughness is penalized on every edge in the $L_1$ norm. Thus the ideas of
total-variation penalization can be extended to a graph. The resulting
minimization problem presents special computational challenges, so we describe
a new, fast algorithm and demonstrate its use with examples.
  Further examples include a graphical approach that gives an improved estimate
of the baseline in spectroscopic analysis, and a simulation applicable to
discrete spatial variation. In our example, penalized regression outperforms
kernel smoothing in terms of identifying local extreme values. In all examples
we use fully automatic procedures for setting the smoothing parameters.