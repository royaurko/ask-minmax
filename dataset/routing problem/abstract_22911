One of the main questions concerning learning in Multi-Agent Systems is:
(How) can agents benefit from mutual interaction during the learning process?.
This paper describes the study of an interactive advice-exchange mechanism as a
possible way to improve agents' learning performance. The advice-exchange
technique, discussed here, uses supervised learning (backpropagation), where
reinforcement is not directly coming from the environment but is based on
advice given by peers with better performance score (higher confidence), to
enhance the performance of a heterogeneous group of Learning Agents (LAs). The
LAs are facing similar problems, in an environment where only reinforcement
information is available. Each LA applies a different, well known, learning
technique: Random Walk (hill-climbing), Simulated Annealing, Evolutionary
Algorithms and Q-Learning. The problem used for evaluation is a simplified
traffic-control simulation. Initial results indicate that advice-exchange can
improve learning speed, although bad advice and/or blind reliance can disturb
the learning performance.