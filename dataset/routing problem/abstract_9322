Knowledge Representation is important issue in reinforcement learning. In
this paper, we bridge the gap between reinforcement learning and knowledge
representation, by providing a rich knowledge representation framework, based
on normal logic programs with answer set semantics, that is capable of solving
model-free reinforcement learning problems for more complex do-mains and
exploits the domain-specific knowledge. We prove the correctness of our
approach. We show that the complexity of finding an offline and online policy
for a model-free reinforcement learning problem in our approach is NP-complete.
Moreover, we show that any model-free reinforcement learning problem in MDP
environment can be encoded as a SAT problem. The importance of that is
model-free reinforcement