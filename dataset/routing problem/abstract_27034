The success of compressed sensing relies essentially on the ability to
efficiently find an approximately sparse solution to an under-determined linear
system. In this paper, we developed an efficient algorithm for the sparsity
promoting $\ell_1$-regularized least squares problem by coupling the primal
dual active set strategy with a continuation technique (on the regularization
parameter). In the active set strategy, we first determine the active set from
primal and dual variables, and then update the primal and dual variables by
solving a low-dimensional least square problem on the active set, which makes
the algorithm very efficient. The continuation technique globalizes the
convergence of the algorithm, with provable global convergence under restricted
isometry property (RIP). Further, we adopt two alternative methods, i.e., a
modified discrepancy principle and a Bayesian information criterion, to choose
the regularization parameter. Numerical experiments indicate that our algorithm
is very competitive with state-of-the-art algorithms in terms of accuracy and
efficiency.