Password: This paper examines the feasibility of using genetic algorithms augmented with a long term memory to attack similar traveling salesman problems. The proposed learning system combines a genetic problem solver with a case-base or data-base of past problem solving attempts to increase performance with experience. Instead of starting from scratch, we retrieve and inject the solutions of previously solved similar problems into the initial population of the genetic algorithm to provide a performance boost. In this paper we are more concerned with relative improvement in performance over time rather than with absolute performance and our results on a number of problems indicate that we can always get better performance with the combined system. If, as we believe, the results are generalizable, combining a case-base with a genetic algorithm will benefit most purely genetic algorithm implementations. 1. Introduction and background Learning requires memory; a place for storing past experiences to guide future operations. The storage area may be distributed or localized, but a system without a memory is forced to start from scratch in trying to solve every given problem. Genetic algorithms (GAs) are randomized parallel search algorithms that search from a population of points [6]  and  [9] . Current genetic algorithm based machine learning systems use rules to store past experience to improve their performance over time [6] , [8] , [9] , [11]  and  [25] . However, many application areas, especially in the design and optimization domain, are more suited to a case-based storage of past experience [4] , [10] , [19]  and  [27] . We propose and describe initial steps towards constructing a system that uses a case-base as a long term knowledge store in a new genetic algorithm based machine learning system. In this paper we show that our system improves relative performance on traveling salesman problems. Typically, a genetic algorithm randomly initializes its starting population so that the GA can proceed from an unbiased sample of the search space. However, problems do not usually exist in isolation and we often confront sets of similar problems. It makes little sense to start a problem solving search attempt from scratch when previous search attempts may have yielded useful information about the search space. Instead, initializing a genetic algorithm's population with relevant solutions or partial solutions to similar previously solved problems can provide information (a search bias) that reduces the time taken to find a quality solution. Our approach borrows ideas from case-based reasoning (CBR) in which old problem and solution information, stored as cases in a case-base, helps solve a new problem [23] . In our system, the data-base, or case-base, of problems and their solutions supplies the genetic problem solver with a long term memory. The system does not require a case-base to start with and can bootstrap itself by learning new cases from the genetic algorithm's attempts at solving a problem. Fig. 1 shows a conceptual view of a simple version of our system. When confronted with a problem, the CBR module looks in its case-base for similar problems and their associated solutions. If any similar problems are found a small number of their solutions are injected into the initial population of the genetic algorithm. The rest of the population is initialized randomly to maintain diversity, and the GA searches from this combined population. Fig. 1.  Conceptual view of our system. The case-base does what it is best at – memory organization; the genetic algorithm handles what it is best at – adaptation. The genetic algorithm also provides a ready-made case generating mechanism as the individuals generated during a GA search can be thought of as cases or as parts of cases. CBR systems usually have difficulty in finding enough cases; our problem is the opposite. We need to sift through a large number of cases to find potential seeds for the initial population. A genetic algorithm explores a subset of the search space during a problem solving attempt and its population serves as an implicit memory guiding the search. Every individual generated during a search defines a point in the search space and the individual's evaluation provides a fitness. This information when stored, organized, and analyzed can be used to explain the solution, that is, tell which parts of the genotype are important, and allow a sensitivity analysis [17] . However, this information is usually discarded at the end of a GA's run and the resources spent in gaining this information are wasted. If we store this information in an explicit memory and use (or re-use) it in a subsequent problem solving attempt on a related problem we can tune the GA to a particular space and thus increase performance in this space assuming that problem similarity implies solution similarity . In case this assumption is false or we are unable to find solutions to similar problems the system need not fail – we are simply back to randomly initializing the population. Note that we are interested in showing that the system learns, that is, it improves performance over time and we only use the TSP as an example problem domain. We do not do any special tuning to the genetic algorithm solving the TSP and simply use techniques described in the literature for attacking the problem. One early attempt at reuse can be found in Ackley's work with SIGH [1] . Ackley periodically restarts a search in an attempt to avoid local optima and increase the quality of solutions. Eshelman's CHC algorithm, a genetic algorithm with elitist selection and cataclysmic mutation, also restarts search when the population diversity drops below a threshold [3] . Other related work includes Koza's automatically defined functions [13] and Schoenauer's constraint satisfaction method [24] . These approaches only attack a single problem not a related class of problems. More recently, Ramsey and Grefenstette come closest to our approach and use previously stored solutions to initialize a genetic algorithm's initial population and thus increase a genetic algorithm's performance in an anytime learning environment that changes with time [21] . Automatic injection of the best solutions to previously encountered problems biases the search toward relevant areas of the search space and results in the reported consistent performance improvements. To our knowledge, the earliest work in combining genetic algorithms and case-based reasoning was done by Louis et al. [17] who used case-based reasoning principles to explain solutions found by genetic algorithm search. Louis and Johnson later addressed the issues of which and how many cases to inject into the population. The work reported in their paper shows that injecting the best solutions to previously solved problems does not always lead to better performance and provides a possible explanation of this result [15]  and  [16] . In this paper, we apply our methodology to the TSP and show that performance improves even when problems of different sizes are used. 1.1. Traveling salesman problem The definition of a traveling salesman problem (TSP) is: given N cities, if a salesman starting from his home city is to visit each city exactly once and then return home, find the order of a tour such that the total distance traveled is minimum. The TSP is a classical NP-complete problem which has extremely large search spaces and is very difficult to solve. People have tried to use both exact and heuristic or probabilistic methods to solve the TSP. Exact methods, like cutting planes, branch and bound [20] , can only optimally solve small sized problems while the heuristic or probabilistic methods, like 2-opt [14] , Markov chain [18] and simulated annealing [12] are good for large sized problems. A genetic algorithm can also be used to solve large TSPs and can get good solutions quickly. The first efforts to find near optimal solutions to TSPs by using GAs are those of Goldberg using partial mapped crossover [5] and Grefenstette using greedy crossover [7] . Davis [2] , Smith [25] , and Suh and Van Gucht [26] also tried to solve TSPs with various crossover operators. In this paper, we present evidence to show that the performance of a genetic algorithm injected with solutions to previously solved similar traveling salesman problems is better than that of running a genetic algorithm with randomly initialized individuals. In the next few sections, we describe genetic algorithms, how we modify a genetic algorithm to solve TSPs, our methodology, results, and conclusions.