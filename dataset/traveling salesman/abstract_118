Password: We describe an artificial ant colony capable of solving the travelling salesman problem (TSP). Ants of the artificial colony are able to generate successively shorter feasible tours by using information accumulated in the form of a pheromone trail deposited on the edges of the TSP graph. Computer simulations demonstrate that the artificial ant colony is capable of generating good solutions to both symmetric and asymmetric instances of the TSP. The method is an example, like simulated annealing, neural networks and evolutionary computation, of the successful use of a natural metaphor to design an optimization algorithm. Keywords Ant colony optimization ; Computational intelligence ; Artificial life ; Adaptive behavior ; Combinatorial optimization ; Reinforcement learning 1. Introduction Real ants are capable of finding the shortest path from a food source to the nest ( Beckers et al., 1992 ; Goss et al., 1989 ) without using visual cues ( Hölldobler and Wilson, 1990 ). Also, they are capable of adapting to changes in the environment, e.g. finding a new shortest path once the old one is no longer feasible due to a new obstacle ( Beckers et al., 1992 ; Goss et al., 1989 ). Consider Fig. 1 A: ants are moving on a straight line that connects a food source to their nest. It is well known that the primary means for ants to form and maintain the line is a pheromone trail. Ants deposit a certain amount of pheromone while walking, and each ant probabilistically prefers to follow a direction rich in pheromone. This elementary behaviour of real ants can be used to explain how they can find the shortest path that reconnects a broken line after the sudden appearance of an unexpected obstacle has interrupted the initial path ( Fig. 1 B). In fact, once the obstacle has appeared, those ants which are just in front of the obstacle cannot continue to follow the pheromone trail and therefore they have to choose between turning right or left. In this situation we can expect half the ants to choose to turn right and the other half to turn left. A very similar situation can be found on the other side of the obstacle ( Fig. 1 C). It is interesting to note that those ants which choose, by chance, the shorter path around the obstacle will more rapidly reconstitute the interrupted pheromone trail compared to those who choose the longer path. Thus, the shorter path will receive a greater amount of pheromone per time unit and in turn a larger number of ants will choose the shorter path. Due to this positive feedback (autocatalytic) process, all the ants will rapidly choose the shorter path ( Fig. 1 D). The most interesting aspect of this autocatalytic process is that finding the shortest path around the obstacle seems to be an emergent property of the interaction between the obstacle shape and ants distributed behaviour: although all ants move at approximately the same speed and deposit a pheromone trail at approximately the same rate, it is a fact that it takes longer to contour obstacles on their longer side than on their shorter side which makes the pheromone trail accumulate quicker on the shorter side. It is the ants preference for higher pheromone trail levels which makes this accumulation still quicker on the shorter path. We will now show how a similar process can be put to work in a simulated world inhabited by artificial ants that try to solve the travelling salesman problem. Fig. 1.  (A) Real ants follow a path between nest and food source. (B) An obstacle appears on the path: ants choose whether to turn left or right with equal probability. (C) Pheromone is deposited more quickly on the shorter path. (D) All ants have chosen the shorter path. Figure options The travelling salesman problem (TSP) is the problem of finding a shortest closed tour which visits all the cities in a given set. In this article we will restrict attention to TSPs in which cities are on a plane and a path (edge) exists between each pair of cities (i.e., the TSP graph is completely connected). 2. Artificial ants In this work an artificial ant is an agent which moves from city to city on a TSP graph. It chooses the city to move to using a probabilistic function both of trail accumulated on edges and of a heuristic value, which was chosen here to be a function of the edges length. Artificial ants probabilistically prefer cities that are connected by edges with a lot of pheromone trail and which are close-by. Initially, m artificial ants are placed on randomly selected cities. At each time step they move to new cities and modify the pheromone trail on the edges used—this is termed local trail updating. When all the ants have completed a tour the ant that made the shortest tour modifies the edges belonging to its tour—termed global trail updating—by adding an amount of pheromone trail that is inversely proportional to the tour length. These are three ideas from natural ant behaviour that we have transferred to our artificial ant colony: (i) the preference for paths with a high pheromone level, (ii) the higher rate of growth of the amount of pheromone on shorter paths, and (iii) the trail mediated communication among ants. Artificial ants were also given a few capabilities which do not have a natural counterpart, but which have been observed to be well suited to the TSP application: artificial ants can determine how far away cities are, and they are endowed with a working memory M k used to memorize cities already visited (the working memory is emptied at the beginning of each new tour, and is updated after each time step by adding the new visited city). There are many different ways to translate the above principles into a computational system apt to solve the TSP. In our ant colony system (ACS) an artificial ant k in city r chooses the city s to move to among those which do not belong to its working memory M k by applying the following probabilistic formula: equation ( 1 ) where τ ( r ,  u ) is the amount of pheromone trail on edge ( r ,  u ), η ( r ,  u ) is a heuristic function, which was chosen to be the inverse of the distance between cities r and u , β is a parameter which weighs the relative importance of pheromone trail and of closeness, q is a value chosen randomly with uniform probability in [0, 1], q 0 (0≤ q 0 ≤1) is a parameter and S is a random variable selected according to the following probability distribution, which favours edges which are shorter and have a higher level of pheromone trail: equation ( 2 ) The pheromone trail is changed both locally and globally. Global updating is intended to reward edges belonging to shorter tours. Once artificial ants have completed their tours, the best ant deposits pheromone on visited edges; that is, on those edges that belong to its tour. (The other edges remain unchanged.) The amount of pheromone Δ τ ( r ,  s ) deposited on each visited edge ( r ,  s ) by the best ant is inversely proportional to the length of the tour: the shorter the tour the greater the amount of pheromone deposited on edges. This manner of depositing pheromone is intended to emulate the property of differential pheromone trail accumulation, which in the case of real ants was due to the interplay between the length of the path and continuity of time. The global trail updating formula is τ ( r ,  s )←(1− α )· τ ( r ,  s )+ α ·Δ τ ( r ,  s ), where Δ τ ( r ,  s )=(shortest tour) −1 . Global trail updating is similar to a reinforcement learning scheme in which better solutions get a higher reinforcement. Local updating is intended to avoid a very strong edge being chosen by all the ants: every time an edge is chosen by an ant its amount of pheromone is changed by applying the local trail updating formula: τ ( r ,  s )←(1− α )· τ ( r ,  s )+ α · τ 0 , where τ 0 is a parameter. Local trail updating is also motivated by trail evaporation in real ants.