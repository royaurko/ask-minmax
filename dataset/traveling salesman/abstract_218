Password: The Traveling Salesman Problem (TSP) is a very hard optimization problem in the field of operations research. It has been shown to be NP-complete, and is an often-used benchmark for new optimization techniques. One of the main challenges with this problem is that standard, non-AI heuristic approaches such as the Lin–Kernighan algorithm (LK) and the chained LK variant are currently very effective and in wide use for the common fully connected, Euclidean variant that is considered here. This paper presents an algorithm that uses adaptive resonance theory (ART) in combination with a variation of the Lin–Kernighan local optimization algorithm to solve very large instances of the TSP. The primary advantage of this algorithm over traditional LK and chained-LK approaches is the increased scalability and parallelism allowed by the divide-and-conquer clustering paradigm. Tours obtained by the algorithm are lower quality, but scaling is much better and there is a high potential for increasing performance using parallel hardware. Keywords Traveling salesman problem ; Lin–Kernighan algorithm ; Adaptive resonance theory 1. Introduction The Traveling Salesman Problem (TSP) is one of the most studied problems in computer science literature. It is an example of the important class of problems known as NP-complete problems. An NP-complete problem is one that is solvable in polynomial time by a non-deterministic algorithm, but not necessarily by a deterministic one. Another way of considering this class of problems is to say that a correct solution may be checked in polynomial time, but no known algorithm can solve the problem in that time. These problems are interesting because it is possible to draw parallels between any two NP-complete problems and show that finding an algorithm to solve one in polynomial time gives you an algorithm to solve the other. They are also interesting because it has never been proven that NP-complete problems cannot be solved in polynomial time, so it remains as an open question. The most general form of the TSP is to find a Hamiltonian cycle given an arbitrary graph. All known algorithms to solve this problem take greater than polynomial time, but if we have a solution we can check it in O ( n ) time. The more specific case of the TSP considered in this paper is also NP-complete, but is more complicated to check. The traveling salesman family of problems is an area in which neural networks have previously been unable to compete with the best non-neural approaches, in accuracy, speed, or scaling. (See ( Vishwanathan & Wunsch, 2001 ) for a critique of the then-state-of-the-art in neural network approaches to TSP. Improvements in the past 2 years notwithstanding, accuracy, speed and scaling were significant limitations.) Accuracy remains an important limitation. In fact, it seems doubtful whether neural networks will ever exceed the accuracy of algorithms like the Lin–Kernighan solution ( Lin & Kernighan, 1973 ) in solving this class of problems. Clustering algorithms in general are limited in the accuracy they can achieve on the TSP Table 1 . If highly accurate tours are required, then Lin–Kernighan and variants ( Applegate, Cook, & Rohe, 2000 ) seem likely to remain the algorithms of choice. In situations where accuracy is not the primary determinant, however, neural networks may show some promise. This is especially relevant for situations where significant modifications to ( Lin & Kernighan, 1973 ) and ( Applegate et al., 2000 ) may be required, as opposed to minor modifications and retraining, which is often all that is needed for a neural network. Table 1. Our goal then is to evaluate what advantages a neural clustering algorithm can bring to bear on the problem and decide how to best exploit those advantages. Adaptive resonance theory (ART) provides a very rapid and effective neural clustering model. Functionally, it operates similarly to k-means clustering, with an optimal k determined dynamically by the vigilance factor. The divide and conquer paradigm gives us the flexibility to hierarchically break large problems into arbitrarily small clusters depending on what trade-off between accuracy and speed is desired. In addition, the sub-problems provide an excellent opportunity to take advantage of parallel systems for further optimization. Even without parallel processing, the algorithm developed in this paper has demonstrated that better scaling is possible using a divide and conquer approach. 1.1. Traveling salesman problem Given a complete undirected graph G =( V , E ), where V is a set of vertices and E is a set of edges each relating two vertices with an associated non-negative integer costs c ( u , v ), the most general form of the TSP is equivalent to finding any Hamiltonian cycle over G where such a cycle is known as a tour. The more common form of the problem is the optimization problem of trying to find the shortest Hamiltonian cycle. Both of these problems have been proven to be NP-complete in ( Cormen, Leiserson, & Rivest, 1996 ). These problems are very useful to consider because they map so easily to many real-world applications in a wide range of fields from network routing to cryptography ( Agarwala et al., 2000 , Bailey et al., 2003  and  Turino, 2002 ). The variation of the TSP that we (and most neural network approaches to this topic) consider is even more limited. We look only at graphs that can be mapped to a two-dimensional Euclidean coordinate system, where the edge weight between two nodes is the distance between them. This system implies that the triangle inequality holds: c ( u , w )≤ c ( u , v )+ c ( v , w ). We also require that the XY coordinates of each node be given. This variation can be shown to still be NP-complete and therefore to map onto the more general problem ( Papadimitriou, 1977 ). The Euclidean form of the TSP has been widely studied ( Braun and Buhmann, 2002 , Cochrane and Cochrane, 1999  and  Aurora, 1998 ). 1.2. Adaptive resonance theory ART was first introduced by Carpenter and Grossberg (1988) . The unsupervised variants provide a simple, effective neural clustering algorithm. The original algorithm, designated ART1, used binary input sequences. The variation developed for this solution uses two-input integer sequences where the integers are the XY coordinates of a node. In this form, ART is functionally similar to k-means clustering except that k is increased dynamically as new patterns are introduced. 1.3. Local search techniques By far the most successful algorithms in tackling large-scale (1000+cities) TSPs have been the family of algorithms known as local search heuristics ( Johnson & McGeoch, 2002 ). The basic idea of local search is to start with some tour, either randomly generated or generated by some fast but low quality method, and make iterative improvements, hopefully driving it towards the optimal. In many ways this resembles the neural network technique of starting with random initial weights and then making incremental improvements via a technique like steepest descent, in an attempt to minimize errors. In the case of the TSP, the error to be minimized may be seen as the tour length. The local search class of algorithms considers a series of minor changes to determine whether they reduce the tour length. A simple local search technique that has been easy to implement is to consider the result of swapping any two edges currently in the tour with two new edges in such a way that a valid tour still exists. In a permutation representation of the tour, this change can be seen as the operation of flipping a segment of the tour. By repeatedly searching for the flip that minimizes the tour length, and stopping when no flips can be found that reduce the tour length, a shorter tour may be discovered. Once no shorter tour can be found through this method, the tour is said to be locally optimal. This specific algorithm is referred to in the literature as 2-Opt. There is a general class of algorithms of this nature that involve substituting a fixed number of edges with new edges such that a valid tour is maintained. These are referred to as k -Opt algorithms. An ( n +1)-Opt algorithm, where n is the number of cities in the problem, will always find the optimal solution, i.e. the optimal solution is at most n +1 edges away from the current tour ( Rego & Glover, 2002 )