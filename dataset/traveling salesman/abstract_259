Password: A parallel version of a Genetic Algorithm (GA) is presented and implemented on a cluster of workstations. Even though our algorithm is general enough to be applied to a wide variety of problems, we used it to obtain optimal and/or suboptimal solutions to the well-known Traveling Salesman Problem. The proposed algorithm is implemented using the Parallel Virtual Machine (PVM) library over a network of workstations. A master–slave paradigm is used to implement the proposed parallel/distributed Genetic Algorithm (PDGA), which is based on a distributed-memory approach. Tests were performed with clusters of 1, 2, 4, 8, and 16 workstations, using several real problems and population sizes. Results are presented to show how the performance of the algorithm is affected by variations on the number of slaves, population size, mutation rate, and mutation interval. The results presented show the utility, versatility, efficiency and potential value of the proposed parallel and distributed Genetic Algorithm to tackle NP-complete problems of the same nature. Keywords Genetic Algorithm ; Parallel computing ; Distributed system ; Message-passing ; Traveling Salesman Problem 1. Introduction A “complex system” has been defined [21] as one whose properties are not fully explained by an understanding of its components parts. Such systems occur in many diverse fields, such as chemistry, engineering, physics, biology, meteorology, and economics. Indeed, a new interest in complex systems is driving a disciplinary convergence, bringing biology together with mathematics, computer science, engineering and physics. Leading universities around the country are spending millions of dollars to build new interdisciplinary institutes and departments with specialists from many diverse fields to study complex systems in new and innovative ways. Much of this resurgent interest in complex systems is based on our increasing ability to employ sophisticated computational models to simulate how various collections of elements interact with one another, in order to predict their collective behavior. In many diverse modeling situations, one finds numerous optimizations of non-differentiable functions or minimization/optimization of functions (or functionals) with multiple minima, or global search methods which interact in ways that cannot be predicted without large-scale computer simulations of a magnitude unprecedented in size and complexity. Distributed systems are ideally suited to model, simulate and analyze complex engineering systems in ways that are impossible to implement with most other systems. In particular, there is a need in innovation in software-enabled technologies to facilitate a new range of system types and scales. In the past, NP-hard problems were limited by constrained computer processor, memory and communication capability. Although the cost of distributed/parallel computing hardware has fallen dramatically in the past years due to the advent of high-performance low-cost computers connected via high-speed networks, there has not been a rush to move large-scale scientific NP-hard optimizations related computations to these environments. There is a need to seek entirely new approaches to large optimization that leverage new memory capacity and computing power through high-speed massively distributed and parallel computing. In this paper a parallel/distributed version of a Genetic Algorithm (GA) is presented and implemented over a cluster of workstations to obtain quasi-optimal solutions to the widely known Traveling Salesman Problem (TSP). The TSP is important from a theoretical point of view because it is easy to formulate and, as is the case with all NP-hard problems, its corresponding decision version (DTSP) is NP-complete. When a problem is NP-complete, all other corresponding problems are polynomial-time reducible to it. In particular, finding an efficient algorithm for any NP-complete problem implies that an efficient algorithm can be found for all NP-complete problems. Nonetheless, owing to the above mentioned conjecture and to the fact that instances of this problem arise not only in the Scientific field, but also in practical situations in industry, much effort has been directed towards finding approximate solutions by means of heuristics, i.e. algorithms that produce good (although not necessarily optimal) solutions in reasonable amount of time. Among the best-known heuristics tailored for the DTSP are the Lin and Kernighan’s algorithm [15] , the Elastic Net method [6] , the Nearest Neighbors method [25] , the Minimum-Cost Spanning Tree algorithm [25] , and the Christofides’ algorithm [25] . Similarly, Simulated Annealing [13] and Genetic Algorithms [10]  and  [30] are in the group of general heuristics that have been successfully applied to this problem. Among the fastest algorithms with time complexity there is the recently reported work of Yoshiyuki and Yoshiki [29] , which is based on real space re-normalization theory. In this paper, the proposed algorithm is implemented using the Parallel Virtual Machine (PVM) library over a Network of Workstations (NoW). Genetic Algorithms are computational models inspired by the idea of evolution [26] . As it is well known, GAs encode solutions to a specific problem using a chromosome-like data structure and apply recombination operators to produce new individuals. GAs were introduced by John Holland and his students [5]  and  [12] . In a more general sense, we call a GA any population-based model that uses operators for selection and recombination to generate new individuals in the search space. More details on GAs can be found in [26] . Although GAs have been used in diverse types of problems and applications, they are often used as function optimizers. GAs are also considered global search methods that do not use gradient information. Therefore, they might be applied to problems in which the function to be optimized is non-differentiable or with multiple local optima. A GA is inherently parallel [17] , and at every iteration individuals are independently selected for crossover and mutation following some probability distribution. The proposed parallel and distributed implementation introduced in this paper uniformly decomposes the population among the available processors (hosts), so that genetic operators can be applied in parallel to multiple individuals. A master–slave paradigm is used to implement the parallel/distributed Genetic Algorithm (PDGA). The main function of the master process is to control and synchronize the operation of the slave processes. The proposed PDGA is applied to the TSP [7] , [16]  and  [18] . The problem at hand is an optimization problem which consists of finding a Hamiltonian cycle of minimum length. Individuals in the population are Hamiltonian cycles represented as a sequence of vertices, which makes the mutation and crossover operators simpler and efficient. New heuristics as well as decisional rules are introduced to support computationally efficient migration of individuals between sub-populations in order to improve the gene pool. Based on a distributed-memory approach the pseudo-code for the proposed PDGA is also presented. The proposed PDGA is implemented on a network of SUN workstations (Ultra Sparc 1) running PVM. Tests are performed using 1, 2, 4, 8, and 16 slave workstations. Several real problems and population sizes are used in our experiments. Real data for the test experiments are obtained from a library of TSPs called TSPLIB from Rice University. This library has real data on graphs of different sizes. The experimental results obtained are very promising. In particular, we show that as we increase the size of the population the performance of the PDGA improves as we increase the number of SLAVE tasks used. We additionally show that with small population sizes (i.e. p =128) the communication overhead overcomes the advantage of using the PDGA. The rest of this paper is organized as follows: in Section 2 we provide a general description of the TSP. Section 3 gives an overview of the GA methodology used, and presents the problem encoding and the fitness function used. In addition, it shows the general design of our PDGA and describes the problem parameters and the GA operators used. The pseudo-code for the MASTER and SLAVE tasks is presented in Sections 4 and 5 , respectively. In Section 6 we describe our test environment, and the test results and analysis are presented in Section 7 . The conclusions and future research is presented in Section 8 . 2. The Traveling Salesman Problem (TSP) The widely known TSP [7] , [16]  and  [18] can be stated as follows [3] : Given n cities and the distance between each pair of them, the task of the salesman is to visit each and every city once so that the overall tour-length is minimal [3] , [4]  and  [28] .